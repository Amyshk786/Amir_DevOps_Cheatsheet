{
  "CI-CD/CircleCI": "# CircleCI Cheatsheet\n\n![](https://imgur.com/s6aXKl9.png)\n\n**1. Introduction:**\n\n- CircleCI is a continuous integration and delivery platform that automates the build, test, and deploy processes, allowing for quick and efficient development workflows.\n\n**2. Key Concepts:**\n\n- **Job:** A collection of steps to be executed in a build.\n- **Step:** A single command or script within a job.\n- **Workflow:** Defines the order of jobs and their dependencies.\n- **Executor:** Specifies the environment in which the job runs (e.g., Docker, Linux VM, macOS).\n\n**3. Basic `.circleci/config.yml` Example:**\n\n- **YAML Syntax:**\n\n  ```yaml\n  version: 2.1\n\n  jobs:\n    build:\n      docker:\n        - image: circleci/node:14\n      steps:\n        - checkout\n        - run: npm install\n        - run: npm test\n\n    deploy:\n      docker:\n        - image: circleci/node:14\n      steps:\n        - checkout\n        - run: npm run deploy\n\n  workflows:\n    version: 2\n    build_and_deploy:\n      jobs:\n        - build\n        - deploy\n  ```\n\n**4. Executors:**\n\n- **Docker:** Run jobs in Docker containers.\n\n  ```yaml\n  docker:\n    - image: circleci/node:14\n  ```\n\n- **Machine:** Run jobs in a Linux VM.\n\n  ```yaml\n  machine:\n    image: ubuntu-2004:202101-01\n  ```\n\n- **macOS:** Run jobs on macOS for iOS builds.\n\n  ```yaml\n  macos:\n    xcode: \"12.4.0\"\n  ```\n\n**5. Reusable Configurations:**\n\n- **Commands:** Reuse steps across multiple jobs.\n\n  ```yaml\n  commands:\n    setup:\n      steps:\n        - checkout\n        - run: npm install\n\n  jobs:\n    build:\n      docker:\n        - image: circleci/node:14\n      steps:\n        - setup\n        - run: npm test\n  ```\n\n- **Executors:** Reuse the environment configuration.\n\n  ```yaml\n  executors:\n    node-executor:\n      docker:\n        - image: circleci/node:14\n\n  jobs:\n    build:\n      executor: node-executor\n      steps:\n        - checkout\n        - run: npm install\n  ```\n\n**6. Caching and Artifacts:**\n\n- **Caching:** Speed up builds by caching dependencies.\n\n  ```yaml\n  - restore_cache:\n      keys:\n        - v1-dependencies-{{ checksum \"package-lock.json\" }}\n  - save_cache:\n      paths:\n        - node_modules\n      key: v1-dependencies-{{ checksum \"package-lock.json\" }}\n  ```\n\n- **Artifacts:** Save build outputs and other data for later use.\n\n  ```yaml\n  - store_artifacts:\n      path: ./build\n      destination: build_output\n  ```\n\n**7. Workflows:**\n\n- **Sequential Jobs:** Define jobs that run in sequence.\n\n  ```yaml\n  workflows:\n    version: 2\n    build_and_deploy:\n      jobs:\n        - build\n        - deploy\n  ```\n\n- **Parallel Jobs:** Run jobs in parallel to speed up pipeline execution.\n\n  ```yaml\n  workflows:\n    version: 2\n    test-and-deploy:\n      jobs:\n        - test\n        - deploy\n  ```\n\n**8. Environment Variables:**\n\n- **Project-level Variables:** Set environment variables in the CircleCI project settings.\n- **Context Variables:** Use contexts to securely store and manage environment variables.\n- **Job-level Variables:**\n\n  ```yaml\n  jobs:\n    build:\n      docker:\n        - image: circleci/node:14\n      environment:\n        NODE_ENV: production\n  ```\n\n**9. Advanced CircleCI Features:**\n\n- **Orbs:** Reusable packages of CircleCI configuration that make it easy to integrate with third-party tools.\n\n  ```yaml\n  orbs:\n    aws-s3: circleci/aws-s3@4.2.0\n\n  jobs:\n    deploy:\n      steps:\n        - aws-s3/copy:\n            from: \"build/\"\n            to: \"s3://my-bucket/\"\n  ```\n\n- **Conditional Steps:** Run steps conditionally based on the success or failure of previous steps.\n\n  ```yaml\n  - run:\n      name: Deploy only if tests pass\n      command: ./deploy.sh\n      when: on_success\n  ```\n\n**10. Best Practices:**\n\n- **Parallelism:** Use parallelism to reduce build times by running tests and other tasks simultaneously.\n- **Modular Configurations:** Break down your CircleCI configuration into reusable components with orbs, commands, and executors.\n- **Effective Caching:** Cache dependencies effectively to reduce build times, but remember to invalidate caches when necessary to avoid stale dependencies.\n",
  "CI-CD/GitHub-Actions": "# GitHub Actions Cheatsheet\n\n![](https://imgur.com/GMwRo18.png)\n\n**1. Introduction:**\n\n- GitHub Actions is a powerful CI/CD and automation tool integrated directly into GitHub repositories, allowing you to build, test, and deploy your code.\n\n**2. Key Concepts:**\n\n- **Workflow:** An automated process defined in YAML that is triggered by events like `push`, `pull_request`, etc.\n- **Job:** A set of steps that runs on the same runner.\n- **Step:** An individual task, such as running a script or installing a dependency.\n- **Runner:** A server that runs the jobs in a workflow, can be GitHub-hosted or self-hosted.\n\n**3. Basic Workflow Example:**\n\n- **YAML Syntax:**\n\n  ```yaml\n  name: CI Workflow\n\n  on:\n    push:\n      branches:\n        - main\n    pull_request:\n      branches:\n        - main\n\n  jobs:\n    build:\n      runs-on: ubuntu-latest\n      steps:\n        - uses: actions/checkout@v3\n        - name: Set up Node.js\n          uses: actions/setup-node@v3\n          with:\n            node-version: '14'\n        - run: npm install\n        - run: npm test\n  ```\n\n**4. Common Actions:**\n\n- **actions/checkout:** Checks out your repository under `$GITHUB_WORKSPACE`.\n- **actions/setup-node:** Sets up a Node.js environment.\n- **actions/upload-artifact:** Uploads build artifacts for later use.\n- **actions/cache:** Caches dependencies like `node_modules` or `Maven`.\n\n**5. Triggers:**\n\n- **on: push:** Trigger a workflow when a push occurs.\n- **on: pull_request:** Trigger a workflow when a pull request is opened.\n- **on: schedule:** Schedule a workflow to run at specific times using cron syntax.\n\n**6. Environment Variables:**\n\n- **Set environment variables:**\n\n  ```yaml\n  env:\n    NODE_ENV: production\n    DEBUG: true\n  ```\n\n- **Access secrets:**\n\n  ```yaml\n  env:\n    MY_SECRET: ${{ secrets.MY_SECRET }}\n  ```\n\n**7. Matrix Builds:**\n\n- **Example:**\n\n  ```yaml\n  jobs:\n    build:\n      runs-on: ubuntu-latest\n      strategy:\n        matrix:\n          node-version: [12, 14, 16]\n      steps:\n        - uses: actions/checkout@v3\n        - name: Set up Node.js\n          uses: actions/setup-node@v3\n          with:\n            node-version: ${{ matrix.node-version }}\n        - run: npm install\n        - run: npm test\n  ```\n\n**8. Artifacts and Caching:**\n\n- **Upload Artifacts:**\n\n  ```yaml\n  - name: Upload build artifacts\n    uses: actions/upload-artifact@v3\n    with:\n      name: my-artifact\n      path: ./build\n  ```\n\n- **Caching Dependencies:**\n\n  ```yaml\n  - name: Cache Node.js modules\n    uses: actions/cache@v3\n    with:\n      path: node_modules\n      key: ${{ runner.os }}-node-${{ hashFiles('**/package-lock.json') }}\n      restore-keys: |\n        ${{ runner.os }}-node-\n  ```\n\n**9. Reusable Workflows:**\n\n- **Define a reusable workflow:**\n\n  ```yaml\n  name: Reusable CI Workflow\n\n  on:\n    workflow_call:\n      inputs:\n        node-version:\n          required: true\n          type: string\n\n  jobs:\n    build:\n      runs-on: ubuntu-latest\n      steps:\n        - uses: actions/checkout@v3\n        - name: Set up Node.js\n          uses: actions/setup-node@v3\n          with:\n            node-version: ${{ inputs.node-version }}\n        - run: npm install\n        - run: npm test\n  ```\n\n- **Call a reusable workflow:**\n\n  ```yaml\n  jobs:\n    call-workflow:\n      uses: ./.github/workflows/reusable-workflow.yml\n      with:\n        node-version: '14'\n  ```\n\n**10. Best Practices:**\n\n- **Modular Workflows:** Break down complex workflows into smaller, reusable pieces.\n- **Use Environments:** Leverage environments in GitHub Actions for deployments with manual approvals.\n- **Secret Management:** Always use GitHub Secrets for sensitive information and never hard-code them.\n",
  "CI-CD/GitLab-CI": "# GitLab CI Cheatsheet\n\n![](https://imgur.com/dbufti0.png)\n\n**1. Introduction:**\n\n- GitLab CI/CD is a part of GitLab, a complete DevOps platform, allowing you to define CI/CD pipelines directly within your GitLab repository using the `.gitlab-ci.yml` file.\n\n**2. Key Concepts:**\n\n- **Pipeline:** A series of stages that run jobs sequentially or in parallel.\n- **Job:** An individual unit of work, such as running tests or deploying code.\n- **Stage:** A group of jobs that run in parallel.\n- **Runner:** The agent that executes jobs, can be GitLab-hosted or self-hosted.\n\n**3. Basic `.gitlab-ci.yml` Example:**\n\n- **YAML Syntax:**\n\n  ```yaml\n  stages:\n    - build\n    - test\n    - deploy\n\n  build-job:\n    stage: build\n    script:\n      - echo \"Building the project...\"\n      - make\n\n  test-job:\n    stage: test\n\n\n    script:\n      - echo \"Running tests...\"\n      - make test\n\n  deploy-job:\n    stage: deploy\n    script:\n      - echo \"Deploying the project...\"\n      - make deploy\n  ```\n\n**4. Runners:**\n\n- **Shared Runners:** Provided by GitLab and available to all projects.\n- **Specific Runners:** Custom runners registered to a specific project or group.\n- **Tags:** Use tags to specify which runner should execute a job.\n\n**5. Artifacts and Caching:**\n\n- **Artifacts:** Save job outputs and make them available to subsequent jobs.\n\n  ```yaml\n  artifacts:\n    paths:\n      - build/\n    expire_in: 1 week\n  ```\n\n- **Caching:** Speed up jobs by reusing previously downloaded dependencies.\n\n  ```yaml\n  cache:\n    paths:\n      - node_modules/\n  ```\n\n**6. Environments and Deployments:**\n\n- **Environments:** Define environments to organize and manage deployments.\n\n  ```yaml\n  deploy-job:\n    stage: deploy\n    environment:\n      name: production\n      url: https://myapp.com\n    script:\n      - echo \"Deploying to production...\"\n      - ./deploy.sh\n  ```\n\n- **Manual Deployments:** Require manual approval before a job runs.\n\n  ```yaml\n  deploy-job:\n    stage: deploy\n    script:\n      - ./deploy.sh\n    when: manual\n  ```\n\n**7. Advanced `.gitlab-ci.yml` Features:**\n\n- **YAML Anchors:** Reuse parts of your YAML configuration.\n\n  ```yaml\n  .default-job: &default-job\n    script:\n      - echo \"Default job script\"\n\n  job1:\n    <<: *default-job\n\n  job2:\n    <<: *default-job\n  ```\n\n- **Includes:** Include other YAML files to organize your configuration.\n\n  ```yaml\n  include:\n    - local: '/templates/.gitlab-ci-template.yml'\n  ```\n\n**8. Security and Compliance:**\n\n- **Secret Variables:** Store sensitive data securely in GitLab CI/CD.\n\n  ```yaml\n  deploy-job:\n    script:\n      - deploy --token $CI_DEPLOY_TOKEN\n  ```\n\n- **Protected Branches:** Restrict certain jobs to run only on protected branches.\n\n**9. Troubleshooting:**\n\n- **Pipeline Logs:** Access detailed logs for each job to troubleshoot failures.\n- **Retrying Jobs:** Use the GitLab UI to manually retry failed jobs.\n\n**10. Best Practices:**\n\n- **Modular Pipelines:** Break down your pipeline into stages for better organization.\n- **Use CI/CD Templates:** Leverage GitLab’s built-in templates for common CI/CD tasks.\n- **Optimize Runner Usage:** Use caching, artifacts, and parallel jobs to reduce pipeline runtime.\n",
  "CI-CD/Jenkins": "# Jenkins Cheatsheet\n\n![](https://imgur.com/jWGs9lH.png)\n\n**1. Introduction:**\n\n- Jenkins is an open-source automation server that helps automate parts of software development related to building, testing, and deploying, facilitating continuous integration and delivery.\n\n**2. Installation:**\n\n- **Docker Installation:**\n\n  ```bash\n  docker run -d -p 8080:8080 -p 50000:50000 jenkins/jenkins:lts\n  ```\n\n- **Direct Installation:**\n\n  - **For Ubuntu/Debian:**\n\n    ```bash\n    wget -q -O - https://pkg.jenkins.io/debian/jenkins.io.key | sudo apt-key add -\n    sudo sh -c 'echo deb http://pkg.jenkins.io/debian-stable binary/ > /etc/apt/sources.list.d/jenkins.list'\n    sudo apt update\n    sudo apt install jenkins\n    ```\n\n  - **For CentOS/RHEL:**\n\n    ```bash\n    sudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo\n    sudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key\n    sudo yum install jenkins\n    ```\n\n- **Access Jenkins:**\n  - Visit `http://localhost:8080` in your web browser.\n\n**3. Jenkins Pipeline:**\n\n- **Declarative Pipeline:**\n\n  ```groovy\n  pipeline {\n      agent any\n      environment {\n          MY_VAR = \"value\"\n      }\n      stages {\n          stage('Checkout') {\n              steps {\n                  checkout scm\n              }\n          }\n          stage('Build') {\n              steps {\n                  sh 'make'\n              }\n          }\n          stage('Test') {\n              steps {\n                  sh 'make test'\n              }\n          }\n          stage('Deploy') {\n              steps {\n                  sh 'make deploy'\n              }\n          }\n      }\n      post {\n          success {\n              echo 'Pipeline completed successfully!'\n          }\n          failure {\n              echo 'Pipeline failed.'\n          }\n      }\n  }\n  ```\n\n- **Scripted Pipeline:**\n\n  ```groovy\n  node {\n      stage('Checkout') {\n          checkout scm\n      }\n      stage('Build') {\n          sh 'make'\n      }\n      stage('Test') {\n          sh 'make test'\n      }\n      stage('Deploy') {\n          sh 'make deploy'\n      }\n  }\n  ```\n\n**4. Common Jenkins Commands:**\n\n- **Restart Jenkins:**\n\n  ```bash\n  sudo systemctl restart jenkins\n  ```\n\n- **Manage Jenkins from CLI:**\n\n  ```bash\n  java -jar jenkins-cli.jar -s http://localhost:8080/ list-jobs\n  ```\n\n**5. Useful Jenkins Plugins:**\n\n- **Blue Ocean:** Modern UI for Jenkins pipelines.\n- **Git:** Integrate Git version control into Jenkins.\n- **Pipeline:** Enables Pipeline as Code.\n- **Credentials Binding:** Securely manage credentials.\n- **SonarQube Scanner:** Integrate code quality checks.\n- **Slack Notification:** Send pipeline status notifications to Slack.\n\n**6. Best Practices:**\n\n- **Pipeline as Code:** Always use Jenkins Pipelines defined in `Jenkinsfile` for consistent and version-controlled builds.\n- **Use Parameters:** Use parameters to make your pipelines flexible and reusable.\n\n  ```groovy\n  parameters {\n      string(name: 'ENV', defaultValue: 'dev', description: 'Environment')\n  }\n  ```\n\n- **Secure Jenkins:** Regularly update plugins, use RBAC, and secure the Jenkins instance with HTTPS.\n\n**7. Jenkins Configuration:**\n\n- **Manage Jenkins:**\n  - Manage and configure global settings from the Jenkins dashboard under **Manage Jenkins**.\n- **Configure Tools:** Set up JDK, Maven, and other tools globally in **Global Tool Configuration**.\n- **Jenkinsfile Configuration:**\n  - Define your pipeline stages, environment, and agents within a `Jenkinsfile` stored in your repository.\n\n**8. Advanced Jenkins:**\n\n- **Parallel Stages:**\n\n  ```groovy\n  pipeline {\n      agent any\n      stages {\n          stage('Parallel') {\n              parallel {\n                  stage('Unit Tests') {\n                      steps {\n                          sh 'make test'\n                      }\n                  }\n                  stage('Integration Tests') {\n                      steps {\n                          sh 'make integration-test'\n                      }\n                  }\n              }\n          }\n      }\n  }\n  ```\n\n- **Shared Libraries:** Centralize and reuse pipeline code across projects using Shared Libraries.\n\n## **Troubleshooting**\n\n### **Common Issues**\n\n1. **Jenkins Won't Start**\n   ```bash\n   # Check logs\n   sudo tail -f /var/log/jenkins/jenkins.log\n   \n   # Check permissions\n   sudo chown -R jenkins:jenkins /var/lib/jenkins\n   ```\n\n2. **Pipeline Failure**\n   ```groovy\n   // Add error handling\n   pipeline {\n       agent any\n       stages {\n           stage('Build') {\n               steps {\n                   script {\n                       try {\n                           sh 'make build'\n                       } catch (exc) {\n                           echo 'Build failed!'\n                           throw exc\n                       }\n                   }\n               }\n           }\n       }\n   }\n   ```\n\n3. **Plugin Issues**\n   - Clear plugin cache:\n     ```bash\n     rm -rf $JENKINS_HOME/plugins/*.jpi\n     rm -rf $JENKINS_HOME/plugins/*.hpi\n     ```\n   - Restart Jenkins after plugin updates\n\n## **Useful Plugins**\n\n1. **Pipeline**\n   - Pipeline Graph View\n   - Pipeline Stage View\n   - Blue Ocean\n\n2. **Source Control**\n   - Git\n   - GitHub Integration\n   - BitBucket Integration\n\n3. **Build Tools**\n   - Maven Integration\n   - Gradle\n   - NodeJS\n\n4. **Testing**\n   - JUnit\n   - Cobertura\n   - SonarQube Scanner\n\n5. **Deployment**\n   - Docker\n   - Kubernetes\n   - AWS\n",
  "Containerization/CRI-O": "# CRI-O Cheatsheet\n\n![text](https://imgur.com/iET0fW6.png)\n\n## Table of Contents\n\n1. **Introduction to CRI-O**\n   - What is CRI-O?\n   - Architecture Overview\n   - Key Features\n2. **Installation**\n   - System Requirements\n   - Installing CRI-O on Linux\n   - Post-Installation Configuration\n3. **Basic Commands**\n   - CRI-O CLI Overview\n   - Starting and Stopping CRI-O\n   - Managing Containers\n   - Viewing Logs\n4. **Container Management**\n   - Pulling Images\n   - Running Containers\n   - Stopping and Removing Containers\n   - Viewing Running Containers\n5. **Networking**\n   - Default Networking Configuration\n   - Configuring Custom Networks\n   - Using CNI Plugins with CRI-O\n6. **Storage**\n   - Managing Container Storage\n   - Configuring Storage Options\n   - Persistent Storage Management\n7. **Security**\n   - Pod Security Policies (PSPs)\n   - SELinux and CRI-O\n   - Seccomp Profiles\n   - AppArmor Integration\n8. **Monitoring and Logging**\n   - Integrating with Prometheus\n   - Setting Up Log Collection\n   - Debugging Containers\n9. **Advanced Configuration**\n   - CRI-O Configuration Files\n   - Runtime Configuration\n   - Resource Limits and Cgroups\n   - Tuning for Performance\n10. **Troubleshooting**\n    - Common Issues and Fixes\n    - Analyzing CRI-O Logs\n    - Debugging Failed Containers\n11. **Integration with Kubernetes**\n    - Configuring CRI-O with Kubernetes\n    - CRI-O as a Container Runtime for K8s\n    - Multi-tenancy with CRI-O in Kubernetes\n12. **Best Practices**\n    - Security Best Practices\n    - Performance Optimization\n    - Efficient Resource Management\n13. **FAQs**\n    - Common Questions about CRI-O\n14. **References**\n    - Official Documentation\n    - Community Resources\n\n---\n\n## 1. Introduction to CRI-O\n\n### What is CRI-O?\n\n- **CRI-O** is an open-source, lightweight container runtime for Kubernetes. It is designed to provide a minimal and stable interface between Kubernetes and the container runtime, adhering to the Container Runtime Interface (CRI) specifications.\n\n### Architecture Overview\n\n- **CRI-O** integrates directly with Kubernetes, using OCI-compatible runtimes (like runc) to handle container operations. It replaces the need for a full container engine like Docker in Kubernetes environments.\n\n### Key Features\n\n- **Lightweight**: Minimal dependencies and a smaller footprint compared to full container engines.\n- **Compatibility**: Fully compliant with Kubernetes and the Open Container Initiative (OCI) specifications.\n- **Security**: Integrates with SELinux, AppArmor, and seccomp for enhanced security.\n- **Performance**: Optimized for performance with lower overhead.\n\n---\n\n## 2. Installation\n\n### System Requirements\n\n- **Supported OS**: CRI-O supports various Linux distributions including Fedora, CentOS, and Ubuntu.\n- **Kernel Version**: Ensure that your Linux kernel is 4.19 or higher for optimal compatibility.\n\n### Installing CRI-O on Linux\n\n- **Fedora/CentOS**:\n\n  ```bash\n  sudo dnf install -y cri-o\n  ```\n\n- **Ubuntu**:\n\n  ```bash\n  sudo apt-get install -y cri-o\n  ```\n\n### Post-Installation Configuration\n\n- **Start and Enable CRI-O**:\n\n  ```bash\n  sudo systemctl start crio\n  sudo systemctl enable crio\n  ```\n\n- **Verify Installation**:\n\n  ```bash\n  crio --version\n  ```\n\n---\n\n## 3. Basic Commands\n\n### CRI-O CLI Overview\n\n- **`crio`**: The main command for interacting with the CRI-O service.\n- **`crictl`**: A CLI tool used to manage containers and images through CRI-O.\n\n### Starting and Stopping CRI-O\n\n- **Start CRI-O**:\n\n  ```bash\n  sudo systemctl start crio\n  ```\n\n- **Stop CRI-O**:\n\n  ```bash\n  sudo systemctl stop crio\n  ```\n\n### Managing Containers\n\n- **List Running Containers**:\n\n  ```bash\n  sudo crictl ps\n  ```\n\n- **Stop a Container**:\n\n  ```bash\n  sudo crictl stop <container_id>\n  ```\n\n- **Remove a Container**:\n\n  ```bash\n  sudo crictl rm <container_id>\n  ```\n\n### Viewing Logs\n\n- **View CRI-O Logs**:\n\n  ```bash\n  sudo journalctl -u crio\n  ```\n\n---\n\n## 4. Container Management\n\n### Pulling Images\n\n- **Pull an Image**:\n\n  ```bash\n  sudo crictl pull <image_name>\n  ```\n\n### Running Containers\n\n- **Run a Container**:\n\n  ```bash\n  sudo crictl run <pod_config.json> <container_config.json>\n  ```\n\n### Stopping and Removing Containers\n\n- **Stop a Container**:\n\n  ```bash\n  sudo crictl stop <container_id>\n  ```\n\n- **Remove a Container**:\n\n  ```bash\n  sudo crictl rm <container_id>\n  ```\n\n### Viewing Running Containers\n\n- **List Containers**:\n\n  ```bash\n  sudo crictl ps\n  ```\n\n---\n\n## 5. Networking\n\n### Default Networking Configuration\n\n- **Default Network**: CRI-O uses the `cni0` bridge for networking by default.\n\n### Configuring Custom Networks\n\n- **CNI Plugins**: CRI-O can use various CNI plugins to configure custom network setups.\n\n### Using CNI Plugins with CRI-O\n\n- **Install CNI Plugins**:\n\n  ```bash\n  sudo dnf install -y containernetworking-plugins\n  ```\n\n- **Configure Plugin**: Add your CNI plugin configuration in `/etc/cni/net.d/`.\n\n---\n\n## 6. Storage\n\n### Managing Container Storage\n\n- **Default Storage**: CRI-O uses `overlay` storage driver by default.\n\n### Configuring Storage Options\n\n- **Modify Storage Driver**: Edit `/etc/containers/storage.conf` to change the storage driver.\n\n### Persistent Storage Management\n\n- **Mount Volumes**: Use `--mount` option to attach persistent storage volumes to containers.\n\n---\n\n## 7. Security\n\n### Pod Security Policies (PSPs)\n\n- **Enable PSPs**: Configure PSPs in Kubernetes to apply security restrictions on CRI-O managed containers.\n\n### SELinux and CRI-O\n\n- **SELinux Enforcement**: Ensure SELinux is enabled on the host system for better security.\n\n### Seccomp Profiles\n\n- **Enable Seccomp**: CRI-O supports seccomp profiles to restrict system calls for containers.\n\n### AppArmor Integration\n\n- **AppArmor Profiles**: Apply AppArmor profiles for CRI-O containers to enforce security policies.\n\n---\n\n## 8. Monitoring and Logging\n\n### Integrating with Prometheus\n\n- **Prometheus Metrics**: CRI-O exposes metrics that can be scraped by Prometheus for monitoring.\n\n### Setting Up Log Collection\n\n- **Log Rotation**: Configure log rotation in `/etc/crio/crio.conf` to manage container logs.\n\n### Debugging Containers\n\n- **Container Logs**:\n\n  ```bash\n  sudo crictl logs <container_id>\n  ```\n\n---\n\n## 9. Advanced Configuration\n\n### CRI-O Configuration Files\n\n- **Main Configuration File**: `/etc/crio/crio.conf`\n- **Modify Configurations**: Adjust settings for runtime, networking, and storage.\n\n### Runtime Configuration\n\n- **Specify Runtime**: Use the `runtime` section in `crio.conf` to set the container runtime (e.g., runc, kata).\n\n### Resource Limits and Cgroups\n\n- **Set Resource Limits**: Define CPU and memory limits in the container configuration.\n\n### Tuning for Performance\n\n- **Adjust Parameters**: Modify parameters like `pids_limit` and `log_size_max` in `crio.conf` for performance tuning.\n\n---\n\n## 10. Troubleshooting\n\n### Common Issues and Fixes\n\n- **Containers Not Starting**: Check logs for errors related to runtime or configuration issues.\n- **Networking Issues**: Verify CNI plugin configurations and network settings.\n\n### Analyzing CRI-O Logs\n\n- **View Logs**:\n\n  ```bash\n  sudo journalctl -u crio\n  ```\n\n### Debugging Failed Containers\n\n- **Check Exit Code**:\n\n  ```bash\n  sudo crictl inspect <container_id>\n  ```\n\n---\n\n## 11. Integration with Kubernetes\n\n### Configuring CRI-O with Kubernetes\n\n- **Set CRI-O as the Default Runtime**: Modify Kubernetes configuration to use CRI-O as the default container runtime.\n\n### CRI-O as a Container Runtime for K8s\n\n- **Installation**: Ensure CRI-O is installed and configured on all Kubernetes nodes.\n\n### Multi-tenancy with CRI-O in Kubernetes\n\n- **Namespace Isolation**: Use Kubernetes namespaces and CRI-O security features to ensure tenant isolation.\n\n---\n\n## 12. Best Practices\n\n### Security Best Practices\n\n- **Use SELinux**: Enable SELinux for all nodes running CRI-O.\n- **Limit Resource Usage**: Define CPU and memory limits to prevent resource exhaustion.\n\n### Performance Optimization\n\n- **Tune Runtime**: Adjust runtime parameters for high-performance workloads.\n- **Log Management**: Set up proper log rotation to prevent disk space exhaustion.\n\n### Efficient Resource Management\n\n- **Resource Limits**: Apply resource limits to containers to optimize cluster resource usage.\n\n---\n\n## 13. FAQs\n\n### Common Questions about CRI-O\n\n- **\n\nQ**: How does CRI-O differ from Docker?\n  **A**: CRI-O is a lightweight container runtime designed specifically for Kubernetes, whereas Docker is a full-featured container platform.\n\n- **Q**: Can CRI-O run standalone without Kubernetes?\n  **A**: CRI-O is designed to run within Kubernetes environments, but it can also be used with tools like `crictl` for standalone operations.\n\n---\n\n## 14. References\n\n### Official Documentation\n\n- [CRI-O GitHub Repository](https://github.com/cri-o/cri-o)\n- [CRI-O Documentation](https://crio.readthedocs.io/)\n\n### Community Resources\n\n- [Kubernetes CRI-O Integration Guide](https://kubernetes.io/docs/setup/production-environment/container-runtimes/#cri-o)\n",
  "Containerization/Docker": "# Docker Cheatsheet\n\n![text](https://imgur.com/XHwJp6U.png)\n\n## Checkout detailed article on [Dev.to](https://dev.to/prodevopsguytech/docker-commands-from-beginner-to-advanced-for-devops-engineers-bb3)\n\n## 1. Introduction to Docker\n\n### What is Docker?\n\n- **Docker** is an open-source platform that automates the deployment, scaling, and management of applications by using containerization technology. Containers are lightweight, portable, and consistent environments that contain everything needed to run a piece of software, including the code, runtime, system tools, libraries, and settings.\n\n### Key Concepts\n\n- **Docker Engine**: The core component of Docker, responsible for running containers.\n- **Image**: A lightweight, standalone, and executable software package that includes everything needed to run an application.\n- **Container**: A runtime instance of a Docker image that shares the host system's kernel.\n- **Dockerfile**: A script containing a series of commands to assemble a Docker image.\n- **Registry**: A storage and distribution system for Docker images, such as Docker Hub.\n- **Docker Compose**: A tool for defining and running multi-container Docker applications using a YAML file.\n\n---\n\n## 2. Installing Docker\n\n### Install Docker on Linux\n\n- **Install Docker Engine**:\n\n  ```bash\n  sudo apt-get update\n  sudo apt-get install docker-ce docker-ce-cli containerd.io\n  ```\n\n- **Start Docker Service**:\n\n  ```bash\n  sudo systemctl start docker\n  sudo systemctl enable docker\n  ```\n\n### Install Docker on macOS\n\n- **Install Docker Desktop**:\n  - Download and install Docker Desktop from [Docker's official website](https://www.docker.com/products/docker-desktop).\n\n### Install Docker on Windows\n\n- **Install Docker Desktop**:\n  - Download and install Docker Desktop from [Docker's official website](https://www.docker.com/products/docker-desktop).\n\n---\n\n## 3. Basic Docker Operations\n\n### Working with Docker Images\n\n- **Search for an Image**:\n\n  ```bash\n  docker search nginx\n  ```\n\n- **Pull an Image from Docker Hub**:\n\n  ```bash\n  docker pull nginx\n  ```\n\n- **List All Images**:\n\n  ```bash\n  docker images\n  ```\n\n- **Remove an Image**:\n\n  ```bash\n  docker rmi nginx\n  ```\n\n### Working with Docker Containers\n\n- **Run a Container**:\n\n  ```bash\n  docker run -d -p 80:80 --name mynginx nginx\n  ```\n\n- **List Running Containers**:\n\n  ```bash\n  docker ps\n  ```\n\n- **List All Containers (including stopped)**:\n\n  ```bash\n  docker ps -a\n  ```\n\n- **Stop a Running Container**:\n\n  ```bash\n  docker stop mynginx\n  ```\n\n- **Remove a Container**:\n\n  ```bash\n  docker rm mynginx\n  ```\n\n### Docker Networks\n\n- **List All Networks**:\n\n  ```bash\n  docker network ls\n  ```\n\n- **Create a New Network**:\n\n  ```bash\n  docker network create mynetwork\n  ```\n\n- **Connect a Container to a Network**:\n\n  ```bash\n  docker network connect mynetwork mynginx\n  ```\n\n- **Disconnect a Container from a Network**:\n\n  ```bash\n  docker network disconnect mynetwork mynginx\n  ```\n\n---\n\n## 4. Building Docker Images\n\n### Dockerfile Basics\n\n- **Sample Dockerfile**:\n\n  ```Dockerfile\n  # Use an official Node.js runtime as a parent image\n  FROM node:14\n\n  # Set the working directory in the container\n  WORKDIR /app\n\n  # Copy the current directory contents into the container at /app\n  COPY . /app\n\n  # Install any needed packages specified in package.json\n  RUN npm install\n\n  # Make port 8080 available to the world outside this container\n  EXPOSE 8080\n\n  # Define environment variable\n  ENV NODE_ENV production\n\n  # Run app.js using node\n  CMD [\"node\", \"app.js\"]\n  ```\n\n### Building an Image from a Dockerfile\n\n- **Build the Image**:\n\n  ```bash\n  docker build -t mynodeapp .\n  ```\n\n### Managing Image Tags\n\n- **Tag an Image**:\n\n  ```bash\n  docker tag mynodeapp myrepo/mynodeapp:v1.0\n  ```\n\n- **Push an Image to Docker Hub**:\n\n  ```bash\n  docker push myrepo/mynodeapp:v1.0\n  ```\n\n---\n\n## 5. Docker Compose\n\n### Introduction to Docker Compose\n\n- **Docker Compose** is a tool for defining and running multi-container Docker applications. You use a YAML file to configure your application's services, and then use a single command to create and start all the services.\n\n### Sample `docker-compose.yml` File\n\n```yaml\nversion: '3'\nservices:\n  web:\n    image: nginx\n    ports:\n      - \"8080:80\"\n  db:\n    image: mysql:5.7\n    environment:\n      MYSQL_ROOT_PASSWORD: example\n```\n\n### Docker Compose Commands\n\n- **Start Services**:\n\n  ```bash\n  docker-compose up\n  ```\n\n- **Stop Services**:\n\n  ```bash\n  docker-compose down\n  ```\n\n- **Scale Services**:\n\n  ```bash\n  docker-compose up --scale web=3\n  ```\n\n### Managing Volumes with Docker Compose\n\n- **Defining Volumes**:\n\n  ```yaml\n  services:\n    web:\n      image: nginx\n      volumes:\n        - ./webdata:/usr/share/nginx/html\n  ```\n\n---\n\n## 6. Docker Volumes and Storage\n\n### Understanding Docker Volumes\n\n- **Volumes** are the preferred mechanism for persisting data generated and used by Docker containers.\n\n### Managing Volumes\n\n- **Create a Volume**:\n\n  ```bash\n  docker volume create myvolume\n  ```\n\n- **List All Volumes**:\n\n  ```bash\n  docker volume ls\n  ```\n\n- **Inspect a Volume**:\n\n  ```bash\n  docker volume inspect myvolume\n  ```\n\n- **Remove a Volume**:\n\n  ```bash\n  docker volume rm myvolume\n  ```\n\n### Mounting Volumes\n\n- **Mount a Volume to a Container**:\n\n  ```bash\n  docker run -d -p 80:80 --name mynginx -v myvolume:/usr/share/nginx/html nginx\n  ```\n\n### Bind Mounts\n\n- **Use a Bind Mount**:\n\n  ```bash\n  docker run -d -p 80:80 --name mynginx -v /path/to/local/dir:/usr/share/nginx/html nginx\n  ```\n\n---\n\n## 7. Docker Networking\n\n### Networking Modes\n\n- **Bridge Network**: The default network driver, which allows containers to communicate on the same host.\n- **Host Network**: Removes network isolation between the container and the Docker host.\n- **Overlay Network**: Enables networking between multiple Docker hosts in a swarm.\n\n### Working with Networks\n\n- **Create a User-Defined Bridge Network**:\n\n  ```bash\n  docker network create mynetwork\n  ```\n\n- **Run a Container in a Network**:\n\n  ```bash\n  docker run -d --name mynginx --network=mynetwork nginx\n  ```\n\n- **Inspect a Network**:\n\n  ```bash\n  docker network inspect mynetwork\n  ```\n\n### DNS in Docker\n\n- Docker containers can resolve each other's hostnames to IP addresses by using the embedded DNS server.\n\n---\n\n## 8. Docker Security\n\n### Securing Docker\n\n- **Least Privileged User**: Always run containers as a non-root user.\n\n  ```Dockerfile\n  FROM nginx\n  USER www-data\n  ```\n\n- **Use Trusted Images**: Use official images or images from trusted sources.\n- **Keep Docker Updated**: Regularly update Docker to the latest version to benefit from security patches.\n\n### Docker Content Trust\n\n- **Enable Docker Content Trust (DCT)**:\n\n  ```bash\n  export DOCKER_CONTENT_TRUST=1\n  ```\n\n### Managing Secrets\n\n- **Create a Secret in Docker Swarm**:\n\n  ```bash\n  echo \"mysecretpassword\" | docker secret create my_secret -\n  ```\n\n- **Use a Secret in a Service**:\n\n  ```bash\n  docker service create --name myservice --secret my_secret nginx\n  ```\n\n### Securing Docker Daemon\n\n- **Use TLS to Secure Docker API**:\n  - Generate TLS certificates and configure the Docker daemon to use them for secure communication.\n\n### Limiting Container Resources\n\n- **Limit Memory**:\n\n  ```bash\n  docker run -d --name mynginx --memory=\"256m\" nginx\n  ```\n\n- **Limit CPU**:\n\n  ```bash\n  docker run -d --name mynginx --cpus=\"1.0\" nginx\n  ```\n\n---\n\n## 9. Advanced Docker Features\n\n### Docker Swarm\n\n- **Initialize a Swarm**:\n\n  ```bash\n  docker swarm init\n  ```\n\n- **Join a Swarm**:\n\n  ```bash\n  docker swarm join --token SWMTKN-1-xxxx\n  ```\n\n- **Deploy a Stack**:\n\n  ```bash\n  docker stack deploy -c docker-compose.yml mystack\n  ```\n\n### Multi-Stage Builds\n\n- **Example of a Multi-Stage Dockerfile**:\n\n  ```Dockerfile\n  # First Stage\n  FROM golang:1.16 as builder\n  WORKDIR /app\n  COPY . .\n  RUN go build -o myapp\n\n  # Second Stage\n  FROM alpine:latest\n  WORKDIR /app\n  COPY --from=builder /app/myapp .\n  CMD [\"./myapp\"]\n  ```\n\n### Docker Plugins\n\n- **List Installed Plugins**:\n\n  ```bash\n  docker plugin ls\n  ```\n\n- **Install a Plugin\n\n**:\n\n  ```bash\n  docker plugin install vieux/sshfs\n  ```\n\n### Docker Daemon Configuration\n\n- **Customizing Docker Daemon**:\n  - Edit the `/etc/docker/daemon.json` file to configure the Docker daemon.\n\n  ```json\n  {\n    \"log-driver\": \"json-file\",\n    \"log-level\": \"warn\",\n    \"storage-driver\": \"overlay2\"\n  }\n  ```\n\n- **Reload Daemon Configuration**:\n\n  ```bash\n  sudo systemctl reload docker\n  ```\n\n---\n\n## 10. Monitoring and Logging\n\n### Docker Logs\n\n- **View Container Logs**:\n\n  ```bash\n  docker logs mynginx\n  ```\n\n- **Follow Logs**:\n\n  ```bash\n  docker logs -f mynginx\n  ```\n\n### Monitoring Containers\n\n- **Inspect Resource Usage**:\n\n  ```bash\n  docker stats mynginx\n  ```\n\n- **Docker Events**:\n  - Monitor Docker events in real-time.\n\n  ```bash\n  docker events\n  ```\n\n### Integrating with Monitoring Tools\n\n- **Prometheus and Grafana**: Use cAdvisor and Prometheus Node Exporter to monitor Docker containers.\n\n  ```bash\n  docker run -d --name=cadvisor --volume=/:/rootfs:ro --volume=/var/run:/var/run:ro --volume=/sys:/sys:ro --volume=/var/lib/docker/:/var/lib/docker:ro --volume=/dev/disk/:/dev/disk:ro --publish=8080:8080 google/cadvisor:latest\n  ```\n\n---\n\n## 11. Docker Best Practices\n\n### Dockerfile Best Practices\n\n- **Minimize Image Size**: Use multi-stage builds and slim base images.\n- **Leverage Build Cache**: Organize Dockerfile instructions to maximize the use of cache layers.\n- **Use `.dockerignore`**: Exclude unnecessary files from the build context using a `.dockerignore` file.\n\n### Container Management Best Practices\n\n- **Immutable Infrastructure**: Treat containers as immutable, replace rather than modify running containers.\n- **Keep Containers Stateless**: Design containers to be stateless, with external data persistence.\n- **Log to STDOUT/STDERR**: Ensure containers log to STDOUT/STDERR for easier aggregation and analysis.\n\n### Security Best Practices\n\n- **Regularly Scan Images**: Use tools like `trivy` to scan images for vulnerabilities.\n- **Use Namespaces**: Use namespaces to isolate container resources and enhance security.\n- **Limit Capabilities**: Drop unnecessary capabilities from containers.\n\n  ```bash\n  docker run --cap-drop=ALL --cap-add=NET_BIND_SERVICE nginx\n  ```\n\n---\n\n## 12. Troubleshooting Docker\n\n### Common Issues\n\n- **Container Exits Immediately**:\n  - Check the Docker logs for errors.\n\n  ```bash\n  docker logs <container_id>\n  ```\n\n- **Image Build Fails**:\n  - Debug using the `--no-cache` option to rebuild the image without cache.\n\n  ```bash\n  docker build --no-cache -t myimage .\n  ```\n\n- **Networking Issues**:\n  - Verify network settings and connectivity.\n\n  ```bash\n  docker network inspect <network_name>\n  ```\n\n### Useful Docker Commands for Troubleshooting\n\n- **Inspect a Container**:\n\n  ```bash\n  docker inspect <container_id>\n  ```\n\n- **Enter a Running Container**:\n\n  ```bash\n  docker exec -it <container_id> /bin/bash\n  ```\n\n- **Check Resource Usage**:\n\n  ```bash\n  docker stats\n  ```\n\n---\n\n## 13. References\n\n### Official Documentation\n\n- [Docker Documentation](https://docs.docker.com/)\n\n### Community Resources\n\n- [Docker Hub](https://hub.docker.com/)\n- [Docker GitHub Repository](https://github.com/docker/docker-ce)\n- [Docker Forums](https://forums.docker.com/)\n",
  "Containerization/Helm": "# Helm Cheatsheet\n\n![text](https://imgur.com/nDW9BHK.png)\n\n**1. Introduction:**\n\n- **Helm** is a package manager for Kubernetes, helping you define, install, and upgrade even the most complex Kubernetes applications. It uses charts to package Kubernetes resources.\n\n**2. Key Concepts:**\n\n- **Chart:** A collection of files that describe a set of Kubernetes resources.\n- **Release:** An instance of a chart running in a Kubernetes cluster.\n- **Repository:** A place where charts can be collected and shared.\n\n**3. Installing Helm:**\n\n- **Helm Installation:**\n\n  ```bash\n  curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash\n  ```\n\n- **Add a Helm Repository:**\n\n  ```bash\n  helm repo add stable https://charts.helm.sh/stable\n  helm repo update\n  ```\n\n**4. Helm Commands:**\n\n- **Install a Chart:**\n\n  ```bash\n  helm install my-release stable/nginx\n  ```\n\n- **List Releases:**\n\n  ```bash\n  helm list\n  ```\n\n- **Upgrade a Release:**\n\n  ```bash\n  helm upgrade my-release stable/nginx\n  ```\n\n- **Uninstall a Release:**\n\n  ```bash\n  helm uninstall my-release\n  ```\n\n- **Search for Charts:**\n\n  ```bash\n  helm search repo nginx\n  ```\n\n**5. Chart Structure:**\n\n- **Basic Chart Structure:**\n\n  ```\n  my-chart/\n  ├── Chart.yaml\n  ├── values.yaml\n  ├── charts/\n  ├── templates/\n  │   ├── deployment.yaml\n  │   ├── service.yaml\n  │   └── _helpers.tpl\n  ```\n\n- **Chart.yaml:**\n\n  ```yaml\n  apiVersion: v2\n  name: my-chart\n  description: A Helm chart for Kubernetes\n  version: 0.1.0\n  ```\n\n- **values.yaml:**\n\n  ```yaml\n  replicaCount: 3\n  image:\n    repository: nginx\n    tag: stable\n  ```\n\n- **Template Example (deployment.yaml):**\n\n  ```yaml\n  apiVersion: apps/v1\n  kind: Deployment\n  metadata:\n    name: {{ .Release.Name }}-nginx\n  spec:\n    replicas: {{ .Values.replicaCount }}\n    selector:\n      matchLabels:\n        app: {{ .Release.Name }}-nginx\n    template:\n      metadata:\n        labels:\n          app: {{ .Release.Name }}-nginx\n      spec:\n        containers:\n        - name: nginx\n          image: \"{{ .Values.image.repository }}:{{ .Values.image.tag }}\"\n  ```\n\n**6. Helm Lifecycle:**\n\n- **Creating a New Chart:**\n\n  ```bash\n  helm create my-chart\n  ```\n\n- **Templating:**\n  - **List all template values:**\n\n    ```bash\n    helm template my-release my-chart\n    ```\n  \n  - **Lint a Chart:**\n\n    ```bash\n    helm lint my-chart\n    ```\n\n**7. Helm Repositories:**\n\n- **Creating a Local Helm Repository:**\n\n  ```bash\n  helm repo index ./charts --url http://example.com/charts\n  ```\n  \n- **Serving Charts:**\n\n  ```bash\n  helm serve --address 0.0.0.0:8879\n  ```\n\n**8. Helm Hooks:**\n\n- **Example of a Pre-Install Hook:**\n\n  ```yaml\n  apiVersion: batch/v1\n  kind: Job\n  metadata:\n    name: \"{{ .Release.Name }}-preinstall\"\n    annotations:\n      \"helm.sh/hook\": pre-install\n  spec:\n    template:\n      spec:\n        containers:\n        - name: preinstall\n          image: busybox\n          command: ['sh', '-c', 'echo Hello Helm']\n        restartPolicy: Never\n  ```\n\n**9. Helm and CI/CD:**\n\n- **Using Helm in Jenkins Pipeline:**\n\n  ```groovy\n  pipeline {\n    agent any\n    stages {\n      stage('Deploy') {\n        steps {\n          script {\n            sh \"helm upgrade --install my-release ./my-chart\"\n          }\n        }\n      }\n    }\n  }\n  ```\n\n**10. Advanced Helm Concepts:**\n\n- **Subcharts:** Use subcharts to package related Kubernetes resources together.\n- **Chart Museum:** Helm repository server to store and manage Helm charts.\n- **Helmfile:** A declarative spec for deploying Helm charts.\n\n**11. Helm Security:**\n\n- **Chart Signing:**\n  - Sign and verify Helm charts to ensure integrity.\n\n  ```bash\n  helm package --sign --key <key> --keyring <keyring> my-chart\n  helm verify my-chart-0.1.0.tgz\n  ```\n\n- **RBAC:** Control access to Helm releases with Kubernetes RBAC.\n\n**12. Troubleshooting Helm:**\n\n- **Debugging a Chart Installation:**\n\n  ```bash\n  helm install --debug --dry-run my-release ./my-chart\n  ```\n\n- **Checking Helm Release History:**\n\n  ```bash\n  helm history my-release\n  ```\n\n- **Rollback a Release:**\n\n  ```bash\n  helm rollback my-release 1\n  ```\n",
  "Containerization/Kubernetes": "# Kubernetes Cheatsheet\n\n![text](https://imgur.com/aYuSIvY.png)\n\n## Checkout detailed article on [Dev.to](https://dev.to/prodevopsguytech/kubernetes-commands-for-devops-engineers-124o)\n\n## 1. Introduction to Kubernetes\n\n### What is Kubernetes?\n\n- **Kubernetes** is an open-source container orchestration platform that automates the deployment, scaling, and management of containerized applications.\n\n### Key Concepts\n\n- **Cluster**: A set of worker machines, called nodes, that run containerized applications.\n- **Node**: A single machine in a Kubernetes cluster.\n- **Pod**: The smallest deployable unit, which can contain one or more containers.\n- **Service**: A stable network endpoint to expose a set of pods.\n- **Namespace**: A way to divide cluster resources between multiple users.\n- **Kubelet**: An agent running on each node that ensures containers are running in a Pod.\n- **Kubectl**: Command-line tool to interact with Kubernetes clusters.\n\n---\n\n## 2. Basic Kubernetes Operations\n\n### Setting Up a Kubernetes Cluster\n\n- **Minikube**: Set up a single-node Kubernetes cluster for testing.\n\n  ```bash\n  minikube start\n  ```\n\n### Working with `kubectl`\n\n- **Get Cluster Information**:\n\n  ```bash\n  kubectl cluster-info\n  ```\n\n- **Get All Nodes in the Cluster**:\n\n  ```bash\n  kubectl get nodes\n  ```\n\n### Managing Pods\n\n- **Create a Pod**:\n\n  ```bash\n  kubectl run mypod --image=nginx\n  ```\n\n- **List All Pods**:\n\n  ```bash\n  kubectl get pods\n  ```\n\n- **Describe a Pod**:\n\n  ```bash\n  kubectl describe pod mypod\n  ```\n\n- **Delete a Pod**:\n\n  ```bash\n  kubectl delete pod mypod\n  ```\n\n### Using Namespaces\n\n- **List All Namespaces**:\n\n  ```bash\n  kubectl get namespaces\n  ```\n\n- **Create a Namespace**:\n\n  ```bash\n  kubectl create namespace mynamespace\n  ```\n\n- **Delete a Namespace**:\n\n  ```bash\n  kubectl delete namespace mynamespace\n  ```\n\n---\n\n## 3. Deployments and Scaling\n\n### Deployments\n\n- **Create a Deployment**:\n\n  ```bash\n  kubectl create deployment myapp --image=nginx\n  ```\n\n- **View Deployment Status**:\n\n  ```bash\n  kubectl get deployments\n  ```\n\n- **Update a Deployment**:\n\n  ```bash\n  kubectl set image deployment/myapp nginx=nginx:1.16\n  ```\n\n- **Rollback a Deployment**:\n\n  ```bash\n  kubectl rollout undo deployment/myapp\n  ```\n\n### Scaling Applications\n\n- **Scale a Deployment**:\n\n  ```bash\n  kubectl scale deployment myapp --replicas=3\n  ```\n\n- **Auto-scaling with Horizontal Pod Autoscaler (HPA)**:\n\n  ```bash\n  kubectl autoscale deployment myapp --min=1 --max=5 --cpu-percent=80\n  ```\n\n---\n\n## 4. Services and Networking\n\n### Services\n\n- **Expose a Pod with a Service**:\n\n  ```bash\n  kubectl expose pod mypod --port=80 --target-port=8080\n  ```\n\n- **Create a Service for a Deployment**:\n\n  ```bash\n  kubectl expose deployment myapp --type=NodePort --port=80\n  ```\n\n- **List All Services**:\n\n  ```bash\n  kubectl get services\n  ```\n\n### Networking\n\n- **Understanding Cluster Networking**: Kubernetes abstracts network communication between Pods.\n- **Network Policies**: Restrict Pod communication using Network Policies.\n\n  ```yaml\n  apiVersion: networking.k8s.io/v1\n  kind: NetworkPolicy\n  metadata:\n    name: mynetworkpolicy\n    namespace: mynamespace\n  spec:\n    podSelector:\n      matchLabels:\n        role: db\n    policyTypes:\n    - Ingress\n    - Egress\n    ingress:\n    - from:\n      - podSelector:\n          matchLabels:\n            role: frontend\n    egress:\n    - to:\n      - podSelector:\n          matchLabels:\n            role: backend\n  ```\n\n---\n\n## 5. Persistent Storage\n\n### Volumes\n\n- **Create a Persistent Volume**:\n\n  ```yaml\n  apiVersion: v1\n  kind: PersistentVolume\n  metadata:\n    name: mypv\n  spec:\n    capacity:\n      storage: 1Gi\n    accessModes:\n      - ReadWriteOnce\n    hostPath:\n      path: \"/mnt/data\"\n  ```\n\n- **Create a Persistent Volume Claim**:\n\n  ```yaml\n  apiVersion: v1\n  kind: PersistentVolumeClaim\n  metadata:\n    name: mypvc\n  spec:\n    accessModes:\n      - ReadWriteOnce\n    resources:\n      requests:\n        storage: 1Gi\n  ```\n\n### StorageClasses\n\n- **Create a StorageClass**:\n\n  ```yaml\n  apiVersion: storage.k8s.io/v1\n  kind: StorageClass\n  metadata:\n    name: mystorageclass\n  provisioner: kubernetes.io/aws-ebs\n  parameters:\n    type: gp2\n  ```\n\n---\n\n## 6. ConfigMaps and Secrets\n\n### ConfigMaps\n\n- **Create a ConfigMap from a File**:\n\n  ```bash\n  kubectl create configmap myconfig --from-file=config.txt\n  ```\n\n- **View a ConfigMap**:\n\n  ```bash\n  kubectl get configmap myconfig -o yaml\n  ```\n\n- **Use a ConfigMap in a Pod**:\n\n  ```yaml\n  apiVersion: v1\n  kind: Pod\n  metadata:\n    name: mypod\n  spec:\n    containers:\n    - name: mycontainer\n      image: nginx\n      envFrom:\n      - configMapRef:\n          name: myconfig\n  ```\n\n### Secrets\n\n- **Create a Secret from a Literal Value**:\n\n  ```bash\n  kubectl create secret generic mysecret --from-literal=username=admin\n  ```\n\n- **View a Secret**:\n\n  ```bash\n  kubectl get secret mysecret -o yaml\n  ```\n\n- **Use a Secret in a Pod**:\n\n  ```yaml\n  apiVersion: v1\n  kind: Pod\n  metadata:\n    name: mypod\n  spec:\n    containers:\n    - name: mycontainer\n      image: nginx\n      envFrom:\n      - secretRef:\n          name: mysecret\n  ```\n\n---\n\n## 7. Ingress Controllers\n\n### Setting Up Ingress\n\n- **Install an Ingress Controller**: Use a Helm chart or YAML manifest to install an ingress controller (e.g., NGINX Ingress Controller).\n\n  ```bash\n  kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/cloud/deploy.yaml\n  ```\n\n### Configuring Ingress Resources\n\n- **Create an Ingress Resource**:\n\n  ```yaml\n  apiVersion: networking.k8s.io/v1\n  kind: Ingress\n  metadata:\n    name: myingress\n  spec:\n    rules:\n    - host: myapp.example.com\n      http:\n        paths:\n        - path: /\n          pathType: Prefix\n          backend:\n            service:\n              name: myapp-service\n              port:\n                number: 80\n  ```\n\n- **TLS Termination with Ingress**:\n\n  ```yaml\n  apiVersion: networking.k8s.io/v1\n  kind: Ingress\n  metadata:\n    name: myingress\n  spec:\n    tls:\n    - hosts:\n      - myapp.example.com\n      secretName: mytlssecret\n    rules:\n    - host: myapp.example.com\n      http:\n        paths:\n        - path: /\n          pathType: Prefix\n          backend:\n            service:\n              name: myapp-service\n              port:\n                number: 80\n  ```\n\n---\n\n## 8. Kubernetes Security\n\n### Role-Based Access Control (RBAC)\n\n- **Create a Role**:\n\n  ```yaml\n  apiVersion: rbac.authorization.k8s.io/v1\n  kind: Role\n  metadata:\n    namespace: mynamespace\n    name: myrole\n  rules:\n  - apiGroups: [\"\"]\n    resources: [\"pods\"]\n    verbs: [\"get\", \"watch\", \"list\"]\n  ```\n\n- **Bind a Role to a User**:\n\n  ```yaml\n  apiVersion: rbac.authorization.k8s.io/v1\n  kind: RoleBinding\n  metadata:\n    name: myrolebinding\n    namespace: mynamespace\n  subjects:\n  - kind: User\n    name: myuser\n    apiGroup: rbac.authorization.k8s.io\n  roleRef:\n    kind: Role\n    name: myrole\n    apiGroup: rbac.authorization.k8s.io\n  ```\n\n### Pod Security Policies (PSP)\n\n- **Create a PSP**:\n\n  ```yaml\n  apiVersion: policy/v1beta1\n  kind: PodSecurityPolicy\n  metadata:\n    name: mypsp\n  spec:\n    privileged: false\n    seLinux:\n      rule: RunAsAny\n    supplementalGroups:\n      rule: RunAsAny\n    runAsUser:\n      rule: RunAsAny\n    fsGroup:\n      rule: RunAsAny\n    volumes:\n    - '*'\n  ```\n\n### Network Policies\n\n- **Create a Network Policy**:\n\n  ```yaml\n  apiVersion: networking.k8s.io/v1\n  kind: NetworkPolicy\n  metadata:\n    name: allow-db\n    namespace: mynamespace\n  spec:\n    podSelector:\n      matchLabels:\n        role: db\n    policyTypes:\n\n\n    - Ingress\n    ingress:\n    - from:\n      - podSelector:\n          matchLabels:\n            role: frontend\n  ```\n\n### Securing Kubernetes API Server\n\n- **Enable API Server Auditing**:\n  - Edit the API server manifest to include auditing options.\n\n  ```yaml\n  - --audit-log-path=/var/log/kubernetes/audit.log\n  - --audit-policy-file=/etc/kubernetes/audit-policy.yaml\n  ```\n\n---\n\n## 9. Advanced Kubernetes\n\n### Custom Resource Definitions (CRDs)\n\n- **Create a Custom Resource Definition**:\n\n  ```yaml\n  apiVersion: apiextensions.k8s.io/v1\n  kind: CustomResourceDefinition\n  metadata:\n    name: myresources.example.com\n  spec:\n    group: example.com\n    versions:\n    - name: v1\n      served: true\n      storage: true\n      schema:\n        openAPIV3Schema:\n          type: object\n          properties:\n            spec:\n              type: object\n    scope: Namespaced\n    names:\n      plural: myresources\n      singular: myresource\n      kind: MyResource\n      shortNames:\n      - mr\n  ```\n\n### Operators\n\n- **Introduction to Operators**: Operators are Kubernetes applications designed to manage complex stateful applications by extending the Kubernetes API.\n- **Creating an Operator**:\n  - Use the Operator SDK to scaffold and build an operator.\n\n  ```bash\n  operator-sdk init --domain=example.com --repo=github.com/example/memcached-operator\n  operator-sdk create api --group=cache --version=v1 --kind=Memcached --resource --controller\n  ```\n\n### Service Mesh with Istio\n\n- **Install Istio**:\n\n  ```bash\n  istioctl install --set profile=demo\n  ```\n\n- **Deploy an Application with Istio**:\n  - Annotate namespace to enable Istio sidecar injection.\n\n  ```bash\n  kubectl label namespace mynamespace istio-injection=enabled\n  ```\n\n  - Deploy application in the annotated namespace.\n- **Traffic Management with Istio**:\n  - Create VirtualService and DestinationRule to manage traffic routing.\n\n  ```yaml\n  apiVersion: networking.istio.io/v1alpha3\n  kind: VirtualService\n  metadata:\n    name: myapp\n  spec:\n    hosts:\n    - myapp.example.com\n    http:\n    - route:\n      - destination:\n          host: myapp\n          subset: v1\n  ```\n  \n### Monitoring and Logging\n\n- **Prometheus and Grafana**:\n  - **Install Prometheus**:\n\n    ```bash\n    kubectl apply -f https://github.com/prometheus-operator/prometheus-operator/blob/main/bundle.yaml\n    ```\n\n  - **Install Grafana**:\n\n    ```bash\n    kubectl apply -f https://raw.githubusercontent.com/grafana/grafana/main/deploy/kubernetes/grafana-deployment.yaml\n    ```\n\n  - **View Metrics in Grafana**: Access the Grafana dashboard and configure data sources to use Prometheus.\n\n- **Logging with ELK Stack**:\n  - **Deploy ELK Stack**: Use Helm or custom YAML manifests to deploy Elasticsearch, Logstash, and Kibana.\n\n    ```bash\n    helm install elk-stack stable/elastic-stack\n    ```\n\n  - **Configure Fluentd for Log Collection**:\n    - Deploy Fluentd as a DaemonSet to collect logs from all nodes and send them to Elasticsearch.\n\n### High Availability and Disaster Recovery\n\n- **Kubernetes High Availability (HA)**:\n  - **HA Master Nodes**: Set up multiple master nodes to ensure availability.\n  - **HA etcd Cluster**: Use an HA etcd cluster to store Kubernetes state with redundancy.\n\n- **Disaster Recovery**:\n  - **Backup and Restore etcd**:\n    - Use `etcdctl` to take snapshots of the etcd cluster.\n\n    ```bash\n    etcdctl snapshot save /path/to/backup\n    ```\n\n    - Restore from the snapshot when needed.\n\n### Federation\n\n- **Multi-Cluster Federation**:\n  - **Set Up Federation**: Use Kubernetes Federation v2 to manage multiple clusters from a single control plane.\n\n  ```bash\n  kubefedctl join mycluster --cluster-context=mycluster-context --host-cluster-context=host-cluster-context\n  ```\n\n  - **Deploy Federated Resources**: Deploy resources that span across multiple clusters using the Federation API.\n\n---\n\n## 10. References\n\n### Official Documentation\n\n- [Kubernetes Official Documentation](https://kubernetes.io/docs/)\n\n### Community Resources\n\n- [Kubernetes Slack](http://slack.k8s.io/)\n- [Kubernetes GitHub Repository](https://github.com/kubernetes/kubernetes)\n- [Kubernetes Blog](https://kubernetes.io/blog/)\n",
  "Containerization/OpenShift": "# OpenShift Cheatsheet\n\n![text](https://imgur.com/2HuS6vE.png)\n\n## Table of Contents\n\n1. **Introduction to OpenShift**\n   - What is OpenShift?\n   - Key Features\n   - OpenShift Editions\n   - Architecture Overview\n2. **Installation and Setup**\n   - System Requirements\n   - Installing OpenShift\n   - Setting Up OpenShift CLI (`oc`)\n   - Post-Installation Configuration\n3. **Basic Concepts**\n   - Projects and Namespaces\n   - Pods, Services, and Routes\n   - Deployments and DeploymentConfigs\n   - StatefulSets and DaemonSets\n   - OpenShift Builds and ImageStreams\n   - ConfigMaps and Secrets\n4. **User Management**\n   - Creating and Managing Users\n   - Role-Based Access Control (RBAC)\n   - Service Accounts\n   - Managing Quotas and Limits\n5. **Networking**\n   - OpenShift SDN Overview\n   - Ingress and Egress Traffic Management\n   - Configuring Routes and DNS\n   - NetworkPolicies for Pod Security\n6. **Storage**\n   - Persistent Volumes and Persistent Volume Claims\n   - StorageClasses and Dynamic Provisioning\n   - Managing Storage for Stateful Applications\n   - NFS and GlusterFS Integration\n7. **Security**\n   - OpenShift Security Context Constraints (SCCs)\n   - Using SELinux with OpenShift\n   - Securing Routes with TLS\n   - OpenShift Compliance and Security Audits\n8. **Application Lifecycle Management**\n   - Creating Applications using `oc new-app`\n   - Managing Application Deployments\n   - Rolling Updates and Rollbacks\n   - Blue-Green and Canary Deployments\n9. **Monitoring and Logging**\n   - Monitoring with Prometheus and Grafana\n   - Logging with Elasticsearch, Fluentd, and Kibana (EFK)\n   - Setting Up Alerts and Notifications\n   - Debugging Pods and Containers\n10. **Advanced Configuration**\n    - Customizing OpenShift Templates\n    - Managing Resources with Limits and Requests\n    - Configuring Auto-scaling with Horizontal Pod Autoscalers (HPA)\n    - Customizing OpenShift SDN\n11. **CI/CD Pipelines**\n    - OpenShift Pipelines with Tekton\n    - Integrating Jenkins with OpenShift\n    - Automating Builds with BuildConfigs\n    - Continuous Delivery Strategies\n12. **OpenShift Service Mesh**\n    - Introduction to Istio and Service Mesh\n    - Configuring OpenShift Service Mesh\n    - Traffic Management with Istio\n    - Monitoring and Tracing with Kiali and Jaeger\n13. **Serverless Computing**\n    - OpenShift Serverless Overview\n    - Deploying Serverless Applications with Knative\n    - Autoscaling Serverless Functions\n14. **Hybrid Cloud and Multi-Cloud Deployments**\n    - OpenShift 4.x Hybrid Cloud Capabilities\n    - Deploying OpenShift Across Multiple Clouds\n    - Managing Multi-Cluster Deployments with ACM\n15. **Troubleshooting and Best Practices**\n    - Common Issues and Fixes\n    - Best Practices for OpenShift Operations\n    - Performance Tuning\n16. **FAQs**\n    - Common Questions about OpenShift\n17. **References**\n    - Official Documentation\n    - Community Resources\n\n---\n\n## 1. Introduction to OpenShift\n\n### What is OpenShift?\n\n- **OpenShift** is an enterprise Kubernetes platform developed by Red Hat, offering container orchestration, DevOps tools, and a robust ecosystem for developing, deploying, and managing applications at scale.\n\n### Key Features\n\n- **Integrated Developer Tools**: Supports CI/CD pipelines, source-to-image (S2I) builds, and developer environments.\n- **Enterprise Security**: Includes role-based access control (RBAC), network policies, and Security Context Constraints (SCCs).\n- **Scalability**: Auto-scaling features for applications and clusters.\n- **Multi-cloud and Hybrid Cloud**: Deploy and manage applications across multiple cloud environments.\n\n### OpenShift Editions\n\n- **OpenShift Container Platform (OCP)**: The full-featured enterprise version.\n- **OpenShift Online**: Managed OpenShift service hosted by Red Hat.\n- **OpenShift Dedicated**: A managed version of OpenShift Container Platform.\n- **OKD (OpenShift Kubernetes Distribution)**: The open-source, community-supported version.\n\n### Architecture Overview\n\n- **Master Nodes**: Handle API requests, manage the cluster state, and schedule workloads.\n- **Worker Nodes**: Run the containerized applications, managed by the master nodes.\n- **etcd**: A distributed key-value store that holds the cluster state.\n- **SDN**: OpenShift Software-Defined Networking for managing networking.\n\n---\n\n## 2. Installation and Setup\n\n### System Requirements\n\n- **Operating System**: RHEL, CentOS, or Fedora.\n- **Memory**: Minimum 16 GB RAM for a single-node installation.\n- **Storage**: At least 50 GB of disk space.\n- **CPU**: 4 cores or more.\n\n### Installing OpenShift\n\n- **Single-node Cluster (CodeReady Containers)**:\n\n  ```bash\n  crc setup\n  crc start\n  ```\n\n- **Multi-node Cluster (OpenShift Installer)**:\n\n  ```bash\n  openshift-install create cluster\n  ```\n\n### Setting Up OpenShift CLI (`oc`)\n\n- **Install `oc` CLI**:\n\n  ```bash\n  sudo dnf install -y openshift-clients\n  ```\n\n- **Login to Cluster**:\n\n  ```bash\n  oc login https://<master-url>:6443 --token=<token>\n  ```\n\n### Post-Installation Configuration\n\n- **Verify Installation**:\n\n  ```bash\n  oc status\n  ```\n\n- **Set up Default Project**:\n\n  ```bash\n  oc new-project <project-name>\n  ```\n\n---\n\n## 3. Basic Concepts\n\n### Projects and Namespaces\n\n- **Create a New Project**:\n\n  ```bash\n  oc new-project myproject\n  ```\n\n- **Switch Project**:\n\n  ```bash\n  oc project myproject\n  ```\n\n### Pods, Services, and Routes\n\n- **Create a Pod**:\n\n  ```bash\n  oc run myapp --image=myimage\n  ```\n\n- **Expose a Service**:\n\n  ```bash\n  oc expose pod myapp --port=8080\n  ```\n\n- **Create a Route**:\n\n  ```bash\n  oc expose service myapp\n  ```\n\n### Deployments and DeploymentConfigs\n\n- **Create a Deployment**:\n\n  ```bash\n  oc create deployment myapp --image=myimage\n  ```\n\n- **Update a Deployment**:\n\n  ```bash\n  oc set image deployment/myapp myapp=mynewimage\n  ```\n\n### StatefulSets and DaemonSets\n\n- **Create a StatefulSet**:\n\n  ```bash\n  oc create -f statefulset.yaml\n  ```\n\n- **Create a DaemonSet**:\n\n  ```bash\n  oc create daemonset myds --image=mydaemonimage\n  ```\n\n### OpenShift Builds and ImageStreams\n\n- **Start a Build**:\n\n  ```bash\n  oc start-build mybuild\n  ```\n\n- **Create an ImageStream**:\n\n  ```bash\n  oc create imagestream myimage\n  ```\n\n### ConfigMaps and Secrets\n\n- **Create a ConfigMap**:\n\n  ```bash\n  oc create configmap myconfig --from-file=config.yaml\n  ```\n\n- **Create a Secret**:\n\n  ```bash\n  oc create secret generic mysecret --from-literal=password=secret\n  ```\n\n---\n\n## 4. User Management\n\n### Creating and Managing Users\n\n- **Create a New User**:\n\n  ```bash\n  oc create user myuser\n  ```\n\n- **Assign a User to a Project**:\n\n  ```bash\n  oc adm policy add-role-to-user admin myuser -n myproject\n  ```\n\n### Role-Based Access Control (RBAC)\n\n- **Create a Role**:\n\n  ```bash\n  oc create role myrole --verb=get --verb=list --resource=pods\n  ```\n\n- **Assign a Role to a User**:\n\n  ```bash\n  oc adm policy add-role-to-user myrole myuser -n myproject\n  ```\n\n### Service Accounts\n\n- **Create a Service Account**:\n\n  ```bash\n  oc create serviceaccount myserviceaccount\n  ```\n\n- **Assign a Role to a Service Account**:\n\n  ```bash\n  oc adm policy add-cluster-role-to-user cluster-admin -z myserviceaccount\n  ```\n\n### Managing Quotas and Limits\n\n- **Create a Resource Quota**:\n\n  ```bash\n  oc create quota myquota --hard=cpu=2,memory=4Gi -n myproject\n  ```\n\n- **Set Limits for a Project**:\n\n  ```bash\n  oc create limitrange mylimits --default=cpu=500m,memory=1Gi -n myproject\n  ```\n\n---\n\n## 5. Networking\n\n### OpenShift SDN Overview\n\n- **Default Network**: OpenShift uses the OpenShift SDN by default, which provides networking capabilities to connect pods and services.\n\n### Ingress and Egress Traffic Management\n\n- **Create an Ingress Rule**:\n\n  ```bash\n  oc create route edge myroute --service=myservice --hostname=myapp.example.com\n  ```\n\n### Configuring Routes and DNS\n\n- **Create a Route**:\n\n  ```bash\n  oc expose service myservice --hostname=myapp.example.com\n  ```\n\n- **Check Route Status**:\n\n  ```bash\n  oc get routes\n  ```\n\n### NetworkPolicies for Pod Security\n\n- **Create a NetworkPolicy**:\n\n  ```bash\n  oc create -f networkpolicy.yaml\n  ```\n\n---\n\n## 6\n\n. Storage\n\n### Persistent Volumes and Persistent Volume Claims\n\n- **Create a Persistent Volume**:\n\n  ```bash\n  oc create -f persistentvolume.yaml\n  ```\n\n- **Create a Persistent Volume Claim**:\n\n  ```bash\n  oc create -f persistentvolumeclaim.yaml\n  ```\n\n### StorageClasses and Dynamic Provisioning\n\n- **Create a StorageClass**:\n\n  ```bash\n  oc create -f storageclass.yaml\n  ```\n\n- **Use Dynamic Provisioning**: OpenShift can automatically provision storage based on the StorageClass.\n\n### Managing Storage for Stateful Applications\n\n- **Assign a Persistent Volume to a StatefulSet**:\n\n  ```yaml\n  volumeClaimTemplates:\n  - metadata:\n      name: myvolume\n    spec:\n      accessModes: [\"ReadWriteOnce\"]\n      storageClassName: \"mystorageclass\"\n      resources:\n        requests:\n          storage: 1Gi\n  ```\n\n### NFS and GlusterFS Integration\n\n- **Use NFS**: Set up NFS as a storage backend and create PersistentVolumes with NFS settings.\n- **Use GlusterFS**: Deploy a GlusterFS cluster and configure OpenShift to use it as a storage backend.\n\n---\n\n## 7. Security\n\n### OpenShift Security Context Constraints (SCCs)\n\n- **View Available SCCs**:\n\n  ```bash\n  oc get scc\n  ```\n\n- **Assign an SCC to a Service Account**:\n\n  ```bash\n  oc adm policy add-scc-to-user privileged -z myserviceaccount -n myproject\n  ```\n\n### Using SELinux with OpenShift\n\n- **Enable SELinux**:\n\n  ```bash\n  setenforce 1\n  ```\n\n- **Configure SELinux for OpenShift**: Ensure the correct SELinux policies are in place for OpenShift.\n\n### Securing Routes with TLS\n\n- **Create a TLS Route**:\n\n  ```bash\n  oc create route edge myroute --service=myservice --cert=tls.crt --key=tls.key --ca-cert=ca.crt\n  ```\n\n### OpenShift Compliance and Security Audits\n\n- **Run a Security Scan**:\n\n  ```bash\n  oc adm diagnostics security\n  ```\n\n- **Compliance Operator**: Use OpenShift's Compliance Operator to automate security compliance checks.\n\n---\n\n## 8. Application Lifecycle Management\n\n### Creating Applications using `oc new-app`\n\n- **Create an Application from a Git Repository**:\n\n  ```bash\n  oc new-app https://github.com/myorg/myrepo.git --name=myapp\n  ```\n\n### Managing Application Deployments\n\n- **Create a DeploymentConfig**:\n\n  ```bash\n  oc create -f deploymentconfig.yaml\n  ```\n\n- **Trigger a New Deployment**:\n\n  ```bash\n  oc rollout latest dc/myapp\n  ```\n\n### Rolling Updates and Rollbacks\n\n- **Perform a Rolling Update**:\n\n  ```bash\n  oc set image dc/myapp myapp=mynewimage\n  ```\n\n- **Rollback to a Previous Version**:\n\n  ```bash\n  oc rollout undo dc/myapp\n  ```\n\n### Blue-Green and Canary Deployments\n\n- **Blue-Green Deployment**: Create two separate environments (blue and green) and switch traffic between them using routes.\n- **Canary Deployment**: Gradually shift traffic to a new version using multiple routes and services.\n\n---\n\n## 9. Monitoring and Logging\n\n### Monitoring with Prometheus and Grafana\n\n- **Access Prometheus**: Typically available at `<openshift-master>:9090`.\n- **Access Grafana**: Access via the OpenShift Web Console under Monitoring > Dashboards.\n\n### Logging with Elasticsearch, Fluentd, and Kibana (EFK)\n\n- **View Logs in Kibana**: Access Kibana via the OpenShift Web Console.\n- **Search Logs**:\n\n  ```bash\n  oc logs -f <pod-name>\n  ```\n\n### Setting Up Alerts and Notifications\n\n- **Configure Alerts in Prometheus**: Set up alerting rules in Prometheus.\n- **Integrate with Notification Channels**: Use Alertmanager to send notifications to channels like Slack, email, etc.\n\n### Debugging Pods and Containers\n\n- **Get Pod Logs**:\n\n  ```bash\n  oc logs <pod-name>\n  ```\n\n- **Execute Commands in a Running Pod**:\n\n  ```bash\n  oc exec -it <pod-name> -- /bin/bash\n  ```\n\n---\n\n## 10. Advanced Configuration\n\n### Customizing OpenShift Templates\n\n- **Create a New Template**:\n\n  ```bash\n  oc create -f template.yaml\n  ```\n\n- **Instantiate a Template**:\n\n  ```bash\n  oc process -f template.yaml | oc create -f -\n  ```\n\n### Managing Resources with Limits and Requests\n\n- **Set Resource Limits**:\n\n  ```yaml\n  resources:\n    requests:\n      memory: \"64Mi\"\n      cpu: \"250m\"\n    limits:\n      memory: \"128Mi\"\n      cpu: \"500m\"\n  ```\n\n### Configuring Auto-scaling with Horizontal Pod Autoscalers (HPA)\n\n- **Create an HPA**:\n\n  ```bash\n  oc autoscale dc/myapp --min=1 --max=10 --cpu-percent=80\n  ```\n\n### Customizing OpenShift SDN\n\n- **Configure SDN**: Modify the SDN configuration through the OpenShift Web Console or by editing the SDN-related resources.\n\n---\n\n## 11. CI/CD Pipelines\n\n### OpenShift Pipelines with Tekton\n\n- **Install Tekton**:\n\n  ```bash\n  oc apply -f tekton-pipelines.yaml\n  ```\n\n- **Create a Tekton Pipeline**:\n\n  ```bash\n  oc create -f pipeline.yaml\n  ```\n\n### Integrating Jenkins with OpenShift\n\n- **Deploy Jenkins**:\n\n  ```bash\n  oc new-app jenkins-ephemeral\n  ```\n\n- **Create a Jenkins Pipeline**:\n\n  ```bash\n  oc create -f jenkins-pipeline.yaml\n  ```\n\n### Automating Builds with BuildConfigs\n\n- **Create a BuildConfig**:\n\n  ```bash\n  oc create -f buildconfig.yaml\n  ```\n\n- **Trigger a Build**:\n\n  ```bash\n  oc start-build mybuildconfig\n  ```\n\n### Continuous Delivery Strategies\n\n- **Implement CI/CD with Jenkins**: Create pipelines in Jenkins integrated with OpenShift to manage the full application lifecycle.\n- **Use Tekton for GitOps**: Automate deployments using GitOps principles with Tekton pipelines.\n\n---\n\n## 12. OpenShift Service Mesh\n\n### Introduction to Istio and Service Mesh\n\n- **Service Mesh Overview**: OpenShift Service Mesh is based on Istio, providing traffic management, security, and observability for microservices.\n\n### Configuring OpenShift Service Mesh\n\n- **Install Service Mesh Components**:\n\n  ```bash\n  oc apply -f servicemesh-install.yaml\n  ```\n\n- **Create a Service Mesh Control Plane**:\n\n  ```bash\n  oc apply -f controlplane.yaml\n  ```\n\n### Traffic Management with Istio\n\n- **Create a VirtualService**:\n\n  ```bash\n  oc create -f virtualservice.yaml\n  ```\n\n- **Configure Traffic Splitting**:\n\n  ```yaml\n  http:\n  - route:\n    - destination:\n        host: myservice\n        subset: v1\n      weight: 50\n    - destination:\n        host: myservice\n        subset: v2\n      weight: 50\n  ```\n\n### Monitoring and Tracing with Kiali and Jaeger\n\n- **Access Kiali**: Typically available via the OpenShift Web Console under the Service Mesh section.\n- **Use Jaeger for Tracing**: View distributed traces for microservices in Jaeger.\n\n---\n\n## 13. Serverless Computing\n\n### OpenShift Serverless Overview\n\n- **Knative on OpenShift**: OpenShift Serverless is built on Knative, providing serverless capabilities for deploying functions and apps that scale to zero.\n\n### Deploying Serverless Applications with Knative\n\n- **Create a Knative Service**:\n\n  ```bash\n  oc create -f knative-service.yaml\n  ```\n\n### Autoscaling Serverless Functions\n\n- **Configure Autoscaling**:\n\n  ```yaml\n  spec:\n    autoscaler:\n      minReplicas: 1\n      maxReplicas: 5\n  ```\n\n---\n\n## 14. Hybrid Cloud and Multi-Cloud Deployments\n\n### OpenShift 4.x Hybrid Cloud Capabilities\n\n- **Deploy on Multiple Clouds**: OpenShift supports deployment across AWS, Azure, GCP, and on-premise environments.\n\n### Deploying OpenShift Across Multiple Clouds\n\n- **Use Red Hat Advanced Cluster Management (ACM)**: Manage multiple OpenShift clusters across different environments.\n- **Configure Multi-Cloud Deployments**: Use ACM to deploy applications across multiple OpenShift clusters.\n\n### Managing Multi-Cluster Deployments with ACM\n\n- **Install ACM**:\n\n  ```bash\n  oc apply -f acm-install.yaml\n  ```\n\n- **Manage Multiple Clusters**: Use ACM to oversee the health, configuration, and workload management across multiple clusters.\n\n---\n\n## 15. Troubleshooting and Best Practices\n\n### Common Issues and Fixes\n\n- **Debugging Pods**:\n\n  ```bash\n  oc describe pod <pod-name>\n  ```\n\n- **Network Issues**: Check the status of routes and network policies.\n\n### Best Practices for OpenShift Operations\n\n- **Use RBAC**: Ensure role-based access control is correctly implemented to limit access.\n- **Monitor Resource Usage**: Use monitoring tools to keep an eye on resource usage and scaling needs.\n\n### Performance Tuning\n\n- **Optimize Resource Requests and Limits**: Set appropriate limits and requests for CPU and memory to avoid over-provisioning.\n- **Tune SDN**: Adjust SDN configurations for optimal network performance.\n\n---\n\n## 16. FAQs\n\n\n\n### Common Questions about OpenShift\n\n- **What is the difference between OpenShift and Kubernetes?**\n  - OpenShift is an enterprise Kubernetes platform with additional features like integrated CI/CD, developer tools, and enterprise security.\n\n- **How do I upgrade OpenShift?**\n  - Upgrading OpenShift involves using the OpenShift CLI or the Web Console to initiate a cluster upgrade.\n\n---\n\n## 17. References\n\n### Official Documentation\n\n- [OpenShift Documentation](https://docs.openshift.com/)\n- [Red Hat OpenShift Blog](https://cloud.redhat.com/blog/)\n\n### Community Resources\n\n- [OpenShift Commons](https://commons.openshift.org/)\n- [Red Hat Developer](https://developers.redhat.com/)\n",
  "Containerization/Podman": "# Podman Cheatsheet\n\n![text](https://imgur.com/6x1bZIJ.png)\n\n**1. Introduction:**\n\n- **Podman** is an open-source container engine that performs much like Docker but without the daemon dependency. It supports the Open Container Initiative (OCI) standards for both containers and container images.\n\n**2. Key Concepts:**\n\n- **Pod:** A group of containers that run together and share resources, similar to a Kubernetes Pod.\n- **Rootless Containers:** Podman can run containers as a non-root user.\n- **Docker Compatibility:** Podman commands are similar to Docker, making it easy to switch between the two.\n\n**3. Installation:**\n\n- **On Fedora:**\n\n  ```bash\n  sudo dnf install podman\n  ```\n  \n- **On Ubuntu:**\n\n  ```bash\n  sudo apt-get -y install podman\n  ```\n\n**4. Basic Podman Commands:**\n\n- **Run a Container:**\n\n  ```bash\n  podman run -dt -p 8080:80 nginx\n  ```\n  \n- **List Running Containers:**\n\n  ```bash\n  podman ps\n  ```\n  \n- **Stop a Container:**\n\n  ```bash\n  podman stop container_id\n  ```\n  \n- **Remove a Container:**\n\n  ```bash\n  podman rm container_id\n  ```\n\n- **Build an Image:**\n\n  ```bash\n  podman build -t my-image:latest .\n  ```\n\n**5. Podman vs Docker:**\n\n- **No Daemon:** Podman does not rely on a central daemon; each container is an isolated process.\n- **Rootless Mode:** Allows running containers without root privileges, enhancing security.\n- **Podman Pods:** Group containers under a single network namespace.\n\n**6. Pods in Podman:**\n\n- **Create a Pod:**\n\n  ```bash\n  podman pod create --name mypod -p 8080:80\n  ```\n  \n- **Run a Container in a Pod:**\n\n  ```bash\n  podman run -dt --pod mypod nginx\n  ```\n\n- **Inspect a Pod:**\n\n  ```bash\n  podman pod inspect mypod\n  ```\n\n- **Stop a Pod:**\n\n  ```bash\n  podman pod stop mypod\n  ```\n\n**7. Networking:**\n\n- **Podman Network Command:**\n\n  ```bash\n  podman network create mynetwork\n  ```\n\n- **Attaching a Container to a Network:**\n\n  ```bash\n  podman run -dt --network mynetwork nginx\n  ```\n\n**8. Storage Management:**\n\n- **Mount a Volume:**\n\n  ```bash\n  podman run -dt -v /host/data:/container/data nginx\n  ```\n\n- **List Volumes:**\n\n  ```bash\n  podman volume ls\n  ```\n\n- **Create a Volume:**\n\n  ```bash\n  podman volume create myvolume\n  ```\n\n**9. Rootless Containers:**\n\n- **Running Rootless:**\n\n  ```bash\n  podman --rootless run -dt -p 8080:80 nginx\n  ```\n\n- **Inspect Rootless Mode:**\n\n  ```bash\n  podman info --format '{{.Host.Rootless}}'\n  ```\n\n**10. Podman Compose:**\n\n- **Install Podman Compose:**\n\n  ```bash\n  pip3 install podman-compose\n  ```\n\n- **Using Docker Compose with Podman:**\n\n  ```bash\n  podman-compose up\n  ```\n\n**11. Troubleshooting Podman:**\n\n- **Check Podman Logs:**\n\n  ```bash\n  podman logs container_id\n  ```\n\n- **Check Network Configuration:**\n\n  ```bash\n  podman network inspect mynetwork\n  ```\n\n- **Debugging Podman Containers:**\n\n  ```bash\n  podman exec -it container_id /bin/bash\n  ```\n\n**12. Podman in CI/CD:**\n\n- **Using Podman in GitLab CI:**\n\n  ```yaml\n  image: quay.io/podman/stable\n\n  build:\n    script:\n      - podman build -t myimage .\n      - podman push myimage registry.example.com/myimage:latest\n  ```\n\n**13. Security Best Practices:**\n\n- **Run Containers as Non-Root:**\n  - Use rootless mode or specify a non-root user in the container.\n\n  ```bash\n  podman run -dt -u 1001 nginx\n  ```\n\n- **Use SELinux:**\n  - Enable SELinux for added security on supported systems.\n\n  ```bash\n  podman run -dt --security-opt label=type:container_runtime_t nginx\n  ```\n\n**14. Migrating from Docker to Podman:**\n\n- **Docker Compatibility Mode:**\n\n  ```bash\n  alias docker=podman\n  ```\n\n- **Importing Docker Images:**\n\n  ```bash\n  podman pull docker-daemon:nginx:latest\n  ```\n\n**15. Podman on Kubernetes:**\n\n- **CRI-O Integration:**\n  - Podman can be used with CRI-O as a runtime for Kubernetes, allowing seamless integration with Kubernetes clusters.\n",
  "Cloud/AWS": "# AWS Cheatsheet\n\n![text](https://imgur.com/DDbwilK.png)\n\n**1. Introduction:**\n\n- **Amazon Web Services (AWS)** is a comprehensive cloud platform offering over 200 fully featured services from data centers globally. AWS provides cloud solutions for compute, storage, databases, machine learning, security, and more.\n\n**2. Core AWS Services:**\n\n- **Compute:**\n  - **EC2 (Elastic Compute Cloud):**\n    - Virtual servers for running applications.\n    - Instance types: General Purpose, Compute Optimized, Memory Optimized, etc.\n    - Key Concepts: AMI, Instance Types, Key Pairs, Security Groups, EBS Volumes.\n    - Example:\n\n      ```bash\n      aws ec2 run-instances --image-id ami-12345678 --instance-type t2.micro --key-name MyKeyPair\n      ```\n\n  - **Lambda:**\n    - Serverless computing to run code without provisioning or managing servers.\n    - Key Concepts: Functions, Event Sources, IAM Roles.\n    - Example:\n\n      ```bash\n      aws lambda create-function --function-name my-function --runtime python3.8 --role arn:aws:iam::123456789012:role/execution_role --handler my_function.handler --zip-file fileb://my-deployment-package.zip\n      ```\n\n  - **ECS/EKS (Elastic Container Service/Elastic Kubernetes Service):**\n    - ECS: Fully managed container orchestration service.\n    - EKS: Managed Kubernetes service for running Kubernetes on AWS.\n    - Key Concepts: Clusters, Tasks, Services, Fargate.\n    - Example:\n\n      ```bash\n      aws ecs create-cluster --cluster-name my-cluster\n      ```\n\n- **Storage:**\n  - **S3 (Simple Storage Service):**\n    - Scalable object storage service.\n    - Key Concepts: Buckets, Objects, Storage Classes, Lifecycle Policies.\n    - Example:\n\n      ```bash\n      aws s3 mb s3://my-bucket\n      aws s3 cp my-file.txt s3://my-bucket/\n      ```\n\n  - **EBS (Elastic Block Store):**\n    - Block storage for use with EC2 instances.\n    - Key Concepts: Volumes, Snapshots, Volume Types (gp2, io1, st1, etc.).\n    - Example:\n\n      ```bash\n      aws ec2 create-volume --size 10 --region us-east-1 --availability-zone us-east-1a --volume-type gp2\n      ```\n\n  - **Glacier:**\n    - Long-term, secure, and durable storage for data archiving and backup.\n    - Key Concepts: Vaults, Archives, Retrieval Policies.\n    - Example:\n\n      ```bash\n      aws glacier create-vault --vault-name my-vault --account-id -\n      ```\n\n- **Database:**\n  - **RDS (Relational Database Service):**\n    - Managed relational database service supporting various engines (MySQL, PostgreSQL, Oracle, SQL Server, etc.).\n    - Key Concepts: DB Instances, Snapshots, Security Groups, Multi-AZ.\n    - Example:\n\n      ```bash\n      aws rds create-db-instance --db-instance-identifier mydbinstance --db-instance-class db.t2.micro --engine mysql --master-username admin --master-user-password password --allocated-storage 20\n      ```\n\n  - **DynamoDB:**\n    - Managed NoSQL database service.\n    - Key Concepts: Tables, Items, Attributes, Primary Key, Global/Local Secondary Indexes.\n    - Example:\n\n      ```bash\n      aws dynamodb create-table --table-name MyTable --attribute-definitions AttributeName=Id,AttributeType=N --key-schema AttributeName=Id,KeyType=HASH --provisioned-throughput ReadCapacityUnits=5,WriteCapacityUnits=5\n      ```\n\n  - **Aurora:**\n    - MySQL and PostgreSQL-compatible relational database built for the cloud, providing high performance and availability.\n    - Key Concepts: Clusters, Replicas, Global Databases.\n    - Example:\n\n      ```bash\n      aws rds create-db-cluster --db-cluster-identifier my-cluster --engine aurora-mysql --master-username admin --master-user-password password\n      ```\n\n**3. Networking:**\n\n- **VPC (Virtual Private Cloud):**\n  - Isolated network environment to launch AWS resources.\n  - Key Concepts: Subnets, Route Tables, Internet Gateways, NAT Gateways, Security Groups, NACLs.\n  - Example:\n\n    ```bash\n    aws ec2 create-vpc --cidr-block 10.0.0.0/16\n    aws ec2 create-subnet --vpc-id vpc-12345678 --cidr-block 10.0.1.0/24\n    ```\n\n- **Route 53:**\n  - Scalable DNS and domain name registration service.\n  - Key Concepts: Hosted Zones, Record Sets, Health Checks, Traffic Policies.\n  - Example:\n\n    ```bash\n    aws route53 create-hosted-zone --name example.com --caller-reference unique-string\n    ```\n\n- **CloudFront:**\n  - Content delivery network (CDN) for delivering content globally with low latency.\n  - Key Concepts: Distributions, Origins, Behaviors, Edge Locations.\n  - Example:\n\n    ```bash\n    aws cloudfront create-distribution --origin-domain-name mybucket.s3.amazonaws.com\n    ```\n\n- **Elastic Load Balancing (ELB):**\n  - Distributes incoming traffic across multiple targets, such as EC2 instances.\n  - Key Concepts: Load Balancers (ALB, NLB, CLB), Target Groups, Listeners.\n  - Example:\n\n    ```bash\n    aws elbv2 create-load-balancer --name my-load-balancer --subnets subnet-12345678 subnet-87654321 --security-groups sg-12345678\n    ```\n\n**4. Security and Identity:**\n\n- **IAM (Identity and Access Management):**\n  - Manages users, groups, roles, and permissions.\n  - Key Concepts: Users, Groups, Roles, Policies, MFA, Access Keys.\n  - Example:\n\n    ```bash\n    aws iam create-user --user-name myuser\n    aws iam attach-user-policy --user-name myuser --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess\n    ```\n\n- **KMS (Key Management Service):**\n  - Managed service for creating and controlling encryption keys.\n  - Key Concepts: CMKs (Customer Master Keys), Aliases, Grants, Key Policies.\n  - Example:\n\n    ```bash\n    aws kms create-key --description \"My CMK\"\n    ```\n\n- **CloudTrail:**\n  - Tracks user activity and API usage across AWS accounts.\n  - Key Concepts: Trails, Logs, S3 Buckets, Insights.\n  - Example:\n\n    ```bash\n    aws cloudtrail create-trail --name MyTrail --s3-bucket-name my-bucket\n    ```\n\n**5. Management Tools:**\n\n- **CloudFormation:**\n  - Infrastructure as Code service for modeling and setting up AWS resources.\n  - Key Concepts: Templates, Stacks, Resources, Outputs, Parameters.\n  - Example:\n\n    ```bash\n    aws cloudformation create-stack --stack-name my-stack --template-body file://template.json\n    ```\n\n- **CloudWatch:**\n  - Monitoring and observability service for AWS resources and applications.\n  - Key Concepts: Metrics, Alarms, Logs, Events, Dashboards.\n  - Example:\n\n    ```bash\n    aws cloudwatch put-metric-alarm --alarm-name my-alarm --metric-name CPUUtilization --namespace AWS/EC2 --statistic Average --period 300 --threshold 80 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --alarm-actions arn:aws:sns:us-east-1:123456789012:my-topic\n    ```\n\n- **AWS Config:**\n  - Service for assessing, auditing, and evaluating the configurations of AWS resources.\n  - Key Concepts: Rules, Resources, Aggregators, Config Recorder.\n  - Example:\n\n    ```bash\n    aws configservice put-configuration-recorder --configuration-recorder name=my-recorder,roleARN=arn:aws:iam::123456789012:role/my-role\n    ```\n\n- **Trusted Advisor:**\n  - Provides real-time guidance to help you provision your resources following AWS best practices.\n  - Key Concepts: Checks, Recommendations.\n  - Example:\n    - Access via AWS Management Console.\n\n**6. Advanced Topics:**\n\n- **Cost Management:**\n  - Use AWS Cost Explorer, Budgets, and Cost & Usage Reports to monitor and optimize spending.\n  - Example:\n\n    ```bash\n    aws ce get-cost-and-usage --time-period Start=2024-08-01,End=2024-08-31 --granularity MONTHLY --metrics \"BlendedCost\"\n    ```\n\n- **Auto Scaling:**\n  - Automatically adjust the capacity of your resources based on demand.\n  - Key Concepts: Auto Scaling Groups, Scaling Policies, Launch Configurations.\n  - Example:\n\n    ```bash\n    aws autoscaling create-auto-scaling-group --auto-scaling-group-name my-asg --launch-configuration-name my-lc --min-size 1 --max-size 10 --desired-capacity 2 --vpc-zone-identifier subnet-12345678\n    ```\n\n- **Serverless Architectures:**\n  - Use AWS Lambda, API Gateway, and DynamoDB to build serverless applications.\n  - Key Concepts: Functions, APIs, Tables, Events, Triggers.\n  - Example:\n\n    ```bash\n    aws apigateway create-rest-api --name 'My API'\n    ```\n\n**7. Best\n\n Practices:**\n\n- **Security:**\n  - Use IAM Roles and Policies, enable MFA, encrypt data at rest and in transit, monitor with CloudTrail, and apply the Principle of Least Privilege.\n  \n- **Reliability:**\n  - Design for failure, use multiple Availability Zones (AZs), implement backups, and set up auto-scaling.\n\n- **Performance Efficiency:**\n  - Right-size instances, use appropriate storage classes, and leverage managed services.\n\n- **Cost Optimization:**\n  - Use Reserved Instances (RIs), Spot Instances, and review billing regularly.\n\n- **Operational Excellence:**\n  - Automate processes, monitor operations, and use infrastructure as code (IaC).\n",
  "Cloud/Azure": "# Azure Cheatsheet\n\n![text](https://imgur.com/f7RWwnx.png)\n\n**1. Introduction:**\n\n- **Microsoft Azure** is a cloud computing platform offering a wide range of services, including compute, analytics, storage, and networking.\n\n**2. Core Azure Services:**\n\n- **Compute:**\n  - **Azure Virtual Machines:**\n    - Scalable virtual servers for running applications.\n    - Key Concepts: VM Sizes, Resource Groups, Virtual Networks, Disks.\n    - Example:\n\n      ```bash\n      az vm create --resource-group myResourceGroup --name myVM --image UbuntuLTS --admin-username azureuser --generate-ssh-keys\n      ```\n\n  - **Azure Functions:**\n    - Serverless compute service for running event-driven code.\n    - Key Concepts: Functions, Triggers, Bindings.\n    - Example:\n\n      ```bash\n      func init MyFunctionProj --dotnet\n      func new --name MyHttpTrigger --template \"HTTP trigger\" --authlevel \"anonymous\"\n      ```\n\n  - **Azure Kubernetes Service (AKS):**\n    - Managed Kubernetes service for running containerized applications.\n    - Key Concepts: Clusters, Nodes, Pods, Services.\n    - Example:\n\n      ```bash\n      az aks create --resource-group myResourceGroup --name myAKSCluster --node-count 1 --enable-addons monitoring --generate-ssh-keys\n      ```\n\n- **Storage:**\n  - **Azure Blob Storage:**\n    - Object storage solution for the cloud.\n    - Key Concepts: Storage Accounts, Containers, Blobs, Access Tiers.\n    - Example:\n\n      ```bash\n      az storage account create --name mystorageaccount --resource-group myResourceGroup --location eastus --sku Standard_LRS\n      az storage container create --name mycontainer --account-name mystorageaccount\n      az storage blob upload --container-name mycontainer --file myfile.txt --name myfile.txt --account-name mystorageaccount\n      ```\n\n  - **Azure Files:**\n    - Managed file shares in the cloud using the SMB protocol.\n    - Key Concepts: File Shares, Directories, Snapshots.\n    - Example:\n\n      ```bash\n      az storage share create --name myshare --account-name mystorageaccount\n      ```\n\n  - **Azure Disk Storage:**\n    - High-performance disk storage for VMs.\n    - Key Concepts: Managed Disks, Disk Types (Standard HDD, Standard SSD, Premium SSD).\n    - Example:\n\n      ```bash\n      az disk create --resource-group myResourceGroup --name myDisk --size-gb 128 --sku Premium_LRS\n      ```\n\n- **Database:**\n  - **Azure SQL Database:**\n    - Managed relational database service.\n    - Key Concepts: Databases, Servers, Elastic Pools, DTUs/vCores.\n    - Example:\n\n      ```bash\n      az sql db create --resource-group myResourceGroup --server myServer --name myDatabase --service-objective S0\n      ```\n\n  - **Cosmos DB:**\n    - Globally distributed, multi-model database service.\n    - Key Concepts: Databases, Containers, Partition Keys, Consistency Levels.\n    - Example:\n\n      ```bash\n      az cosmosdb create --name myCosmosDBAccount --resource-group myResourceGroup --kind MongoDB --locations regionName=eastus\n      ```\n\n  - **Azure Database for MySQL/PostgreSQL:**\n    - Managed MySQL/PostgreSQL service.\n    - Key Concepts: Servers, Databases, Backup Retention, Performance Tiers.\n    - Example:\n\n      ```bash\n      az mysql server create --resource-group myResourceGroup --name mydemoserver --location eastus --admin-user myadmin --admin-password mypassword --sku-name GP_Gen5_2\n      ```\n\n**3. Networking:**\n\n- **Azure Virtual Network (VNet):**\n  - Provides an isolated network environment in Azure.\n  - Key Concepts: Subnets, Network Security Groups, VPN Gateway, Peering.\n  - Example:\n\n    ```bash\n    az network vnet create --resource-group myResourceGroup --name myVnet --address-prefix 10.0.0.0/16 --subnet-name mySubnet --subnet-prefix 10.0.1.0/24\n    ```\n\n- **Azure Load Balancer:**\n  - Distributes inbound traffic across multiple VMs.\n  - Key Concepts: Frontend IP, Backend Pools, Load Balancing Rules.\n  - Example:\n\n    ```bash\n    az network lb create --resource-group myResourceGroup --name myLoadBalancer --frontend-ip-name myFrontEnd --backend-pool-name myBackEndPool\n    ```\n\n- **Azure Application Gateway:**\n  - Web traffic load balancer for managing HTTP and HTTPS traffic.\n  - Key Concepts: Listener, Rules, HTTP Settings, SSL Certificates.\n  - Example:\n\n    ```bash\n    az network application-gateway create --name myAppGateway --resource-group myResourceGroup --capacity 2 --sku Standard_v2 --vnet-name myVnet --subnet mySubnet\n    ```\n\n- **Azure DNS:**\n  - Hosts your DNS domains and provides name resolution using Microsoft Azure infrastructure.\n  - Key Concepts: DNS Zones, Records, NS Records, A Records.\n  - Example:\n\n    ```bash\n    az network dns zone create --resource-group myResourceGroup --name mydomain.com\n    az network dns record-set a add-record --resource-group myResourceGroup --zone-name mydomain.com --record-set-name www --ipv4-address 10.0.0.4\n    ```\n\n**4. Security and Identity:**\n\n- **Azure Active Directory (AAD):**\n  - Identity and access management service.\n  - Key Concepts: Users, Groups, Roles, Managed Identities, Conditional Access.\n  - Example:\n\n    ```bash\n    az ad user create --display-name \"My User\" --user-principal-name myuser@mydomain.com --password \"P@ssw0rd!\"\n    ```\n\n- **Azure Key Vault:**\n  - Securely store and access secrets, keys, and certificates.\n  - Key Concepts: Vaults, Secrets, Keys, Certificates, Access Policies.\n  - Example:\n\n    ```bash\n    az keyvault create --name myKeyVault --resource-group myResourceGroup --location eastus\n    az keyvault secret set --vault-name myKeyVault --name MySecret --value \"MySecretValue\"\n    ```\n\n- **Azure Security Center:**\n  - Unified infrastructure security management system.\n  - Key Concepts: Security Posture, Recommendations, Secure Score, Just-in-Time VM Access.\n  - Example:\n\n    ```bash\n    az security assessment create --name myAssessment --status \"Healthy\" --description \"This is a custom assessment.\"\n    ```\n\n- **Azure Policy:**\n  - Enforce organizational standards and assess compliance at-scale.\n  - Key Concepts: Definitions, Initiatives, Assignments.\n  - Example:\n\n    ```bash\n    az policy assignment create --name myPolicyAssignment --scope /subscriptions/{subscription-id}/resourceGroups/{resource-group-name} --policy /subscriptions/{subscription-id}/providers/Microsoft.Authorization/policyDefinitions/{policyDefinitionName}\n    ```\n\n**5. Management Tools:**\n\n- **Azure Resource Manager (ARM):**\n  - Azure’s deployment and management service.\n  - Key Concepts: ARM Templates, Resources, Resource Groups, Deployments.\n  - Example:\n\n    ```bash\n    az group create --name myResourceGroup --location eastus\n    az deployment group create --resource-group myResourceGroup --template-file azuredeploy.json\n    ```\n\n- **Azure Monitor:**\n  - Comprehensive monitoring service for collecting, analyzing, and acting on telemetry data.\n  - Key Concepts: Metrics, Logs, Alerts, Application Insights, Log Analytics.\n  - Example:\n\n    ```bash\n    az monitor alert create --name myAlert --resource-group myResourceGroup --target /subscriptions/{subscription-id}/resourceGroups/{resource-group-name}/providers/Microsoft.Compute/virtualMachines/{vm-name} --condition \"avg Percentage CPU > 75\"\n    ```\n\n- **Azure Automation:**\n  - Automate frequent, time-consuming, and error-prone cloud management tasks.\n  - Key Concepts: Runbooks, Desired State Configuration (DSC), Hybrid Worker Groups.\n  - Example:\n\n    ```bash\n    az automation account create --name myAutomationAccount --resource-group myResourceGroup --location eastus\n    az automation runbook create --name myRunbook --automation-account-name myAutomationAccount --resource-group myResourceGroup --type PowerShellWorkflow\n    ```\n\n- **Azure Advisor:**\n  - Personalized cloud consultant that helps you follow best practices to optimize your Azure deployments.\n  - Key Concepts: Recommendations, Cost, Performance, Security, High Availability.\n  - Example:\n    - Access via Azure Portal.\n\n**6. Advanced Topics:**\n\n- **Cost Management:**\n  - Monitor and optimize your Azure costs using Cost Management + Billing.\n  - Example:\n\n    ```bash\n    az consumption budget create --amount 1000 --time-grain Monthly --start-date 2024-08-\n\n01 --end-date 2024-08-31 --name myBudget --resource-group myResourceGroup\n    ```\n\n- **Auto Scaling:**\n  - Automatically adjust the number of VM instances based on demand.\n  - Key Concepts: Scale Sets, Scaling Rules, Metrics.\n  - Example:\n\n    ```bash\n    az vmss create --resource-group myResourceGroup --name myScaleSet --image UbuntuLTS --upgrade-policy-mode automatic --admin-username azureuser --generate-ssh-keys\n    ```\n\n- **Serverless Architectures:**\n  - Utilize Azure Functions, Logic Apps, and Event Grid for serverless solutions.\n  - Key Concepts: Triggers, Bindings, Workflows, Event Subscriptions.\n  - Example:\n\n    ```bash\n    az eventgrid event-subscription create --name myEventSubscription --source-resource-id /subscriptions/{subscription-id}/resourceGroups/{resource-group}/providers/Microsoft.Storage/storageAccounts/{storage-account-name} --endpoint https://myfunction.azurewebsites.net/runtime/webhooks/eventgrid?functionName=myfunction\n    ```\n\n**7. Best Practices:**\n\n- **Security:**\n  - Use Azure Security Center, encrypt data, apply RBAC, monitor with Azure Monitor, and implement secure coding practices.\n  \n- **Reliability:**\n  - Use Availability Sets, Availability Zones, configure backups, and utilize disaster recovery services.\n\n- **Performance Efficiency:**\n  - Choose appropriate VM sizes, use caching services, and optimize databases.\n\n- **Cost Optimization:**\n  - Use Reserved Instances (RIs), monitor spend, and optimize resources.\n\n- **Operational Excellence:**\n  - Automate deployments with ARM, monitor operations, and use infrastructure as code (IaC).\n",
  "Cloud/GCP": "# GCP Cheatsheet\n\n![text](https://imgur.com/2MpF0w5.png)\n\n**1. Introduction:**\n\n- **Google Cloud Platform (GCP)** is a suite of cloud computing services offered by Google. It provides a range of services including compute, storage, databases, machine learning, and more.\n\n**2. Core GCP Services:**\n\n- **Compute:**\n  - **Google Compute Engine (GCE):**\n    - Scalable virtual machines running on Google’s infrastructure.\n    - Key Concepts: Machine Types, Images, Snapshots, Persistent Disks.\n    - Example:\n\n      ```bash\n      gcloud compute instances create my-instance --zone=us-central1-a --machine-type=e2-medium --image-family=debian-10 --image-project=debian-cloud\n      ```\n\n  - **Google Kubernetes Engine (GKE):**\n    - Managed Kubernetes service for running containerized applications.\n    - Key Concepts: Clusters, Nodes, Pods, Services, Deployments.\n    - Example:\n\n      ```bash\n      gcloud container clusters create my-cluster --zone us-central1-a --num-nodes 3\n      ```\n\n  - **Cloud Functions:**\n    - Serverless environment to execute code in response to events.\n    - Key Concepts: Functions, Triggers, Event Sources.\n    - Example:\n\n      ```bash\n      gcloud functions deploy my-function --runtime python39 --trigger-http --allow-unauthenticated\n      ```\n\n- **Storage:**\n  - **Google Cloud Storage:**\n    - Object storage service for storing and accessing data.\n    - Key Concepts: Buckets, Objects, Classes (Standard, Nearline, Coldline, Archive).\n    - Example:\n\n      ```bash\n      gsutil mb gs://my-bucket\n      gsutil cp my-file.txt gs://my-bucket/\n      ```\n\n  - **Persistent Disks:**\n    - Durable, high-performance block storage for VM instances.\n    - Key Concepts: Disk Types (Standard, SSD, Balanced), Snapshots, Zonal/Regional Disks.\n    - Example:\n\n      ```bash\n      gcloud compute disks create my-disk --size=100GB --type=pd-ssd --zone=us-central1-a\n      ```\n\n  - **Filestore:**\n    - Fully managed file storage service for applications that require a file system interface.\n    - Key Concepts: Instances, Tiers (Basic, High Scale, Enterprise).\n    - Example:\n\n      ```bash\n      gcloud filestore instances create my-filestore-instance --zone=us-central1-a --tier=STANDARD --file-share=name=\"my-share\",capacity=1TB --network=name=\"default\"\n      ```\n\n- **Database:**\n  - **Cloud SQL:**\n    - Managed relational database service supporting MySQL, PostgreSQL, and SQL Server.\n    - Key Concepts: Instances, Backups, Failover, Maintenance Windows.\n    - Example:\n\n      ```bash\n      gcloud sql instances create my-instance --database-version=MYSQL_8_0 --tier=db-f1-micro --region=us-central1\n      ```\n\n  - **Cloud Spanner:**\n    - Scalable, globally-distributed, and strongly consistent database service.\n    - Key Concepts: Instances, Databases, Schemas, Nodes.\n    - Example:\n\n      ```bash\n      gcloud spanner instances create my-instance --config=regional-us-central1 --nodes=1 --description=\"My Spanner Instance\"\n      ```\n\n  - **Firestore:**\n    - NoSQL document database for mobile, web, and server development.\n    - Key Concepts: Collections, Documents, Queries, Indexes.\n    - Example:\n\n      ```bash\n      gcloud firestore databases create --region=us-central\n      ```\n\n**3. Networking:**\n\n- **VPC (Virtual Private Cloud):**\n  - Isolated network environments within GCP.\n  - Key Concepts: Subnets, Routes, Firewalls, VPN, Interconnect.\n  - Example:\n\n    ```bash\n    gcloud compute networks create my-vpc --subnet-mode=custom\n    gcloud compute networks subnets create my-subnet --network=my-vpc --region=us-central1 --range=10.0.0.0/24\n    ```\n\n- **Cloud Load Balancing:**\n  - Global load balancing service for distributing traffic across multiple instances.\n  - Key Concepts: Frontends, Backends, URL Maps, Health Checks.\n  - Example:\n\n    ```bash\n    gcloud compute forwarding-rules create my-rule --global --target-http-proxy=my-proxy --ports=80\n    ```\n\n- **Cloud DNS:**\n  - Managed DNS service running on the same infrastructure as Google.\n  - Key Concepts: Managed Zones, DNS Records, Policies.\n  - Example:\n\n    ```bash\n    gcloud dns managed-zones create my-zone --dns-name=\"example.com.\" --description=\"My DNS zone\"\n    gcloud dns record-sets transaction start --zone=my-zone\n    gcloud dns record-sets transaction add --zone=my-zone --name=\"www.example.com.\" --ttl=300 --type=A \"1.2.3.4\"\n    gcloud dns record-sets transaction execute --zone=my-zone\n    ```\n\n- **Cloud CDN:**\n  - Content delivery network for delivering web and video content globally.\n  - Key Concepts: Backends, Cache Modes, Signed URLs.\n  - Example:\n\n    ```bash\n    gcloud compute url-maps create my-url-map --default-service=my-backend-service\n    gcloud compute backend-buckets create my-backend-bucket --gcs-bucket-name=my-bucket\n    gcloud compute backend-buckets add-backend --url-map=my-url-map --default-backend-bucket=my-backend-bucket\n    ```\n\n**4. Security and Identity:**\n\n- **Identity and Access Management (IAM):**\n  - Manage access to resources with fine-grained control.\n  - Key Concepts: Roles, Permissions, Policies, Service Accounts.\n  - Example:\n\n    ```bash\n    gcloud projects add-iam-policy-binding my-project --member=\"user:example@gmail.com\" --role=\"roles/editor\"\n    ```\n\n- **Cloud Identity:**\n  - Identity management for users and groups across services.\n  - Key Concepts: Directory, Groups, Security Settings, OAuth.\n  - Example:\n    - Managed via Google Admin Console.\n\n- **Cloud Key Management Service (KMS):**\n  - Create, manage, and use cryptographic keys.\n  - Key Concepts: Key Rings, Keys, Versions, Policies.\n  - Example:\n\n    ```bash\n    gcloud kms keyrings create my-keyring --location=global\n    gcloud kms keys create my-key --keyring=my-keyring --location=global --purpose=encryption\n    ```\n\n- **Cloud Security Command Center (SCC):**\n  - Security and risk management platform for GCP.\n  - Key Concepts: Findings, Assets, Sources, Security Health Analytics.\n  - Example:\n    - Managed via GCP Console.\n\n**5. Management Tools:**\n\n- **Deployment Manager:**\n  - Infrastructure as code service for managing GCP resources.\n  - Key Concepts: Templates, Deployments, Resources.\n  - Example:\n\n    ```bash\n    gcloud deployment-manager deployments create my-deployment --config=config.yaml\n    ```\n\n- **Stackdriver (now part of Operations Suite):**\n  - Monitoring, logging, and diagnostics tool for GCP.\n  - Key Concepts: Metrics, Logs, Alerts, Dashboards.\n  - Example:\n\n    ```bash\n    gcloud logging write my-log \"This is a log entry\" --severity=ERROR\n    ```\n\n- **Cloud Console:**\n  - Web-based interface to manage GCP resources.\n  - Key Concepts: Dashboards, Cloud Shell, Editor.\n\n- **Cloud Shell:**\n  - Command-line interface with access to all GCP resources.\n  - Example:\n\n    ```bash\n    gcloud config set project my-project\n    ```\n\n**6. Advanced Topics:**\n\n- **Cost Management:**\n  - Monitor and optimize your GCP costs using Billing Reports and Budgets.\n  - Example\n\n:\n    ```bash\n    gcloud beta billing budgets create --billing-account=012345-67890A-BCDEF0 --display-name=\"My Budget\" --amount=500USD\n    ```\n\n- **Auto Scaling:**\n  - Automatically adjust the number of VM instances based on demand.\n  - Key Concepts: Instance Groups, Autoscaler, Metrics.\n  - Example:\n\n    ```bash\n    gcloud compute instance-groups managed set-autoscaling my-group --max-num-replicas 10 --min-num-replicas 1 --target-cpu-utilization 0.6\n    ```\n\n- **Serverless Architectures:**\n  - Use Cloud Functions, Cloud Run, and Pub/Sub for serverless solutions.\n  - Key Concepts: Triggers, Events, Containers, Scaling.\n  - Example:\n\n    ```bash\n    gcloud run deploy my-service --image=gcr.io/my-project/my-image --platform managed\n    ```\n\n**7. Best Practices:**\n\n- **Security:**\n  - Use IAM policies, encrypt data, monitor with SCC, apply security best practices.\n  \n- **Reliability:**\n  - Use multiple zones/regions, set up failover, and implement backups.\n\n- **Performance Efficiency:**\n  - Choose appropriate machine types, use caching, optimize databases.\n\n- **Cost Optimization:**\n  - Use committed use contracts, monitor spend, and optimize resources.\n\n- **Operational Excellence:**\n  - Automate deployments, monitor operations, and use infrastructure as code (IaC).\n",
  "Cloud/Kubernetes-on-AWS": "# Kubernetes on AWS Cheatsheet\n\n![text](https://imgur.com/lWOk4cE.png)\n\n## 1. Introduction to Kubernetes on AWS\n\n### What is Kubernetes?\n\n- **Kubernetes** is an open-source platform for automating containerized application deployment, scaling, and management.\n\n### Kubernetes on AWS\n\n- AWS offers managed Kubernetes services through **Amazon EKS** (Elastic Kubernetes Service), which simplifies the process of running Kubernetes clusters on AWS infrastructure.\n\n---\n\n## 2. Setting Up Kubernetes on AWS\n\n### Amazon EKS Overview\n\n- **Amazon EKS** is a managed service that simplifies running Kubernetes on AWS by handling the control plane and providing integration with AWS services.\n\n### Creating an EKS Cluster\n\n- **Using AWS Management Console**:\n  1. Go to the Amazon EKS console.\n  2. Click **Create cluster**.\n  3. Follow the wizard to configure cluster settings, including VPC, subnets, and IAM roles.\n\n- **Using AWS CLI**:\n\n  ```bash\n  aws eks create-cluster --name my-cluster --role-arn arn:aws:iam::123456789012:role/EKS-Cluster-Role --resources-vpc-config subnetIds=subnet-0bb1c79de4EXAMPLE,subnet-0bb1c79de4EXAMPLE\n  ```\n\n### Configuring kubectl\n\n- **Update kubeconfig**:\n\n  ```bash\n  aws eks update-kubeconfig --name my-cluster\n  ```\n\n---\n\n## 3. EKS Cluster Configuration\n\n### Node Groups\n\n- **Create Node Group Using Console**:\n  1. Go to the Amazon EKS console.\n  2. Select your cluster.\n  3. Navigate to the **Compute** tab and click **Add Node Group**.\n  4. Configure settings such as instance types, scaling options, and IAM roles.\n\n- **Create Node Group Using AWS CLI**:\n\n  ```bash\n  aws eks create-nodegroup --cluster-name my-cluster --nodegroup-name my-node-group --scaling-config minSize=1,maxSize=3,desiredSize=2 --disk-size 20 --subnets subnet-0bb1c79de4EXAMPLE,subnet-0bb1c79de4EXAMPLE --instance-types t3.medium --node-role arn:aws:iam::123456789012:role/EKS-Node-Role\n  ```\n\n### IAM Roles and Policies\n\n- **Create IAM Roles**:\n  - **EKS Cluster Role**: Grants EKS permissions to interact with AWS services.\n  - **Node Instance Role**: Grants permissions for the worker nodes.\n\n- **Attach Policies**:\n  - **AmazonEKSClusterPolicy**\n  - **AmazonEKSWorkerNodePolicy**\n  - **AmazonEC2ContainerRegistryReadOnly**\n\n---\n\n## 4. Networking\n\n### VPC and Subnet Configuration\n\n- **Create VPC**:\n\n  ```bash\n  aws ec2 create-vpc --cidr-block 10.0.0.0/16\n  ```\n\n- **Create Subnets**:\n\n  ```bash\n  aws ec2 create-subnet --vpc-id vpc-0bb1c79de4EXAMPLE --cidr-block 10.0.1.0/24 --availability-zone us-west-2a\n  ```\n\n- **Configure Security Groups**:\n  - Allow inbound traffic on port 443 (Kubernetes API server).\n  - Allow outbound traffic for node communication.\n\n### Cluster Networking\n\n- **Use Amazon VPC CNI Plugin**:\n  - Ensures that Kubernetes pods get IP addresses from the VPC network.\n\n  ```bash\n  kubectl apply -f https://raw.githubusercontent.com/aws/amazon-vpc-cni-k8s/master/config/v1.12/aws-k8s-cni.yaml\n  ```\n\n---\n\n## 5. Deploying Applications\n\n### Deploying with kubectl\n\n- **Create a Deployment**:\n\n  ```yaml\n  apiVersion: apps/v1\n  kind: Deployment\n  metadata:\n    name: my-deployment\n  spec:\n    replicas: 2\n    selector:\n      matchLabels:\n        app: my-app\n    template:\n      metadata:\n        labels:\n          app: my-app\n      spec:\n        containers:\n        - name: my-container\n          image: my-image:latest\n          ports:\n          - containerPort: 80\n  ```\n\n- **Apply the Deployment**:\n\n  ```bash\n  kubectl apply -f deployment.yaml\n  ```\n\n### Managing Services\n\n- **Create a Service**:\n\n  ```yaml\n  apiVersion: v1\n  kind: Service\n  metadata:\n    name: my-service\n  spec:\n    selector:\n      app: my-app\n    ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 80\n    type: LoadBalancer\n  ```\n\n- **Apply the Service**:\n\n  ```bash\n  kubectl apply -f service.yaml\n  ```\n\n### Ingress Controllers\n\n- **Install NGINX Ingress Controller**:\n\n  ```bash\n  kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/aws/deploy.yaml\n  ```\n\n- **Create an Ingress Resource**:\n\n  ```yaml\n  apiVersion: networking.k8s.io/v1\n  kind: Ingress\n  metadata:\n    name: my-ingress\n  spec:\n    rules:\n    - host: myapp.example.com\n      http:\n        paths:\n        - path: /\n          pathType: Prefix\n          backend:\n            service:\n              name: my-service\n              port:\n                number: 80\n  ```\n\n---\n\n## 6. Storage\n\n### EBS Volumes\n\n- **Create and Attach an EBS Volume**:\n  - **Create Volume**:\n\n    ```bash\n    aws ec2 create-volume --size 10 --availability-zone us-west-2a --volume-type gp2\n    ```\n\n  - **Attach Volume**:\n\n    ```bash\n    aws ec2 attach-volume --volume-id vol-0bb1c79de4EXAMPLE --instance-id i-0bb1c79de4EXAMPLE --device /dev/xvdf\n    ```\n\n### Persistent Volumes and Claims\n\n- **Create a Persistent Volume**:\n\n  ```yaml\n  apiVersion: v1\n  kind: PersistentVolume\n  metadata:\n    name: my-pv\n  spec:\n    capacity:\n      storage: 10Gi\n    accessModes:\n      - ReadWriteOnce\n    hostPath:\n      path: /mnt/data\n  ```\n\n- **Create a Persistent Volume Claim**:\n\n  ```yaml\n  apiVersion: v1\n  kind: PersistentVolumeClaim\n  metadata:\n    name: my-pvc\n  spec:\n    accessModes:\n      - ReadWriteOnce\n    resources:\n      requests:\n        storage: 10Gi\n  ```\n\n---\n\n## 7. Monitoring and Logging\n\n### CloudWatch Integration\n\n- **Install CloudWatch Agent**:\n\n  ```bash\n  kubectl apply -f https://s3.amazonaws.com/amazoncloudwatch-agent-kubernetes/amazon-cloudwatch-agent.yaml\n  ```\n\n- **Configure CloudWatch Logs**:\n  - Create log groups and streams in CloudWatch.\n  - Set up IAM roles to allow Kubernetes to push logs to CloudWatch.\n\n### Prometheus and Grafana\n\n- **Install Prometheus**:\n\n  ```bash\n  kubectl create namespace monitoring\n  kubectl apply -f https://github.com/prometheus/prometheus/releases/download/v2.26.0/prometheus-2.26.0.yaml\n  ```\n\n- **Install Grafana**:\n\n  ```bash\n  kubectl apply -f https://raw.githubusercontent.com/grafana/grafana/main/deploy/kubernetes/grafana-deployment.yaml\n  ```\n\n- **Configure Prometheus and Grafana**:\n  - Set up Prometheus as a data source in Grafana.\n  - Import pre-built dashboards or create custom ones.\n\n---\n\n## 8. Security\n\n### IAM Roles for Service Accounts\n\n- **Create IAM Role for Service Account**:\n\n  ```bash\n  aws iam create-role --role-name my-k8s-role --assume-role-policy-document file://trust-policy.json\n  ```\n\n- **Attach Policies**:\n\n  ```bash\n  aws iam attach-role-policy --role-name my-k8s-role --policy-arn arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\n  ```\n\n- **Associate IAM Role with Kubernetes Service Account**:\n\n  ```yaml\n  apiVersion: v1\n  kind: ServiceAccount\n  metadata:\n    name: my-service-account\n  annotations:\n    eks.amazonaws.com/role-arn: arn:aws:iam::123456789012:role/my-k8s-role\n  ```\n\n### Network Policies\n\n- **Create a Network Policy**:\n\n  ```yaml\n  apiVersion: networking.k8s.io/v1\n  kind: NetworkPolicy\n  metadata:\n    name: allow-front-end\n  spec:\n    podSelector:\n      matchLabels:\n        role: front-end\n    ingress:\n    - from:\n      - podSelector:\n          matchLabels:\n            role: back-end\n  ```\n\n### Secrets Management\n\n- **Create a Kubernetes Secret**:\n\n  ```bash\n  kubectl create secret generic my-secret --from-literal=password=my-password\n  ```\n\n- **Access Secret in Pods**:\n\n  ```yaml\n  apiVersion: v1\n  kind: Pod\n  metadata:\n    name: my-pod\n  spec:\n    containers:\n    - name: my-container\n      image: my-image\n      env:\n      - name: MY\n\n_SECRET\n        valueFrom:\n          secretKeyRef:\n            name: my-secret\n            key: password\n\n  ```\n\n---\n\n## 9. Auto-scaling and Load Balancing\n\n### Horizontal Pod Autoscaler\n- **Create Horizontal Pod Autoscaler**:\n  ```bash\n  kubectl autoscale deployment my-deployment --cpu-percent=50 --min=1 --max=10\n  ```\n\n### Cluster Autoscaler\n\n- **Install Cluster Autoscaler**:\n\n  ```bash\n  kubectl apply -f https://github.com/kubernetes/autoscaler/releases/download/<version>/cluster-autoscaler-v<version>.yaml\n  ```\n\n### ELB Integration\n\n- **Configure ELB for Load Balancing**:\n  - Ensure the service type is `LoadBalancer`.\n\n  ```yaml\n  apiVersion: v1\n  kind: Service\n  metadata:\n    name: my-service\n  spec:\n    type: LoadBalancer\n    selector:\n      app: my-app\n    ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 80\n  ```\n\n---\n\n## 10. Backup and Recovery\n\n### EBS Snapshots\n\n- **Create Snapshot**:\n\n  ```bash\n  aws ec2 create-snapshot --volume-id vol-0bb1c79de4EXAMPLE --description \"My snapshot\"\n  ```\n\n- **Restore from Snapshot**:\n\n  ```bash\n  aws ec2 create-volume --snapshot-id snap-0bb1c79de4EXAMPLE --availability-zone us-west-2a\n  ```\n\n### Backup Strategies\n\n- **Use Velero for Backup and Restore**:\n  - **Install Velero**:\n\n    ```bash\n    velero install --provider aws --bucket <bucket-name> --secret-file <credentials-file> --backup-location-config region=<region>\n    ```\n\n- **Create a Backup**:\n\n  ```bash\n  velero backup create my-backup --include-namespaces my-namespace\n  ```\n\n---\n\n## 11. Upgrades and Maintenance\n\n### Upgrading EKS Clusters\n\n- **Upgrade Control Plane**:\n  - **Using Console**: Select your cluster and choose to upgrade.\n  - **Using CLI**:\n\n    ```bash\n    aws eks update-cluster-version --name my-cluster --kubernetes-version 1.21\n    ```\n\n### Upgrading Node Groups\n\n- **Update Node Groups**:\n\n  ```bash\n  aws eks update-nodegroup-version --cluster-name my-cluster --nodegroup-name my-node-group --release-version 1.21\n  ```\n\n### Regular Maintenance\n\n- **Monitor Cluster Health**: Use AWS CloudWatch and Prometheus for monitoring.\n- **Check for Vulnerabilities**: Regularly scan images and clusters for security vulnerabilities.\n\n---\n\n## 12. References\n\n### Official Documentation\n\n- [Amazon EKS Documentation](https://docs.aws.amazon.com/eks/latest/userguide/what-is-eks.html)\n- [Kubernetes Documentation](https://kubernetes.io/docs/)\n\n### Tools and Resources\n\n- [AWS CLI Documentation](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html)\n- [Kubectl Documentation](https://kubernetes.io/docs/reference/kubectl/)\n",
  "Cloud/Terraform-on-AWS": "# Terraform on AWS Cheatsheet\n\n![text](https://stratusgrid.com/hubfs/AWS%20Configuration%20Recorder%20Module%20on%20Terraform.webp)\n\n#### **1. Introduction to Terraform**\n\nTerraform is an open-source Infrastructure as Code (IaC) tool developed by HashiCorp. It allows you to define and provision infrastructure using a high-level configuration language. Terraform is cloud-agnostic, meaning it can manage infrastructure across various cloud providers like AWS, Azure, Google Cloud, and on-premise data centers.\n\n**Key Concepts:**\n\n- **IaC (Infrastructure as Code):** Managing and provisioning infrastructure through code rather than manual processes.\n- **HCL (HashiCorp Configuration Language):** The language used to write Terraform configurations.\n- **Providers:** Plugins that interact with APIs of cloud providers and other services.\n- **Resources:** The most basic building blocks of Terraform, representing infrastructure components.\n- **State:** Terraform keeps track of the real-world state of your infrastructure in a state file.\n\n---\n\n#### **2. Terraform Basics**\n\n**2.1. Installing Terraform**\n\n- Terraform can be installed on various operating systems.\n- Download Terraform from the [official site](https://www.terraform.io/downloads.html) and add it to your system's PATH.\n\n**Example:**\n\n```bash\n# On Ubuntu\nsudo apt-get update && sudo apt-get install -y gnupg software-properties-common\nwget -O- https://apt.releases.hashicorp.com/gpg | sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg\necho \"deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/hashicorp.list\nsudo apt update\nsudo apt install terraform\n```\n\n**2.2. Writing Your First Terraform Configuration**\n\n- Create a directory for your Terraform configuration files.\n- Define the provider and resources in a `.tf` file.\n\n**Example:**\n\n```hcl\n# main.tf\n\nprovider \"aws\" {\n  region = \"us-west-2\"\n}\n\nresource \"aws_instance\" \"example\" {\n  ami           = \"ami-0c55b159cbfafe1f0\"\n  instance_type = \"t2.micro\"\n\n  tags = {\n    Name = \"TerraformExample\"\n  }\n}\n```\n\n**2.3. Initializing Terraform**\n\n- Use `terraform init` to initialize your Terraform project. This downloads the necessary provider plugins.\n\n**Example:**\n\n```bash\nterraform init\n```\n\n**2.4. Planning and Applying Changes**\n\n- **terraform plan:** Generates an execution plan showing what actions Terraform will take.\n- **terraform apply:** Executes the actions proposed in the plan.\n\n**Example:**\n\n```bash\nterraform plan\nterraform apply\n```\n\n**2.5. Managing Terraform State**\n\n- Terraform stores the state of your infrastructure in a file called `terraform.tfstate`.\n- The state file is critical for Terraform to manage your resources accurately.\n\n**Example:**\n\n```bash\n# To view the current state\nterraform show\n\n# To refresh the state\nterraform refresh\n```\n\n---\n\n#### **3. Intermediate Terraform**\n\n**3.1. Variables and Outputs**\n\n- **Variables:** Used to input dynamic values into Terraform configurations.\n- **Outputs:** Used to extract information from Terraform resources after they are created.\n\n**Example:**\n\n```hcl\n# variables.tf\n\nvariable \"instance_type\" {\n  description = \"Type of instance to create\"\n  default     = \"t2.micro\"\n}\n\n# main.tf\n\nresource \"aws_instance\" \"example\" {\n  ami           = \"ami-0c55b159cbfafe1f0\"\n  instance_type = var.instance_type\n\n  tags = {\n    Name = \"TerraformExample\"\n  }\n}\n\n# outputs.tf\n\noutput \"instance_id\" {\n  description = \"The ID of the instance\"\n  value       = aws_instance.example.id\n}\n```\n\n**3.2. Managing Multiple Environments**\n\n- Use `terraform.workspace` to manage different environments like dev, staging, and production.\n  \n**Example:**\n\n```bash\n# Create a new workspace\nterraform workspace new dev\n\n# Switch to an existing workspace\nterraform workspace select dev\n```\n\n**3.3. Terraform Modules**\n\n- Modules are reusable pieces of Terraform code that group resources together. They promote reusability and maintainability.\n\n**Example:**\n\n```hcl\n# Creating a module\n\n# Directory structure\nmodule/\n  ├── main.tf\n  ├── variables.tf\n  └── outputs.tf\n\n# Using a module\nmodule \"vpc\" {\n  source = \"./module\"\n\n  vpc_name = \"example-vpc\"\n}\n```\n\n---\n\n#### **4. Advanced Terraform**\n\n**4.1. Terraform Provisioners**\n\n- Provisioners allow you to execute scripts or commands on a remote resource as part of the resource creation or destruction.\n\n**Example:**\n\n```hcl\nresource \"aws_instance\" \"example\" {\n  ami           = \"ami-0c55b159cbfafe1f0\"\n  instance_type = \"t2.micro\"\n\n  provisioner \"remote-exec\" {\n    inline = [\n      \"sudo apt-get update\",\n      \"sudo apt-get install -y nginx\"\n    ]\n\n    connection {\n      type     = \"ssh\"\n      user     = \"ubuntu\"\n      private_key = file(\"~/.ssh/id_rsa\")\n      host     = self.public_ip\n    }\n  }\n\n  tags = {\n    Name = \"TerraformExample\"\n  }\n}\n```\n\n**4.2. Handling Secrets with Terraform**\n\n- Use HashiCorp Vault or AWS Secrets Manager to securely manage sensitive data like passwords and API keys in your Terraform configurations.\n\n**Example:**\n\n```hcl\nprovider \"vault\" {\n  address = \"https://vault.example.com\"\n}\n\ndata \"vault_generic_secret\" \"example\" {\n  path = \"secret/myapp\"\n}\n\nresource \"aws_db_instance\" \"example\" {\n  engine         = \"mysql\"\n  instance_class = \"db.t2.micro\"\n  username       = \"admin\"\n  password       = data.vault_generic_secret.example.data[\"password\"]\n}\n```\n\n**4.3. Remote State Management**\n\n- Store Terraform state files remotely using backends like S3, Azure Blob Storage, or Google Cloud Storage.\n  \n**Example:**\n\n```hcl\nterraform {\n  backend \"s3\" {\n    bucket = \"my-terraform-state\"\n    key    = \"path/to/my/key\"\n    region = \"us-west-2\"\n  }\n}\n```\n\n**4.4. Terraform Enterprise**\n\n- Terraform Enterprise provides additional features like collaboration, policy enforcement, and enhanced security for teams.\n\n**Example:**\n\n```hcl\n# Example configuration for Terraform Cloud\nterraform {\n  cloud {\n    organization = \"my-org\"\n\n    workspaces {\n      name = \"my-workspace\"\n    }\n  }\n}\n```\n\n**4.5. Custom Providers and Plugins**\n\n- You can write custom providers and plugins if Terraform’s built-in providers don’t meet your needs.\n  \n**Example:**\n\n```hcl\n# Example using a custom provider\nprovider \"custom\" {\n  # Configuration for the custom provider\n}\n\nresource \"custom_resource\" \"example\" {\n  name = \"example-resource\"\n}\n```\n\n---\n\n#### **5. Best Practices for Terraform**\n\n**5.1. Version Control**\n\n- Store your Terraform configurations in version control systems like Git. This ensures that changes are tracked and collaborative work is streamlined.\n\n**5.2. Use of Modules**\n\n- Break down complex infrastructure into modules. This enhances reusability and reduces code duplication.\n\n**5.3. State Management**\n\n- Use remote state for collaboration and ensure that state files are encrypted and secured.\n\n**5.4. Locking State**\n\n- Use state locking to prevent concurrent state modifications when using remote backends like S3 with DynamoDB.\n\n**5.5. Use `terraform validate`**\n\n- Always run `terraform validate` to check the syntax and validity of your Terraform configurations before applying them.\n\n**5.6. Avoid Hardcoding Values**\n\n- Use variables and environment-specific configurations to avoid hardcoding sensitive data or region-specific information.\n\n**5.7. Implement Proper Logging and Monitoring**\n\n- Implement logging and monitoring for your Terraform deployments to track changes, catch issues early, and maintain audit trails.\n\n**5.8. Implement Policy as Code**\n\n- Use tools like HashiCorp Sentinel or Open Policy Agent (OPA) to enforce policies on your Terraform configurations.\n",
  "Infrastructure-Management/Ansible": "# 📜 **Ansible Cheatsheet**  \n\n![ansible](https://imgur.com/XwECXoK.png)\n\n## **🔹 Introduction to Ansible**  \n\n### ✅ What is Ansible?  \n\nAnsible is an **open-source automation tool** used for:  \n✅ **Configuration Management** (e.g., installing & managing software on servers)  \n✅ **Application Deployment** (e.g., deploying a web app on multiple servers)  \n✅ **Orchestration** (e.g., managing multi-tier applications like load balancer + DB)  \n✅ **Provisioning** (e.g., setting up cloud infrastructure with AWS, Azure, GCP)  \n\n### ✅ Why Use Ansible?  \n\n🔹 **Agentless:** No need to install agents on target machines (uses SSH & WinRM)  \n🔹 **Idempotent:** Runs multiple times without unwanted changes  \n🔹 **Human-Readable:** Uses YAML playbooks  \n🔹 **Cross-Platform:** Works on **Linux, Windows, macOS, Cloud Servers**  \n\n---\n\n## **🛠️ 1. Installing & Setting Up Ansible**  \n\n### ✅ Installing Ansible on Linux  \n\n```bash\n# Ubuntu/Debian\nsudo apt update\nsudo apt install -y ansible\n\n# CentOS/RHEL\nsudo yum install -y ansible\n```\n\n### ✅ Checking Installation  \n\n```bash\nansible --version\n```\n\n### ✅ Setting Up an Inventory File  \n\nAn **inventory file** (`/etc/ansible/hosts`) tells Ansible where to connect.  \nExample:  \n\n```ini\n[webservers]\nserver1 ansible_host=192.168.1.10 ansible_user=ubuntu\nserver2 ansible_host=192.168.1.11 ansible_user=ubuntu\n\n[dbservers]\ndb1 ansible_host=192.168.1.20 ansible_user=root\n```\n\n### ✅ Testing Connectivity with `ping`  \n\n```bash\nansible all -m ping\n```\n\n📌 If successful, you'll see:  \n\n```bash\nserver1 | SUCCESS => {\"changed\": false, \"ping\": \"pong\"}\nserver2 | SUCCESS => {\"changed\": false, \"ping\": \"pong\"}\n```\n\n---\n\n## **🚀 2. Running Ad-Hoc Commands (Quick Tasks Without a Playbook)**  \n\n✅ **Check disk usage**  \n\n```bash\nansible all -m command -a \"df -h\"\n```\n\n✅ **Check system uptime**  \n\n```bash\nansible all -m command -a \"uptime\"\n```\n\n✅ **Create a directory on remote hosts**  \n\n```bash\nansible all -m file -a \"path=/opt/newdir state=directory\"\n```\n\n✅ **Copy files to remote servers**  \n\n```bash\nansible all -m copy -a \"src=/tmp/file.txt dest=/home/ubuntu/file.txt\"\n```\n\n✅ **Install a package (e.g., nginx) on all web servers**  \n\n```bash\nansible webservers -m apt -a \"name=nginx state=present\" --become\n```\n\n✅ **Restart a service (e.g., nginx)**  \n\n```bash\nansible webservers -m service -a \"name=nginx state=restarted\" --become\n```\n\n---\n\n## **📜 3. Writing Ansible Playbooks (Automation Scripts)**  \n\n✅ **What is a Playbook?**  \nA **playbook** is a YAML file that contains tasks to **automate configuration**.  \n\n### **🔹 Basic Playbook Example**  \n\n```yaml\n- name: Install and Start Nginx\n  hosts: webservers\n  become: yes  # Run as sudo\n  tasks:\n    - name: Install Nginx\n      apt:\n        name: nginx\n        state: present\n\n    - name: Start Nginx\n      service:\n        name: nginx\n        state: started\n```\n\n✅ **Run the Playbook**  \n\n```bash\nansible-playbook playbook.yml\n```\n\n---\n\n## **🔹 4. Using Variables in Ansible**  \n\n✅ **Define Variables in a Playbook**  \n\n```yaml\n- name: Install a Package with a Variable\n  hosts: webservers\n  vars:\n    package_name: nginx\n  tasks:\n    - name: Install Package\n      apt:\n        name: \"{{ package_name }}\"\n        state: present\n```\n\n✅ **Use Built-in Ansible Facts**  \n\n```bash\nansible all -m setup\n```\n\nExample Fact Usage in Playbook:  \n\n```yaml\n- name: Display System Information\n  hosts: all\n  tasks:\n    - debug:\n        msg: \"This server is running {{ ansible_distribution }} {{ ansible_distribution_version }}\"\n```\n\n---\n\n## **🔹 5. Loops & Conditionals**  \n\n✅ **Loop Example (Install Multiple Packages)**  \n\n```yaml\n- name: Install Multiple Packages\n  hosts: webservers\n  become: yes\n  tasks:\n    - name: Install Packages\n      apt:\n        name: \"{{ item }}\"\n        state: present\n      loop:\n        - nginx\n        - curl\n        - unzip\n```\n\n✅ **Conditional Execution**  \n\n```yaml\n- name: Restart Nginx Only If Needed\n  hosts: webservers\n  become: yes\n  tasks:\n    - name: Check if Nginx is Running\n      shell: pgrep nginx\n      register: nginx_running\n      ignore_errors: yes\n\n    - name: Restart Nginx\n      service:\n        name: nginx\n        state: restarted\n      when: nginx_running.rc == 0\n```\n\n---\n\n## **📂 6. Ansible Roles (Best Practices for Large Projects)**  \n\n✅ **Generate an Ansible Role Structure**  \n\n```bash\nansible-galaxy init my_role\n```\n\n📌 This creates a structured directory like:  \n\n```plaintext\nmy_role/\n├── tasks/\n│   └── main.yml\n├── handlers/\n│   └── main.yml\n├── templates/\n├── files/\n├── vars/\n│   └── main.yml\n├── defaults/\n│   └── main.yml\n├── meta/\n│   └── main.yml\n├── README.md\n```\n\n✅ **Use Roles in a Playbook**  \n\n```yaml\n- name: Deploy Web Server\n  hosts: webservers\n  roles:\n    - nginx_role\n```\n\n---\n\n## **🔐 7. Ansible Vault (Encrypting Secrets)**  \n\n✅ **Create an Encrypted File**  \n\n```bash\nansible-vault create secrets.yml\n```\n\n✅ **Edit an Encrypted File**  \n\n```bash\nansible-vault edit secrets.yml\n```\n\n✅ **Use Vault in Playbooks**  \n\n```yaml\n- name: Deploy with Encrypted Secrets\n  hosts: webservers\n  vars_files:\n    - secrets.yml\n  tasks:\n    - debug:\n        msg: \"The secret password is {{ secret_password }}\"\n```\n\n✅ **Run Playbook with Vault Password Prompt**  \n\n```bash\nansible-playbook playbook.yml --ask-vault-pass\n```\n\n---\n\n## **🎯 8. Useful Ansible Commands**  \n\n✅ **Check Playbook Syntax**  \n\n```bash\nansible-playbook playbook.yml --syntax-check\n```\n\n✅ **Dry Run (Test Without Executing Changes)**  \n\n```bash\nansible-playbook playbook.yml --check\n```\n\n✅ **List All Available Modules**  \n\n```bash\nansible-doc -l\n```\n\n✅ **Get Help for a Specific Module**  \n\n```bash\nansible-doc apt\n```\n\n---\n\n## 🎯 **Conclusion**  \n\nThis **Ansible Cheatsheet** provides a **step-by-step guide** from **beginner to advanced**.  \n\n🚀 **Next Steps:**  \n✅ **Practice with real-world playbooks**  \n✅ **Use roles for better structuring**  \n✅ **Secure credentials with Ansible Vault**  \n✅ **Automate cloud infrastructure with Terraform + Ansible**  \n\n🔗 **Contribute to the Cheatsheet Collection:** [GitHub Repo](https://github.com/NotHarshhaa/devops-cheatsheet)  \n",
  "Infrastructure-Management/Chef": "# 🧑‍🍳 Chef Cheat Sheet\n\n[![chef-cheat.png](https://i.postimg.cc/SsthzhnB/chef-cheat.png)](https://postimg.cc/hzxwHNbs)\n\n## 📘 Introduction\n\nChef is a configuration management tool written in Ruby and Erlang. It automates the process of configuring, deploying, and managing servers and infrastructure.\n\n---\n\n## 🟢 Beginner Level\n\n### 🔹 Key Concepts\n\n* **Node**: A machine (physical/virtual) managed by Chef.\n* **Cookbook**: A collection of recipes and other config files.\n* **Recipe**: The fundamental unit for configuration — contains Ruby code to define resources.\n* **Resource**: A statement of configuration like `package`, `service`, `file`, etc.\n* **Runlist**: A list of recipes/roles applied to a node.\n\n---\n\n## 🍳 Chef Commands\n\n<details>\n<summary>🟢 Beginner Commands (Click to Expand)</summary>\n\n### 🔹 Check Version\n\n```bash\nchef --version\n```\n\n### 🔹 Generate Cookbook\n\n```bash\nchef generate cookbook my_cookbook\n```\n\n### 🔹 Generate Recipe\n\n```bash\nchef generate recipe my_cookbook default\n```\n\n### 🔹 Run Chef Client (Local Mode)\n\n```bash\nchef-client --local-mode --runlist 'recipe[my_cookbook]'\n```\n\n### 🔹 Validate Ruby Syntax\n\n```bash\nruby -c recipes/default.rb\n```\n\n</details>\n\n---\n\n<details>\n<summary>🟡 Intermediate Commands (Click to Expand)</summary>\n\n### 🔹 Knife Bootstrap Node\n\n```bash\nknife bootstrap <IP_ADDRESS> -x user -P password --node-name node1\n```\n\n### 🔹 Upload Cookbook to Server\n\n```bash\nknife cookbook upload my_cookbook\n```\n\n### 🔹 Show Node Information\n\n```bash\nknife node show node1\n```\n\n### 🔹 Run Chef Client on Remote Node\n\n```bash\nknife ssh 'name:node1' 'sudo chef-client' -x user\n```\n\n</details>\n\n---\n\n<details>\n<summary>🔴 Advanced Commands (Click to Expand)</summary>\n\n### 🔹 Search Nodes or Data Bags\n\n```bash\nknife search node 'role:web'\nknife data bag show users\n```\n\n### 🔹 Edit Node or Role\n\n```bash\nknife node edit node1\nknife role edit webserver\n```\n\n### 🔹 Generate Role or Environment\n\n```bash\nchef generate role webserver\nchef generate environment dev\n```\n\n### 🔹 Upload Roles/Environments\n\n```bash\nknife role from file roles/webserver.rb\nknife environment from file environments/dev.rb\n```\n\n### 🔹 Test Cookbook (ChefSpec, InSpec)\n\n```bash\nchef exec rspec\nchef exec inspec exec test/integration/default\n```\n\n</details>\n\n---\n\n### 🔹 Chef Setup\n\n```bash\n# Install Chef Workstation\ncurl -LO https://packages.chef.io/files/stable/chef-workstation/latest/el/7/chef-workstation-*.rpm\nsudo rpm -Uvh chef-workstation-*.rpm\n```\n\n```bash\n# Verify installation\nchef -v\n```\n\n---\n\n### 🔹 Create a Cookbook\n\n```bash\nchef generate cookbook my_cookbook\ncd my_cookbook\n```\n\n---\n\n### 🔹 Basic Recipe\n\n```ruby\n# recipes/default.rb\npackage 'nginx'\n\nservice 'nginx' do\n  action [:enable, :start]\nend\n```\n\n```bash\n# Run recipe on local machine (Test Kitchen or chef-run)\nchef-run 'localhost' my_cookbook\n```\n\n---\n\n### 🔹 Common Resources\n\n| Resource  | Example                                        |\n| --------- | ---------------------------------------------- |\n| `package` | `package 'nginx'`                              |\n| `service` | `service 'nginx' { action [:start, :enable] }` |\n| `file`    | `file '/etc/motd' { content 'Hello Chef' }`    |\n| `user`    | `user 'deploy' { shell '/bin/bash' }`          |\n\n---\n\n## 🟡 Intermediate Level\n\n### 🔸 Attributes\n\n```ruby\n# attributes/default.rb\ndefault['my_cookbook']['greeting'] = 'Welcome to Chef!'\n\n# Use in recipe\nfile '/etc/motd' do\n  content node['my_cookbook']['greeting']\nend\n```\n\n---\n\n### 🔸 Templates\n\nTemplates are ERB files used to manage config files.\n\n```bash\n# generate template\nmkdir templates/default\ntouch templates/default/index.html.erb\n```\n\n```erb\n<!-- templates/default/index.html.erb -->\n<h1>Hello <%= node['hostname'] %>!</h1>\n```\n\n```ruby\n# recipes/default.rb\ntemplate '/var/www/html/index.html' do\n  source 'index.html.erb'\nend\n```\n\n---\n\n### 🔸 Data Bags\n\n```bash\n# Create data bag and item\nknife data bag create users\nknife data bag from file users user1.json\n```\n\n```json\n// users/user1.json\n{\n  \"id\": \"user1\",\n  \"uid\": \"1001\",\n  \"shell\": \"/bin/bash\"\n}\n```\n\n```ruby\n# Use in recipe\nuser_data = data_bag_item('users', 'user1')\n\nuser user_data['id'] do\n  uid user_data['uid']\n  shell user_data['shell']\nend\n```\n\n---\n\n### 🔸 Roles\n\n```bash\n# Create role file\nknife role create webserver\n```\n\n```json\n{\n  \"name\": \"webserver\",\n  \"run_list\": [\n    \"recipe[my_cookbook::default]\"\n  ]\n}\n```\n\n---\n\n### 🔸 Environments\n\nUsed to manage differences between dev, test, prod.\n\n```bash\n# Create environment\nknife environment create dev\n```\n\n```json\n{\n  \"name\": \"dev\",\n  \"default_attributes\": {\n    \"my_cookbook\": {\n      \"greeting\": \"Welcome to Dev Environment\"\n    }\n  }\n}\n```\n\n---\n\n## 🔴 Advanced Level\n\n### 🔹 Custom Resources\n\n```bash\n# inside cookbooks/my_cookbook/resources/hello.rb\nresource_name :hello\n\nproperty :name, String, name_property: true\n\naction :create do\n  file \"/tmp/#{name}\" do\n    content \"Hello, #{name}!\"\n  end\nend\n```\n\n```ruby\n# recipes/default.rb\nhello 'chef_user'\n```\n\n---\n\n### 🔹 ChefSpec (Unit Testing)\n\n```ruby\n# spec/unit/recipes/default_spec.rb\nrequire 'chefspec'\n\ndescribe 'my_cookbook::default' do\n  let(:chef_run) { ChefSpec::SoloRunner.new.converge(described_recipe) }\n\n  it 'installs nginx' do\n    expect(chef_run).to install_package('nginx')\n  end\nend\n```\n\nRun tests:\n\n```bash\nrspec\n```\n\n---\n\n### 🔹 Test Kitchen (Integration Testing)\n\n```bash\n# .kitchen.yml\ndriver:\n  name: vagrant\n\nprovisioner:\n  name: chef_zero\n\nplatforms:\n  - name: ubuntu-20.04\n\nsuites:\n  - name: default\n    run_list:\n      - recipe[my_cookbook::default]\n```\n\n```bash\nkitchen converge\nkitchen verify\n```\n\n---\n\n### 🔹 Policyfiles\n\nAlternative to Berkshelf and runlists.\n\n```bash\nchef generate policyfile my_policy\n```\n\n```ruby\n# Policyfile.rb\nname 'my_policy'\nrun_list 'my_cookbook::default'\ndefault_source :supermarket\ncookbook 'my_cookbook', path: '.'\n```\n\n```bash\nchef install\nchef push my_org my_policy.lock.json\n```\n\n---\n\n### 🔹 Chef Automate\n\nChef Automate provides UI and compliance, visibility, and workflow capabilities.\n\n* Setup dashboards\n* Integrate with InSpec for audits\n* Workflow pipelines for cookbook CI/CD\n\n---\n\n### 🔹 Knife Tips\n\n```bash\nknife bootstrap IP_ADDRESS -x user -P password --node-name NODE_NAME\nknife node list\nknife cookbook upload my_cookbook\nknife role from file webserver.json\n```\n\n---\n\n## 📌 Best Practices\n\n* Keep cookbooks modular and reusable.\n* Use Berkshelf or Policyfiles to manage dependencies.\n* Write tests (ChefSpec/Test Kitchen) for stability.\n* Avoid hardcoding; use attributes or data bags.\n* Prefer custom resources over LWRPs.\n",
  "Infrastructure-Management/Puppet": "# 🤖 Puppet Cheat Sheet\n\n[![puppet-cheat.png](https://i.postimg.cc/HkpyTqyw/puppet-cheat.png)](https://postimg.cc/8j05Hnwc)\n\n## 📘 Introduction\n\n[Puppet](https://puppet.com) is an **open-source configuration management tool** that automates infrastructure provisioning, configuration, and management. It uses a **declarative language** to describe the desired state of your systems.\n\nPuppet supports both **agent-master** and **agentless (bolt)** architectures, making it powerful for large-scale environments.\n\n---\n\n## 🧠 Key Concepts\n\n| Term         | Description                                                                |\n| ------------ | -------------------------------------------------------------------------- |\n| **Manifest** | A file written in Puppet DSL (.pp) that describes desired system state.    |\n| **Module**   | A collection of manifests, templates, files, etc., organized in structure. |\n| **Class**    | Reusable block of Puppet code.                                             |\n| **Resource** | Basic unit that describes something (like a package or service).           |\n| **Facts**    | System information gathered by **Facter**.                                 |\n| **Catalog**  | Compiled version of the manifests specific to a node.                      |\n| **Node**     | A client machine being managed.                                            |\n\n---\n\n## 🧾 Puppet Commands\n\n<details>\n<summary>🟢 Beginner Commands (Click to Expand)</summary>\n\n### 🔹 Check Version\n\n```bash\npuppet --version\n```\n\n### 🔹 Apply Manifest Locally\n\n```bash\npuppet apply example.pp\n```\n\n### 🔹 Validate Syntax of Manifest\n\n```bash\npuppet parser validate example.pp\n```\n\n### 🔹 Format Manifests (Linting)\n\n```bash\npuppet parser validate example.pp\npuppet-lint example.pp\n```\n\n### 🔹 List Available Facts\n\n```bash\nfacter\nfacter os\n```\n\n### 🔹 View Help\n\n```bash\npuppet help\npuppet help apply\n```\n\n</details>\n\n---\n\n<details>\n<summary>🟡 Intermediate Commands (Click to Expand)</summary>\n\n### 🔹 Puppet Resource (Inspect or Manage)\n\n```bash\npuppet resource <type>\npuppet resource user root\npuppet resource service ssh\n```\n\n### 🔹 Generate New Module Skeleton\n\n```bash\npuppet module generate yourname-modulename\n```\n\n### 🔹 Install a Module\n\n```bash\npuppet module install puppetlabs-apache\n```\n\n### 🔹 List Installed Modules\n\n```bash\npuppet module list\n```\n\n### 🔹 Check Current Puppet Config\n\n```bash\npuppet config print\npuppet config print all\n```\n\n</details>\n\n---\n\n<details>\n<summary>🔴 Advanced Commands (Click to Expand)</summary>\n\n### 🔹 Agent Commands\n\n```bash\npuppet agent -t\npuppet agent -t --debug\n```\n\n### 🔹 Manage Certificates\n\n```bash\npuppetserver ca list\npuppetserver ca sign --certname node.example.com\npuppetserver ca revoke --certname node.example.com\npuppetserver ca clean --certname node.example.com\n```\n\n### 🔹 PuppetDB Query\n\n```bash\npuppet query 'inventory[certname] { facts.os.name = \"Ubuntu\" }'\n```\n\n### 🔹 Run Task with Bolt\n\n```bash\nbolt command run \"uptime\" --targets localhost\nbolt plan run myplan\n```\n\n### 🔹 Testing & Debugging\n\n```bash\npuppet apply --noop file.pp\npuppet apply --debug file.pp\npuppet lookup varname\npuppet describe <type>\n```\n\n### 🔹 System & Config\n\n```bash\npuppet config print <setting>\npuppet facts show\npuppet module search apache\npuppet doc <module>\npuppet resource --to_yaml\n```\n\n</details>\n\n---\n\n## 🟢 Beginner Level\n\n### 🔹 Installing Puppet (Agent/Master)\n\n```bash\n# Install Puppet (Debian/Ubuntu)\nsudo apt install puppet\n\n# Check version\npuppet --version\n```\n\n---\n\n### 🔹 First Manifest Example\n\n```puppet\n# hello.pp\nfile { '/tmp/hello.txt':\n  ensure  => present,\n  content => \"Hello from Puppet!\",\n}\n```\n\nRun it:\n\n```bash\npuppet apply hello.pp\n```\n\n---\n\n### 🔹 Resource Types\n\n| Type        | Example                             |\n| ----------- | ----------------------------------- |\n| **file**    | Manage files, directories, symlinks |\n| **package** | Install, remove software            |\n| **service** | Ensure a service is running/stopped |\n| **user**    | Manage system users                 |\n\n```puppet\n# Install nginx and ensure it runs\npackage { 'nginx':\n  ensure => installed,\n}\n\nservice { 'nginx':\n  ensure => running,\n  enable => true,\n}\n```\n\n---\n\n### 🔹 Variables\n\n```puppet\n$greeting = \"Hello, World\"\nnotice($greeting)\n```\n\n---\n\n### 🔹 Conditionals\n\n```puppet\nif $osfamily == 'Debian' {\n  notice(\"Debian-based system\")\n} else {\n  notice(\"Other OS\")\n}\n```\n\n---\n\n## 🟡 Intermediate Level\n\n### 🔸 Facts and Facter\n\nView system facts:\n\n```bash\nfacter\nfacter os\n```\n\nUse in manifests:\n\n```puppet\nif $facts['os']['family'] == 'RedHat' {\n  package { 'httpd': ensure => installed }\n}\n```\n\n---\n\n### 🔸 Classes\n\n```puppet\nclass apache {\n  package { 'apache2': ensure => installed }\n  service { 'apache2': ensure => running }\n}\n```\n\nInclude it:\n\n```puppet\ninclude apache\n```\n\n---\n\n### 🔸 Modules\n\n```bash\npuppet module generate yourname-apache\npuppet module install puppetlabs-apache\n```\n\nStructure:\n\n```\napache/\n├── manifests/\n│   └── init.pp\n├── files/\n├── templates/\n```\n\nUse:\n\n```puppet\nclass { 'apache': }\n```\n\n---\n\n### 🔸 Templates (ERB)\n\nFile: `templates/vhost.erb`\n\n```erb\n<VirtualHost *:80>\n  ServerName <%= @servername %>\n</VirtualHost>\n```\n\nManifest:\n\n```puppet\nfile { '/etc/httpd/conf.d/vhost.conf':\n  content => template('apache/vhost.erb'),\n}\n```\n\n---\n\n### 🔸 Puppet Apply vs Agent\n\n| Mode      | Usage                                  |\n| --------- | -------------------------------------- |\n| **Apply** | Local apply of manifests               |\n| **Agent** | Connects to master and applies catalog |\n\n---\n\n## 🔴 Advanced Level\n\n### 🔹 Puppet Master-Agent Setup\n\n* **Puppet Server**: Central server managing infrastructure.\n* **Agent**: Node that pulls configuration from the server.\n\n```bash\n# On agent\npuppet agent -t\n```\n\nSign certs:\n\n```bash\npuppetserver ca list\npuppetserver ca sign --certname <agent-fqdn>\n```\n\n---\n\n### 🔹 Environments\n\nUsed to separate dev, staging, prod configs.\n\nDirectory structure:\n\n```\n/etc/puppetlabs/code/environments/\n├── production/\n│   └── manifests/\n├── development/\n```\n\n---\n\n### 🔹 Hiera (Hierarchical Data Lookup)\n\nConfigure external data in YAML:\n\n```yaml\n# hiera.yaml\nversion: 5\ndefaults:\n  datadir: data\n  data_hash: yaml_data\n\n# data/common.yaml\napache::port: 80\n```\n\nAccess in Puppet:\n\n```puppet\n$port = lookup('apache::port')\n```\n\n---\n\n### 🔹 PuppetDB\n\nCentral storage for catalog, fact, and report data.\n\nQuery:\n\n```puppet\nquery_nodes(['=', 'catalog_environment', 'production'])\n```\n\n---\n\n### 🔹 Bolt (Agentless Task Runner)\n\n```bash\nbolt command run 'uptime' --targets localhost\nbolt plan run myplan\n```\n\nWrite plans in YAML or Puppet DSL.\n\n---\n\n## 📌 Useful Puppet CLI Commands\n\n| Command                          | Description                   |\n| -------------------------------- | ----------------------------- |\n| `puppet apply <file.pp>`         | Apply a manifest locally      |\n| `puppet agent -t`                | Trigger agent run             |\n| `puppet resource <type> <name>`  | View current resource state   |\n| `puppet module install <name>`   | Install a module              |\n| `puppet config print all`        | Print all config settings     |\n| `puppet parser validate file.pp` | Validate syntax of manifest   |\n| `facter`                         | Show system facts             |\n| `puppet doc <module>`            | Generate module documentation |\n\n---\n\n## 📚 Learning Resources\n\n* 📘 [Official Docs](https://puppet.com/docs/puppet/latest/puppet_index.html)\n* 📦 [Forge Modules](https://forge.puppet.com/)\n* 🧪 [Bolt (Task Runner)](https://puppet.com/docs/bolt/latest/bolt.html)\n* 📖 [Puppet DSL Cheat Sheet](https://puppet.com/docs/puppet/latest/lang_summary.html)\n* 🧠 [Learn Puppet Free Courses](https://learn.puppet.com)\n\n---\n",
  "Infrastructure-Management/Terraform": "# 🧾 Terraform Cheat Sheet (Beginner → Advanced)\n\n![text](https://imgur.com/FwmjyK1.png)\n\n## 📘 **Introduction**\n\nTerraform by [HashiCorp](https://www.hashicorp.com/products/terraform) is an **open-source Infrastructure as Code (IaC)** tool used to provision and manage cloud, on-prem, and SaaS infrastructure through configuration files written in **HCL (HashiCorp Configuration Language)**.\n\nWith Terraform, you define infrastructure in a **declarative format**, allowing for versioning, reusability, automation, and consistency across environments.\n\n## 🔹 **Key Concepts**\n\n| Term           | Description                                                            |\n| -------------- | ---------------------------------------------------------------------- |\n| **Providers**  | Plugin responsible for managing a specific cloud platform (e.g., AWS). |\n| **Resources**  | Infrastructure components like EC2, S3, etc.                           |\n| **Variables**  | Input values passed into configuration.                                |\n| **Outputs**    | Values that Terraform returns after execution.                         |\n| **State File** | Keeps track of resources Terraform manages.                            |\n\n---\n\n## 🌍 Terraform Commands\n\n<details>\n<summary>🟢 Beginner Commands (Click to Expand)</summary>\n\n### 🔹 Check Version\n\n```bash\nterraform version\n```\n\n### 🔹 Initialize Working Directory\n\n```bash\nterraform init\n```\n\n### 🔹 Validate Configuration\n\n```bash\nterraform validate\n```\n\n### 🔹 Format Code\n\n```bash\nterraform fmt\n```\n\n### 🔹 Show Help\n\n```bash\nterraform -help\nterraform plan -help\n```\n\n</details>\n\n---\n\n<details>\n<summary>🟡 Intermediate Commands (Click to Expand)</summary>\n\n### 🔹 Plan Infrastructure Changes\n\n```bash\nterraform plan\n```\n\n### 🔹 Apply Infrastructure Changes\n\n```bash\nterraform apply\n```\n\n### 🔹 Destroy Infrastructure\n\n```bash\nterraform destroy\n```\n\n### 🔹 Output Variables\n\n```bash\nterraform output\nterraform output my_variable\n```\n\n### 🔹 Manage State\n\n```bash\nterraform state list\nterraform state show <resource>\n```\n\n</details>\n\n---\n\n<details>\n<summary>🔴 Advanced Commands (Click to Expand)</summary>\n\n### 🔹 Target Specific Resources\n\n```bash\nterraform apply -target=aws_instance.example\nterraform destroy -target=module.vpc\n```\n\n### 🔹 Work with Modules\n\n```bash\nterraform get\nterraform init -upgrade\n```\n\n### 🔹 Backend Configuration\n\n```bash\nterraform init -backend-config=\"key=my-state.tfstate\"\n```\n\n### 🔹 Import Existing Infrastructure\n\n```bash\nterraform import aws_instance.example i-12345678\n```\n\n### 🔹 Graph Dependency Tree\n\n```bash\nterraform graph | dot -Tpng > graph.png\n```\n\n</details>\n\n---\n\n## 🟢 **Beginner Commands**\n\n### 🔹 `terraform version`\n\nShows the installed version of Terraform.\n\n```bash\nterraform version\n```\n\n---\n\n### 🔹 `terraform init`\n\nInitializes the working directory with provider plugins and backend config.\n\n```bash\nterraform init\n```\n\n💡 Run this once per project after writing your `.tf` files.\n\n---\n\n### 🔹 `terraform validate`\n\nValidates your configuration files for syntax errors.\n\n```bash\nterraform validate\n```\n\n---\n\n### 🔹 `terraform plan`\n\nShows what actions Terraform *will* take without applying them.\n\n```bash\nterraform plan\n```\n\n📌 Use before every `apply` to preview infrastructure changes.\n\n---\n\n### 🔹 `terraform apply`\n\nApplies changes to reach the desired infrastructure state.\n\n```bash\nterraform apply\n```\n\n* You can auto-approve with:\n\n```bash\nterraform apply -auto-approve\n```\n\n---\n\n### 🔹 `terraform destroy`\n\nRemoves infrastructure defined in the configuration files.\n\n```bash\nterraform destroy\n```\n\n* Auto-confirm with:\n\n```bash\nterraform destroy -auto-approve\n```\n\n---\n\n### 🔹 `terraform fmt`\n\nAutomatically formats `.tf` files to canonical style.\n\n```bash\nterraform fmt\n```\n\n* Format all recursively:\n\n```bash\nterraform fmt -recursive\n```\n\n---\n\n## 🟡 **Intermediate Commands**\n\n### 🔹 `terraform show`\n\nDisplays human-readable output of the current or saved state.\n\n```bash\nterraform show\nterraform show terraform.tfstate\n```\n\n---\n\n### 🔹 `terraform output`\n\nPrints the values of output variables after apply.\n\n```bash\nterraform output\nterraform output instance_ip\n```\n\n---\n\n### 🔹 `terraform state list`\n\nLists all resources tracked in the current state file.\n\n```bash\nterraform state list\n```\n\n---\n\n### 🔹 `terraform state show`\n\nDisplays details about a specific resource in the state.\n\n```bash\nterraform state show aws_instance.example\n```\n\n---\n\n### 🔹 `terraform taint`\n\nForces recreation of a resource on the next apply.\n\n```bash\nterraform taint aws_instance.example\n```\n\n---\n\n### 🔹 `terraform untaint`\n\nRemoves taint from a resource.\n\n```bash\nterraform untaint aws_instance.example\n```\n\n---\n\n### 🔹 `terraform import`\n\nBrings existing infrastructure into Terraform state.\n\n```bash\nterraform import aws_instance.example i-0abcd1234efgh5678\n```\n\n---\n\n### 🔹 `terraform graph`\n\nGenerates a dependency graph (in DOT format).\n\n```bash\nterraform graph | dot -Tpng > graph.png\n```\n\n---\n\n### 🔹 `terraform providers`\n\nLists all providers used in the current configuration.\n\n```bash\nterraform providers\n```\n\n---\n\n### 🔹 `terraform workspace` commands\n\nUsed to manage multiple workspaces (e.g., dev, staging, prod).\n\n```bash\nterraform workspace new dev\nterraform workspace select dev\nterraform workspace list\n```\n\n---\n\n## 🔴 **Advanced Commands**\n\n### 🔹 `terraform plan -out=tfplan`\n\nSaves the execution plan to a file.\n\n```bash\nterraform plan -out=tfplan\n```\n\nThen apply it later:\n\n```bash\nterraform apply tfplan\n```\n\n---\n\n### 🔹 `terraform apply -target=resource`\n\nApply only specific resources.\n\n```bash\nterraform apply -target=aws_instance.example\n```\n\n---\n\n### 🔹 `terraform state mv`\n\nMoves/renames resources in the state.\n\n```bash\nterraform state mv aws_instance.old aws_instance.new\n```\n\n---\n\n### 🔹 `terraform state rm`\n\nRemoves resource from state (does NOT destroy it in the cloud).\n\n```bash\nterraform state rm aws_instance.example\n```\n\n---\n\n### 🔹 `terraform console`\n\nOpens an interactive console to evaluate HCL expressions.\n\n```bash\nterraform console\n> var.instance_type\n```\n\n---\n\n### 🔹 `terraform login`\n\nAuthenticates to Terraform Cloud or Enterprise.\n\n```bash\nterraform login\n```\n\n---\n\n### 🔹 `terraform logout`\n\nLogs out from Terraform Cloud.\n\n```bash\nterraform logout\n```\n\n---\n\n### 🔹 `terraform force-unlock`\n\nForce-unlocks a state file after a failed operation.\n\n```bash\nterraform force-unlock <LOCK_ID>\n```\n\n---\n\n## 📌 **Common Command Workflows**\n\n### 🛠 New Project\n\n```bash\nterraform init\nterraform plan\nterraform apply\n```\n\n### 🔁 Make a Change\n\n```bash\nterraform fmt\nterraform validate\nterraform plan\nterraform apply\n```\n\n### 🧽 Destroy Infra\n\n```bash\nterraform destroy\n```\n\nGreat — here’s the full version of the `Terraform.md` cheat sheet with **introductory info at the top** and **additional learning resources at the bottom**, perfect for your repo:\n\n---\n\n## 🧠 **Tips & Best Practices**\n\n* Keep `.tfstate` files **secure** (use S3 + DynamoDB for remote locking)\n* Use `terraform.tfvars` or `.auto.tfvars` for sensitive input variables\n* Mark secrets using `sensitive = true` in outputs\n* Use **modules** for reusable code\n* Always run `terraform plan` before `apply`\n* Version-lock providers in `required_providers`\n\n---\n\n## 📚 **Learning Resources**\n\n* 🔗 [Official Docs](https://developer.hashicorp.com/terraform/docs)\n* 📘 [Terraform Registry](https://registry.terraform.io/)\n* 🎓 [Learn Terraform (Free)](https://learn.hashicorp.com/terraform)\n* 🧪 [Checkov - IaC Scanning](https://www.checkov.io/)\n* 📖 [Terraform CLI Reference](https://developer.hashicorp.com/terraform/cli)\n",
  "Version-Control/Bitbucket": "# BitBucket Cheatsheet\n\n![text](https://imgur.com/7PDN0aZ.png)\n\nBitbucket, developed by Atlassian, is a Git-based source code repository hosting service. It is designed for teams and provides strong integration with other Atlassian tools like Jira, Trello, and Confluence. This cheatsheet provides a detailed guide for mastering Bitbucket from basic operations to advanced features.\n\n---\n\n## **1. Introduction to Bitbucket**\n\n### What is Bitbucket?\n\n- Bitbucket is a Git-based platform for version control, CI/CD pipelines, and project collaboration.\n- It supports both **private** and **public repositories**.\n- Known for its seamless integration with Atlassian tools (e.g., Jira) and in-built CI/CD pipelines.\n\n### Key Features\n\n- Git repository hosting\n- In-built CI/CD via **Bitbucket Pipelines**\n- Jira integration for issue tracking\n- Branch permissions and code review tools\n- Supports Mercurial (deprecated)\n\n---\n\n## **2. Getting Started**\n\n### Creating a Bitbucket Account\n\n1. Go to [Bitbucket](https://bitbucket.org/) and sign up for an account.\n2. Optionally, link your Atlassian account for better integration.\n\n### Setting Up SSH Keys\n\n1. Generate an SSH key:\n\n   ```bash\n   ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\"\n   ```\n\n2. Add the public key to Bitbucket:\n   - Navigate to **Personal Settings** → **SSH Keys** → **Add Key**.\n\n### Creating a Repository\n\n1. Log in to Bitbucket.\n2. Go to **Repositories** → **Create Repository**.\n3. Configure:\n   - Repository Name\n   - Access level (Private/Public)\n   - Repository Type (Git)\n\n---\n\n## **3. Basic Operations**\n\n### Cloning a Repository\n\n```bash\ngit clone git@bitbucket.org:username/repository.git\n```\n\n### Staging, Committing, and Pushing\n\n```bash\n# Stage changes\ngit add .\n# Commit changes\ngit commit -m \"Initial commit\"\n# Push changes\ngit push origin main\n```\n\n### Pulling Changes\n\n```bash\ngit pull origin main\n```\n\n---\n\n## **4. Branching and Merging**\n\n### Creating and Switching Branches\n\n```bash\n# Create a new branch\ngit checkout -b feature-branch\n# Switch to an existing branch\ngit checkout main\n```\n\n### Pushing a Branch\n\n```bash\ngit push origin feature-branch\n```\n\n### Creating a Pull Request (PR)\n\n1. Open Bitbucket and navigate to **Pull Requests**.\n2. Click **Create Pull Request**.\n3. Select branches, add reviewers, and provide a description.\n\n### Merging Pull Requests\n\n1. Approve the PR.\n2. Merge using the options:\n   - **Merge Commit**: Keeps all commits intact.\n   - **Squash Merge**: Combines all commits into one.\n   - **Rebase**: Rewrites commit history.\n\n---\n\n## **5. Bitbucket Pipelines (CI/CD)**\n\n### Overview\n\nBitbucket Pipelines is an integrated CI/CD service to automate builds, tests, and deployments.\n\n### Enabling Pipelines\n\n1. Go to the repository settings → **Pipelines**.\n2. Enable Pipelines and configure the `.bitbucket-pipelines.yml` file.\n\n### Sample Pipeline Configuration\n\n```yaml\npipelines:\n  default:\n    - step:\n        name: Build and Test\n        image: node:14\n        script:\n          - npm install\n          - npm test\n    - step:\n        name: Deploy to Production\n        script:\n          - echo \"Deploying to production...\"\n```\n\n### Key Triggers\n\n- **default**: Runs on any branch when pushed.\n- **branches**: Customizes triggers for specific branches.\n- **tags**: Automates deployment for version tags.\n\n### Variables and Secrets\n\n1. Go to **Repository Settings** → **Pipelines** → **Environment Variables**.\n2. Add sensitive variables like `AWS_ACCESS_KEY`.\n\n#### Using Variables in Pipelines\n\n```yaml\nscript:\n  - echo \"Using secret: $AWS_ACCESS_KEY\"\n```\n\n---\n\n## **6. Branch Permissions and Access Control**\n\n### Branch Permissions\n\n1. Go to **Repository Settings** → **Branch Permissions**.\n2. Add rules such as:\n   - Prevent direct pushes to `main`.\n   - Require at least 2 code reviews before merging.\n\n### User Roles\n\n- **Admin**: Full control over repositories and permissions.\n- **Write**: Can push and pull code.\n- **Read**: Read-only access to repositories.\n\n---\n\n## **7. Integration with Jira**\n\n### Linking a Repository to Jira\n\n1. Go to **Repository Settings** → **Jira Settings**.\n2. Connect the repository to a Jira project.\n\n### Automating Issue Tracking\n\n- Add Jira issue keys in commit messages:\n\n  ```text\n  PROJ-123: Fix login page bug\n  ```\n\n- Jira automatically links commits, pull requests, and deployments.\n\n---\n\n## **8. Code Review and Quality**\n\n### Using Pull Requests for Code Review\n\n1. Assign reviewers while creating a pull request.\n2. Add comments inline to highlight issues.\n\n### Integrating Code Quality Tools\n\n- Add tools like **SonarCloud** or **CodeClimate** to your pipelines for static code analysis.\n- Example: Adding SonarCloud to Bitbucket Pipelines:\n\n  ```yaml\n  - pipe: sonarsource/sonarcloud-scan:1.4.0\n    variables:\n      SONAR_TOKEN: $SONAR_TOKEN\n  ```\n\n---\n\n## **9. Bitbucket API**\n\n### Authenticating\n\nGenerate a personal access token:\n\n1. Go to **Personal Settings** → **Access Management** → **Create App Password**.\n\nUse the token in API calls:\n\n```bash\ncurl -u username:app_password https://api.bitbucket.org/2.0/repositories\n```\n\n### Common API Endpoints\n\n- List repositories:\n\n  ```bash\n  curl -X GET https://api.bitbucket.org/2.0/repositories/{username}\n  ```\n\n- Create an issue:\n\n  ```bash\n  curl -X POST -u username:app_password \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"title\": \"Bug in Login Page\", \"content\": {\"raw\": \"Description\"}}' \\\n  https://api.bitbucket.org/2.0/repositories/{username}/{repo}/issues\n  ```\n\n---\n\n## **10. Advanced Features**\n\n### Deployments with Bitbucket Pipelines\n\nTrack deployment environments:\n\n1. Go to **Deployments** → Configure environments (e.g., Dev, Staging, Prod).\n\nAdd deployment steps in `.bitbucket-pipelines.yml`:\n\n```yaml\npipelines:\n  branches:\n    main:\n      - step:\n          name: Deploy to Staging\n          deployment: staging\n          script:\n            - ./deploy.sh staging\n```\n\n### Monorepo Support\n\nHost multiple services in one repository:\n\n- Use Pipelines for individual service builds:\n\n  ```yaml\n  pipelines:\n    default:\n      - step:\n          name: Build Service A\n          script:\n            - cd services/service-a && npm install && npm test\n  ```\n\n### Mirror Repositories\n\nMirror a repository between Bitbucket and GitHub:\n\n```bash\ngit remote add bitbucket git@bitbucket.org:username/repo.git\ngit push bitbucket --mirror\n```\n\n---\n\n## **11. Security and Best Practices**\n\n### Enforcing Two-Factor Authentication (2FA)\n\n1. Go to **Personal Settings** → **Security** → Enable 2FA.\n\n### Secret Scanning\n\nBitbucket scans for hard-coded credentials and alerts users.\n\n### Dependency Scanning\n\nUse Atlassian tools like **Snyk** or **Dependabot** to identify vulnerabilities.\n\n---\n\n## **12. Best Practices**\n\n1. **Branch Naming Convention**:\n   - Use prefixes like `feature/`, `bugfix/`, and `release/`.\n\n   ```text\n   feature/add-login-form\n   bugfix/fix-authentication-error\n   ```\n\n2. **Commit Messages**:\n   - Follow a format like:\n\n     ```text\n     [PROJ-123] Fix bug in login functionality\n     ```\n\n   - Reference Jira issues in commit messages.\n\n3. **Automate Everything**:\n   - Use Pipelines for CI/CD.\n   - Automate linting, testing, and deployment.\n\n4. **Use Pull Request Templates**:\n   - Add `.bitbucket/pull_request_template.md` to standardize PR descriptions.\n\n---\n\n## **13. References and Resources**\n\n- [Bitbucket Documentation](https://bitbucket.org/product/)\n- [Bitbucket API Documentation](https://developer.atlassian.com/bitbucket/api/2/reference/)\n- [Pipelines Guide](https://bitbucket.org/product/features/pipelines)\n",
  "Version-Control/GitHub": "# Github Cheatsheet\n\n![text](https://imgur.com/c189VXy.png)\n\n**GitHub** is a powerful platform for version control, collaboration, CI/CD automation, and DevOps workflows. This cheatsheet provides an in-depth guide to using GitHub, covering basic operations to advanced features.\n\n---\n\n## 1. **Introduction to GitHub**\n\n### What is GitHub?\n\nGitHub is a web-based platform that uses Git for version control and provides tools for:\n\n- Collaborative software development\n- CI/CD automation\n- Project management\n- Code review and DevOps integration\n\n### Key Features\n\n- **Git Repositories**: Centralized code hosting with Git.\n- **Collaboration**: Pull requests, code reviews, and discussions.\n- **Actions**: Automate workflows with GitHub Actions.\n- **Project Management**: Boards, issues, and milestones for agile workflows.\n- **Security**: Dependabot alerts and code scanning for vulnerabilities.\n\n---\n\n## 2. **Getting Started**\n\n### Creating an Account\n\n1. Sign up at [GitHub](https://github.com/).\n2. Create or join an organization for team collaboration.\n\n### Adding SSH Keys\n\n1. Generate an SSH key:\n\n   ```bash\n   ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\"\n   ```\n\n2. Add the key to your GitHub account:\n   - Go to **Settings** → **SSH and GPG keys** → Add Key.\n\n### Creating a Repository\n\n1. Go to **Repositories** → **New**.\n2. Configure repository name, description, and visibility.\n3. Add a `.gitignore` file or license if needed.\n\n---\n\n## 3. **Basic GitHub Operations**\n\n### Cloning a Repository\n\n```bash\ngit clone git@github.com:username/repository.git\n```\n\n### Committing and Pushing Changes\n\n```bash\n# Stage changes\ngit add .\n# Commit changes\ngit commit -m \"Initial commit\"\n# Push changes\ngit push origin main\n```\n\n### Pulling Changes\n\n```bash\ngit pull origin main\n```\n\n---\n\n## 4. **Branching and Merging**\n\n### Creating and Switching Branches\n\n```bash\n# Create a new branch\ngit checkout -b feature-branch\n# Switch to an existing branch\ngit checkout main\n```\n\n### Pushing a Branch\n\n```bash\ngit push origin feature-branch\n```\n\n### Merging Branches\n\n1. Open a **Pull Request** on GitHub:\n   - Navigate to the repository → **Pull Requests** → **New Pull Request**.\n2. Review and merge changes.\n\n### Deleting a Branch\n\n```bash\n# Delete locally\ngit branch -d feature-branch\n# Delete on remote\ngit push origin --delete feature-branch\n```\n\n---\n\n## 5. **GitHub Issues and Project Boards**\n\n### Creating an Issue\n\n1. Go to **Issues** → **New Issue**.\n2. Add title, description, and assign labels or assignees.\n\n### Automating Project Boards\n\n- **Add Issues Automatically**:\n  1. Go to the project board.\n  2. Set up automation rules like \"Add issues in progress.\"\n\n### Linking Pull Requests to Issues\n\nUse keywords in PR descriptions:\n\n```text\nFixes #issue_number\nCloses #issue_number\n```\n\n---\n\n## 6. **GitHub Actions (CI/CD)**\n\nGitHub Actions is a workflow automation tool for CI/CD.\n\n### Basics of `.github/workflows/<workflow>.yml`\n\n#### Example Workflow:\n\n```yaml\nname: CI Pipeline\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout Code\n        uses: actions/checkout@v3\n      - name: Install Dependencies\n        run: npm install\n      - name: Run Tests\n        run: npm test\n```\n\n### Workflow Triggers\n\n- **push**: Runs the workflow when a commit is pushed.\n- **pull_request**: Triggers on pull requests.\n- **schedule**: Triggers on a cron schedule.\n\n### Managing Secrets\n\n1. Go to **Settings** → **Secrets and variables** → **Actions**.\n2. Add variables like `AWS_ACCESS_KEY_ID` or `DOCKER_PASSWORD`.\n\n### Example with Secrets\n\n```yaml\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Deploy to AWS\n        run: aws s3 sync ./build s3://my-bucket\n        env:\n          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}\n          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n```\n\n---\n\n## 7. **GitHub Packages**\n\n### Using GitHub as a Docker Registry\n\n1. Authenticate:\n\n   ```bash\n   docker login ghcr.io -u USERNAME -p TOKEN\n   ```\n\n2. Build and Push:\n\n   ```bash\n   docker build -t ghcr.io/username/image-name:tag .\n   docker push ghcr.io/username/image-name:tag\n   ```\n\n### Installing from GitHub Packages\n\n- Add dependency in `package.json` (Node.js):\n\n  ```json\n  \"dependencies\": {\n    \"package-name\": \"github:username/repository\"\n  }\n  ```\n\n---\n\n## 8. **Advanced GitHub Features**\n\n### Protecting Branches\n\n1. Go to **Settings** → **Branches**.\n2. Enable branch protection rules (e.g., prevent force-pushes, require PR reviews).\n\n### Code Review Automation\n\n- Use GitHub Apps like **CodeCov** or **LGTM** for automated code review.\n\n### Dependency Management with Dependabot\n\n1. Enable Dependabot under **Insights** → **Dependency Graph**.\n2. Dependabot creates pull requests to update outdated dependencies.\n\n---\n\n## 9. **GitHub Security**\n\n### Code Scanning\n\n1. Enable **Code Scanning Alerts** under **Security**.\n2. Include scanning actions in workflows:\n\n   ```yaml\n   - name: CodeQL Analysis\n     uses: github/codeql-action/analyze@v2\n   ```\n\n### Secret Scanning\n\n- GitHub scans public repositories for leaked secrets and alerts the repository owner.\n\n### Enabling 2FA\n\n1. Go to **Settings** → **Account Security** → Enable Two-Factor Authentication.\n\n---\n\n## 10. **GitHub CLI (gh)**\n\n### Installing GitHub CLI\n\n```bash\nbrew install gh  # macOS\nsudo apt install gh  # Linux\n```\n\n### Authenticating\n\n```bash\ngh auth login\n```\n\n### Common Commands\n\n- Clone a Repository:\n\n  ```bash\n  gh repo clone username/repository\n  ```\n\n- Create a Pull Request:\n\n  ```bash\n  gh pr create --title \"Feature Update\" --body \"Details of PR\"\n  ```\n\n- List Issues:\n\n  ```bash\n  gh issue list\n  ```\n\n---\n\n## 11. **GitHub API**\n\n### Using the API\n\nAuthenticate using a personal access token:\n\n```bash\ncurl -H \"Authorization: token YOUR_TOKEN\" https://api.github.com/user/repos\n```\n\n### Example: Creating an Issue\n\n```bash\ncurl -X POST -H \"Authorization: token YOUR_TOKEN\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\"title\": \"Bug Report\", \"body\": \"Description of the bug\"}' \\\nhttps://api.github.com/repos/username/repository/issues\n```\n\n---\n\n## 12. **GitHub Best Practices**\n\n- **Use Descriptive Commit Messages**:\n\n  ```text\n  Fix bug in login page #123\n  ```\n\n- **Enable Branch Protections** to enforce review processes.\n- **Automate Testing** using GitHub Actions for pull requests.\n- **Use Issues and Labels** for effective project tracking.\n\n---\n\n## References and Resources\n\n1. [GitHub Documentation](https://docs.github.com/)\n2. [GitHub CLI Documentation](https://cli.github.com/manual/)\n3. [GitHub Actions Guide](https://docs.github.com/en/actions)\n",
  "Version-Control/GitLab": "# GitLab Cheatsheet\n\n![text](https://imgur.com/QJ7J3qs.png)\n\n**GitLab** is a web-based DevOps platform that provides a robust set of tools for source code management, CI/CD, project management, and deployment automation. This cheatsheet covers everything from basic usage to advanced GitLab features.\n\n---\n\n## 1. **Introduction to GitLab**\n\n### What is GitLab?\n\nGitLab is an open-source DevOps platform offering integrated tools for:\n\n- Source control (Git)\n- Continuous Integration/Continuous Deployment (CI/CD)\n- Issue tracking and project management\n- Container registry and DevSecOps\n\n### Key Features\n\n- **Git Repository Management**: Handles distributed version control and code review.\n- **CI/CD Pipelines**: Automates testing, integration, and deployment.\n- **DevSecOps**: Built-in security scanning for dependencies, container images, and code.\n- **Container Registry**: Docker container management.\n\n---\n\n## 2. **Basic GitLab Setup**\n\n### Signing Up and Creating a Project\n\n1. **Sign up**: Visit [GitLab](https://gitlab.com/) and create an account.\n2. **Create a Project**:\n   - Go to **Projects** → **New Project**.\n   - Choose **Blank Project**, **Import**, or **Template**.\n   - Configure visibility (Private, Internal, or Public).\n\n### Adding SSH Keys\n\n1. Generate an SSH key:\n\n   ```bash\n   ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\"\n   ```\n\n2. Copy the public key:\n\n   ```bash\n   cat ~/.ssh/id_rsa.pub\n   ```\n\n3. Add the key in GitLab:\n   - Go to **User Settings** → **SSH Keys** → Paste the public key.\n\n---\n\n## 3. **GitLab Basics**\n\n### Cloning a Repository\n\n```bash\ngit clone git@gitlab.com:username/projectname.git\n```\n\n### Committing Changes\n\n```bash\n# Stage files\ngit add .\n# Commit files\ngit commit -m \"Initial commit\"\n# Push changes\ngit push origin main\n```\n\n### Branching\n\n- Create a branch:\n\n  ```bash\n  git checkout -b feature-branch\n  ```\n\n- Push the branch:\n\n  ```bash\n  git push origin feature-branch\n  ```\n\n### Merge Requests (MRs)\n\n1. Go to your project on GitLab.\n2. Navigate to **Merge Requests** → **New Merge Request**.\n3. Select source and target branches and create an MR.\n\n---\n\n## 4. **Working with GitLab CI/CD**\n\n### Basics of `.gitlab-ci.yml`\n\nThe `.gitlab-ci.yml` file defines the CI/CD pipeline.\n\n#### Example File:\n\n```yaml\nstages:\n  - build\n  - test\n  - deploy\n\nbuild_job:\n  stage: build\n  script:\n    - echo \"Building the project\"\n    - ./build-script.sh\n\ntest_job:\n  stage: test\n  script:\n    - echo \"Running tests\"\n    - ./test-script.sh\n\ndeploy_job:\n  stage: deploy\n  script:\n    - echo \"Deploying to production\"\n    - ./deploy-script.sh\n```\n\n### Pipeline Lifecycle\n\n1. **Stages**: Define steps (e.g., `build`, `test`, `deploy`).\n2. **Jobs**: Define tasks in each stage.\n3. **Runners**: Execute pipeline jobs (shared or custom).\n\n### Running a Pipeline\n\n- Push changes to a branch:\n\n  ```bash\n  git push origin branch-name\n  ```\n\n- Check pipelines:\n  - Navigate to **CI/CD** → **Pipelines** in GitLab.\n\n---\n\n## 5. **Intermediate GitLab Features**\n\n### GitLab Runners\n\n- Runners execute CI/CD jobs.\n- **Shared Runners**: Provided by GitLab.\n- **Custom Runners**: Self-hosted.\n\n#### Register a Custom Runner:\n\n1. Install GitLab Runner:\n\n   ```bash\n   sudo apt install gitlab-runner\n   ```\n\n2. Register the Runner:\n\n   ```bash\n   gitlab-runner register\n   ```\n\n   - Enter GitLab URL, registration token, executor (e.g., `shell`, `docker`), and tags.\n\n### Managing Variables\n\n- **Set Environment Variables**:\n  1. Go to **Settings** → **CI/CD** → **Variables**.\n  2. Add variables (e.g., `AWS_ACCESS_KEY`, `DOCKER_PASSWORD`).\n  \n- Use in `.gitlab-ci.yml`:\n\n  ```yaml\n  script:\n    - echo $MY_VARIABLE\n  ```\n\n### Artifacts\n\nArtifacts store job outputs.\n\n```yaml\ntest_job:\n  stage: test\n  script:\n    - ./run-tests\n  artifacts:\n    paths:\n      - test-results/\n```\n\n---\n\n## 6. **Advanced GitLab Features**\n\n### GitLab Pages\n\nHost static websites directly on GitLab.\n\n#### Example `.gitlab-ci.yml` for Pages:\n\n```yaml\npages:\n  stage: deploy\n  script:\n    - mkdir .public\n    - cp -r * .public\n  artifacts:\n    paths:\n      - public\n```\n\n### Container Registry\n\n- GitLab provides a built-in Docker registry for container storage.\n- **Push an Image**:\n\n  ```bash\n  docker build -t registry.gitlab.com/username/projectname:tag .\n  docker login registry.gitlab.com\n  docker push registry.gitlab.com/username/projectname:tag\n  ```\n\n### GitLab Kubernetes Integration\n\n- Integrate Kubernetes clusters with GitLab for deployments.\n- Navigate to **Operations** → **Kubernetes** to connect your cluster.\n\n#### Deploy Using Helm:\n\n```yaml\ndeploy:\n  stage: deploy\n  script:\n    - helm install my-app ./helm-chart\n```\n\n---\n\n## 7. **Security in GitLab**\n\n### SAST (Static Application Security Testing)\n\n- Enable SAST to scan for vulnerabilities:\n\n  ```yaml\n  include:\n    - template: Security/SAST.gitlab-ci.yml\n  ```\n\n### DAST (Dynamic Application Security Testing)\n\n- Perform runtime vulnerability scans:\n\n  ```yaml\n  include:\n    - template: Security/DAST.gitlab-ci.yml\n  ```\n\n### Secret Detection\n\n- Detect hardcoded secrets:\n\n  ```yaml\n  include:\n    - template: Security/Secret-Detection.gitlab-ci.yml\n  ```\n\n---\n\n## 8. **GitLab Monitoring and Analytics**\n\n### Pipeline Analytics\n\n- Navigate to **Analytics** → **CI/CD** → **Pipelines** to review pipeline efficiency.\n\n### Code Coverage\n\n- Enable coverage reports in `.gitlab-ci.yml`:\n\n  ```yaml\n  test_job:\n    stage: test\n    script:\n      - ./run-tests\n    coverage: '/Code Coverage: \\d+%/'\n  ```\n\n### Container Scanning\n\n- Scan Docker images for vulnerabilities:\n\n  ```yaml\n  include:\n    - template: Security/Container-Scanning.gitlab-ci.yml\n  ```\n\n---\n\n## 9. **GitLab Backup and Recovery**\n\n### Backing Up GitLab\n\n- For self-hosted GitLab, run:\n\n  ```bash\n  gitlab-backup create\n  ```\n\n- Backup includes repositories, CI/CD logs, uploads, and settings.\n\n### Restoring GitLab\n\n- Restore a backup:\n\n  ```bash\n  gitlab-restore restore BACKUP_FILE=backup_filename\n  ```\n\n---\n\n## 10. **Troubleshooting GitLab**\n\n### Common Errors\n\n- **Pipeline Failures**:\n  - Check pipeline logs in **CI/CD** → **Jobs**.\n- **Runner Issues**:\n  - Ensure the runner is active: `gitlab-runner status`.\n- **Permission Errors**:\n  - Verify SSH key and repository access.\n\n### Debugging CI/CD Pipelines\n\n- Add verbose logging:\n\n  ```yaml\n  script:\n    - echo \"Debugging info\"\n    - set -x\n    - ./my-script.sh\n  ```\n\n---\n\n## 11. **GitLab Best Practices**\n\n- **Use Branching Strategies**:\n  - Implement GitLab Flow or GitFlow for streamlined collaboration.\n- **Secure CI/CD Pipelines**:\n  - Use environment variables to manage sensitive data.\n- **Automate Reviews**:\n  - Use merge request templates and code owners.\n- **Leverage GitLab Templates**:\n  - Use pre-built `.gitlab-ci.yml` templates to save time.\n- **Monitor Usage**:\n  - Regularly check project and pipeline analytics.\n\n---\n\n## 12. **Useful GitLab CLI Commands**\n\n### Basic Commands\n\n- **Login to GitLab CLI**:\n\n  ```bash\n  glab auth login\n  ```\n\n- **List Repositories**:\n\n  ```bash\n  glab repo list\n  ```\n\n- **Create an Issue**:\n\n  ```bash\n  glab issue create --title \"Bug report\" --description \"Details here\"\n  ```\n\n---\n\n## References and Resources\n\n1. [GitLab Documentation](https://docs.gitlab.com/)\n2. [GitLab CI/CD Examples](https://docs.gitlab.com/ee/ci/examples/)\n3. [GitLab CLI](https://github.com/profclems/glab)\n",
  "Security/AquaSec": "# AquaSec Cheatsheet\n\n![text](https://imgur.com/8MBLV6G.png)\n\n**1. Introduction:**\n\n- **AquaSec** (Aqua Security) is a comprehensive security platform for securing containers, Kubernetes, and cloud-native applications throughout the CI/CD pipeline.\n\n**2. Installation:**\n\n- **Installing AquaSec:**\n  - AquaSec is usually deployed as a Kubernetes application.\n  - Download AquaSec from the [Aqua website](https://www.aquasec.com/) and follow the installation instructions for your environment.\n\n- **Dockerized Installation:**\n  - AquaSec components can also be installed using Docker images available on Docker Hub.\n\n**3. Basic Configuration:**\n\n- **Aqua Console:**\n  - The Aqua Console is the central management interface for configuring and monitoring AquaSec.\n  - Access the Aqua Console at `http://<aqua-console-ip>:8080`.\n\n- **User Management:**\n  - Create users and assign roles in the Aqua Console under the **Users** section.\n\n**4. Container Security:**\n\n- **Image Scanning:**\n  - AquaSec automatically scans container images for vulnerabilities, malware, and misconfigurations.\n  - Scans can be initiated via the Aqua Console or automated in CI/CD pipelines.\n\n- **Runtime Protection:**\n  - AquaSec provides real-time monitoring of running containers, blocking unauthorized activities based on predefined policies.\n\n**5. Kubernetes Security:**\n\n- **Kubernetes Admission Control:**\n  - AquaSec integrates with Kubernetes admission controllers to enforce security policies during the pod creation process.\n  - Policies can prevent the deployment of vulnerable or misconfigured containers.\n\n- **Network Segmentation:**\n  - AquaSec can segment Kubernetes network traffic using microsegmentation to restrict communication between pods.\n\n**6. Advanced Features:**\n\n- **Secrets Management:**\n  - AquaSec integrates with secrets management tools like HashiCorp Vault to secure sensitive data in containers and Kubernetes clusters.\n\n- **Compliance Auditing:**\n  - AquaSec provides auditing capabilities to ensure compliance with standards like PCI-DSS, HIPAA, and NIST.\n\n**7. AquaSec in CI/CD Pipelines:**\n\n- **Integrating with Jenkins:**\n  - Use the AquaSec Jenkins plugin to scan images as part of the build process and fail builds that do not meet security criteria.\n\n- **Automating Policies:**\n  - Define security policies that are automatically enforced across all stages of the pipeline.\n\n**8. Monitoring and Reporting:**\n\n- **Dashboards:**\n  - AquaSec provides detailed dashboards for monitoring vulnerabilities, policy violations, and runtime security events.\n\n- **Custom Alerts:**\n  - Configure alerts for specific security events, such as the detection of high-severity vulnerabilities or unauthorized access attempts.\n\n**9. Scaling AquaSec:**\n\n- **High Availability:**\n  - Deploy AquaSec in a high-availability configuration with multiple Aqua Consoles and databases to ensure resilience.\n\n- **Integrating with SIEMs:**\n  - AquaSec integrates with Security Information and Event Management (SIEM) systems like Splunk and IBM QRadar for centralized monitoring.\n\n**10. Troubleshooting AquaSec:**\n\n- **Common Issues:**\n  - **Failed Scans:** Ensure that the Aqua scanner is properly configured and has access to the image registry.\n  - **Policy Enforcement Issues:** Review policy definitions and ensure they are correctly applied.\n\n- **Debugging:**\n  - Check AquaSec logs for detailed error information and troubleshooting steps.\n",
  "Security/HashiCorp-Vault": "# HashiCorp Vault Cheatsheet\n\n![text](https://imgur.com/322q6Pi.png)\n\n**1. Introduction:**\n\n- **HashiCorp Vault** is a tool designed to securely store and access secrets. It can manage sensitive data such as passwords, API keys, and certificates.\n\n**2. Installation:**\n\n- **Installing Vault:**\n  - On macOS using Homebrew:\n\n    ```bash\n    brew install vault\n    ```\n\n  - On Linux:\n\n    ```bash\n    wget https://releases.hashicorp.com/vault/1.9.0/vault_1.9.0_linux_amd64.zip\n    unzip vault_1.9.0_linux_amd64.zip\n    sudo mv vault /usr/local/bin/\n    ```\n\n  - On Windows:\n    - Download the binary from the [official HashiCorp releases](https://www.vaultproject.io/downloads).\n\n**3. Basic Usage:**\n\n- **Initializing Vault:**\n\n  ```bash\n  vault operator init\n  ```\n\n  - This command initializes the Vault server, generating unseal keys and a root token.\n\n- **Unsealing Vault:**\n\n  ```bash\n  vault operator unseal <unseal-key-1>\n  vault operator unseal <unseal-key-2>\n  vault operator unseal <unseal-key-3>\n  ```\n\n  - Unseal Vault using the keys provided during initialization.\n\n- **Storing Secrets:**\n\n  ```bash\n  vault kv put secret/my-secret password=\"mypassword\"\n  ```\n\n  - This command stores a secret in Vault at the path `secret/my-secret`.\n\n- **Retrieving Secrets:**\n\n  ```bash\n  vault kv get secret/my-secret\n  ```\n\n  - Retrieves the secret stored at `secret/my-secret`.\n\n**4. Advanced Usage:**\n\n- **Dynamic Secrets:**\n  - Vault can generate secrets dynamically, such as database credentials that are created on-demand.\n  - Example: Generating MySQL credentials:\n\n    ```bash\n    vault write database/roles/my-role db_name=mydb creation_statements=\"CREATE USER '{{name}}'@'%' IDENTIFIED BY '{{password}}';\" default_ttl=\"1h\" max_ttl=\"24h\"\n    vault read database/creds/my-role\n    ```\n\n- **Secret Engines:**\n  - Vault supports multiple secret engines like KV, AWS, GCP, and more.\n  - Enable a secrets engine:\n\n    ```bash\n    vault secrets enable aws\n    ```\n\n  - Configure and use the AWS secrets engine:\n\n    ```bash\n    vault write aws/config/root access_key=<AWS_ACCESS_KEY> secret_key=<AWS_SECRET_KEY>\n    vault write aws/roles/my-role credential_type=iam_user policy_arns=arn:aws:iam::aws:policy/ReadOnlyAccess\n    ```\n\n**5. Authentication Methods:**\n\n- **Enabling Authentication Methods:**\n  - Vault supports various authentication methods, including AppRole, LDAP, and AWS.\n  - Enable an authentication method:\n\n    ```bash\n    vault auth enable approle\n    ```\n\n- **Configuring AppRole Authentication:**\n  - Create a role:\n\n    ```bash\n    vault write auth/approle/role/my-role token_policies=\"default\" token_ttl=1h token_max_ttl=4h\n    ```\n\n  - Retrieve the role ID and secret ID:\n\n    ```bash\n    vault read auth/approle/role/my-role/role-id\n    vault write -f auth/approle/role/my-role/secret-id\n    ```\n\n**6. Policies and Access Control:**\n\n- **Creating Policies:**\n  - Define a policy to control access to secrets:\n\n    ```hcl\n    path \"secret/data/*\" {\n      capabilities = [\"create\", \"read\", \"update\", \"delete\", \"list\"]\n    }\n    ```\n\n  - Apply the policy:\n\n    ```bash\n    vault policy write my-policy my-policy.hcl\n    ```\n\n**7. Vault in Production:**\n\n- **High Availability (HA):**\n  - Vault supports HA configurations using storage backends like Consul.\n  - Example Consul configuration:\n\n    ```bash\n    storage \"consul\" {\n      address = \"127.0.0.1:8500\"\n      path    = \"vault/\"\n    }\n    ```\n\n- **Performance Replication:**\n  - Vault Enterprise supports performance replication for scaling reads.\n\n**8. Integrations and Automation:**\n\n- **Terraform Integration:**\n  - Use the [Terraform Vault provider](https://registry.terraform.io/providers/hashicorp/vault/latest/docs) to manage Vault resources.\n  - Example Terraform configuration:\n\n    ```hcl\n    provider \"vault\" {}\n\n    resource \"vault_generic_secret\" \"example\" {\n      path = \"secret/example\"\n      data_json = <<EOT\n    {\n      \"password\": \"mypassword\"\n    }\n    EOT\n    }\n    ```\n\n- **CI/CD Integration:**\n  - Integrate Vault with CI/CD pipelines to inject secrets dynamically into build processes.\n\n**9. Monitoring and Auditing:**\n\n- **Enabling Audit Devices:**\n  - Enable an audit device:\n\n    ```bash\n    vault audit enable file file_path=/var/log/vault_audit.log\n    ```\n\n- **Monitoring Vault:**\n  - Monitor Vault health and performance using tools like Prometheus and Grafana.\n\n**10. Troubleshooting Vault:**\n\n- **Common Issues:**\n  - **Unseal Keys Lost:** If unseal keys are lost, Vault data is irrecoverable unless backups are available.\n  - **Token Expiry:** Ensure tokens used for authentication have appropriate TTL settings to avoid expiration during use.\n\n- **Debugging:**\n  - Enable detailed logging by setting the `VAULT_LOG_LEVEL` environment variable:\n\n    ```bash\n    export VAULT_LOG_LEVEL=debug\n    ```\n",
  "Security/SonarQube": "# SonarQube Cheatsheet\n\n![text](https://imgur.com/l49w71S.png)\n\n**1. Introduction:**\n\n- **SonarQube** is a popular open-source platform for continuous inspection of code quality, performing automatic reviews with static analysis of code to detect bugs, code smells, and security vulnerabilities.\n\n**2. Installation:**\n\n- **Installing SonarQube:**\n  - On Docker:\n\n    ```bash\n    docker run -d --name sonarqube -p 9000:9000 sonarqube\n    ```\n\n  - Manual Installation on Linux:\n\n    ```bash\n    wget https://binaries.sonarsource.com/Distribution/sonarqube/sonarqube-8.9.0.43852.zip\n    unzip sonarqube-8.9.0.43852.zip\n    cd sonarqube-8.9.0.43852/bin/linux-x86-64\n    ./sonar.sh start\n    ```\n\n- **Starting SonarQube:**\n  - Access SonarQube at `http://localhost:9000`.\n  - Default credentials: `admin/admin`.\n\n**3. Configuring SonarQube:**\n\n- **Database Configuration:**\n  - SonarQube requires a database like PostgreSQL, MySQL, or Oracle.\n  - Configure the database connection in the `sonar.properties` file:\n\n    ```properties\n    sonar.jdbc.url=jdbc:postgresql://localhost/sonarqube\n    sonar.jdbc.username=sonar\n    sonar.jdbc.password=sonar\n    ```\n\n- **Configuring Quality Profiles:**\n  - Quality profiles define the set of rules SonarQube uses for code analysis.\n  - Create or customize profiles in the **Quality Profiles** section of the UI.\n\n**4. Running Analysis:**\n\n- **Using SonarQube Scanner:**\n  - Install the scanner:\n\n    ```bash\n    npm install -g sonarqube-scanner\n    ```\n\n  - Run a scan:\n\n    ```bash\n    sonar-scanner \\\n      -Dsonar.projectKey=my-project \\\n      -Dsonar.sources=. \\\n      -Dsonar.host.url=http://localhost:9000 \\\n      -Dsonar.login=admin \\\n      -Dsonar.password=admin\n    ```\n\n- **Integrating with CI/CD:**\n  - Integrate SonarQube with Jenkins, GitLab CI, or other CI/CD tools to automate code analysis.\n\n**5. SonarQube Plugins:**\n\n- **Installing Plugins:**\n  - Navigate to **Administration > Marketplace** in SonarQube and search for plugins.\n  - Popular plugins include SonarLint, SonarCSS, and SonarTS.\n\n- **SonarQube and IDE Integration:**\n  - **SonarLint** is a plugin that integrates with IDEs like IntelliJ, Eclipse, and VS Code for real-time code quality feedback.\n\n**6. Advanced Features:**\n\n- **Code Coverage:**\n  - SonarQube integrates with code coverage tools like Jacoco for Java and Istanbul for JavaScript to report on test coverage.\n\n- **Security Vulnerabilities:**\n  - SonarQube detects vulnerabilities and provides remediation guidance based on OWASP and SANS standards.\n\n**7. Managing Users and Permissions:**\n\n- **User Management:**\n  - Add users and groups in the **Security** section.\n  - Assign roles such as **Admin**, **User**, or **Code Viewer**.\n\n- **LDAP/SSO Integration:**\n  - Configure LDAP or SSO in `sonar.properties` for centralized user authentication.\n\n**8. Monitoring and Reporting:**\n\n- **Project Dashboards:**\n  - SonarQube provides detailed dashboards for each project, showing metrics like code coverage, duplications, and issues over time.\n\n- **Custom Reports:**\n  - Generate custom reports with detailed metrics and trends for management or compliance purposes.\n\n**9. Scaling SonarQube:**\n\n- **High Availability:**\n  - Run SonarQube in a cluster mode by configuring multiple nodes and a load balancer.\n  - Configure the cluster settings in the `sonar.properties` file.\n\n- **Optimizing Performance:**\n  - Use a separate database for larger SonarQube deployments and allocate sufficient resources to the server.\n\n**10. Troubleshooting SonarQube:**\n\n- **Common Issues:**\n  - **Out of Memory:** Increase JVM heap size in `sonar.properties`.\n  - **Failed Scans:** Check the logs in `logs/` directory for detailed error messages.\n\n- **Debugging:**\n  - Enable debug logging in `sonar.properties`:\n\n    ```properties\n    sonar.log.level=DEBUG\n    ```\n",
  "Security/Trivy": "# Trivy Cheatsheet\n\n![text](https://imgur.com/TYu7qw7.png)\n\n**1. Introduction:**\n\n- **Trivy** is a comprehensive and easy-to-use security scanner for container images, file systems, and Git repositories, detecting vulnerabilities, misconfigurations, and secrets.\n\n**2. Installation:**\n\n- **Installing Trivy:**\n  - On macOS using Homebrew:\n\n    ```bash\n    brew install aquasecurity/trivy/trivy\n    ```\n\n  - On Linux:\n\n    ```bash\n    sudo apt-get install wget apt-transport-https gnupg lsb-release\n    wget -qO - https://aquasecurity.github.io/trivy-repo/deb/public.key | sudo apt-key add -\n    echo deb https://aquasecurity.github.io/trivy-repo/deb $(lsb_release -sc) main | sudo tee -a /etc/apt/sources.list.d/trivy.list\n    sudo apt-get update\n    sudo apt-get install trivy\n    ```\n\n  - On Windows:\n    - Download the binary from the [GitHub releases](https://github.com/aquasecurity/trivy/releases).\n\n**3. Basic Usage:**\n\n- **Scanning a Docker Image:**\n\n  ```bash\n  trivy image nginx:latest\n  ```\n\n  - This command scans the `nginx:latest` Docker image for known vulnerabilities.\n\n- **Scanning a File System:**\n\n  ```bash\n  trivy fs /path/to/directory\n  ```\n\n  - This command scans the specified directory for vulnerabilities and misconfigurations.\n\n- **Scanning a Git Repository:**\n\n  ```bash\n  trivy repo https://github.com/user/repository\n  ```\n\n  - This command scans the entire GitHub repository for vulnerabilities.\n\n**4. Scanning Options:**\n\n- **Severity Levels:**\n  - Filter results based on severity:\n\n    ```bash\n    trivy image --severity HIGH,CRITICAL nginx:latest\n    ```\n\n  - This command limits the output to high and critical vulnerabilities only.\n\n- **Ignore Unfixed Vulnerabilities:**\n\n  ```bash\n  trivy image --ignore-unfixed nginx:latest\n  ```\n\n  - Excludes vulnerabilities that have no known fixes.\n\n- **Output Formats:**\n  - JSON:\n\n    ```bash\n    trivy image -f json -o results.json nginx:latest\n    ```\n\n  - Table (default):\n\n    ```bash\n    trivy image -f table nginx:latest\n    ```\n\n**5. Advanced Usage:**\n\n- **Customizing Vulnerability Database Update:**\n\n  ```bash\n  trivy image --skip-update nginx:latest\n  ```\n\n  - Skips updating the vulnerability database before scanning.\n\n- **Using Trivy with Docker:**\n  - Running Trivy as a Docker container:\n\n    ```bash\n    docker run --rm -v /var/run/docker.sock:/var/run/docker.sock aquasec/trivy image nginx:latest\n    ```\n\n  - Scanning an image by directly pulling it from a registry:\n\n    ```bash\n    trivy image --docker-username <username> --docker-password <password> myregistry.com/myimage:tag\n    ```\n\n- **Trivy in CI/CD Pipelines:**\n  - Integrate Trivy into CI/CD workflows to automate vulnerability scanning during build stages.\n\n**6. Trivy Misconfiguration Detection:**\n\n- **Scanning for Misconfigurations:**\n\n  ```bash\n  trivy config /path/to/configuration/files\n  ```\n\n  - Scans configuration files (e.g., Kubernetes, Terraform) for security misconfigurations.\n\n**7. Trivy and Secrets Detection:**\n\n- **Scanning for Secrets:**\n\n  ```bash\n  trivy fs --security-checks secrets /path/to/code\n  ```\n\n  - Detects hardcoded secrets like passwords, API keys, and tokens within the codebase.\n\n**8. Integration with Other Tools:**\n\n- **Trivy and Harbor:**\n  - Trivy can be used as a vulnerability scanner within [Harbor](https://goharbor.io/), a cloud-native registry.\n\n- **Trivy and Kubernetes:**\n  - Trivy can scan Kubernetes resources for vulnerabilities and misconfigurations.\n\n**9. Trivy Reports:**\n\n- **Generating Reports:**\n  - HTML Report:\n\n    ```bash\n    trivy image -f json -o report.json nginx:latest\n    trivy report --input report.json --format html --output report.html\n    ```\n\n  - Detailed Reports with Severity Breakdown:\n\n    ```bash\n    trivy image --severity HIGH,CRITICAL --format table nginx:latest\n    ```\n\n**10. Troubleshooting Trivy:**\n\n- **Common Issues:**\n  - **Slow Scans:** Consider skipping database updates if they are not necessary.\n  - **Network Issues:** Ensure your network allows access to Trivy’s vulnerability database.\n\n- **Debugging:**\n  - Use the `--debug` flag to see detailed logs:\n\n    ```bash\n    trivy image --debug nginx:latest\n    ```\n",
  "Networking/Consul": "# Consul Cheatsheet\n\n![text](https://imgur.com/RWncIhL.png)\n\n## **Overview**\n\nConsul by HashiCorp is a service mesh and service discovery tool that provides distributed service networking, configuration management, and segmentation. It’s widely used for managing microservices in dynamic environments like Kubernetes.\n\n### **Basic Concepts**\n\n- **Service Discovery:** Consul automatically detects services in your network, allowing them to register and discover each other without hardcoding IP addresses or DNS names. This is especially useful in dynamic environments where services are constantly scaling.\n\n- **Key/Value Store:** Consul includes a distributed key/value store that can be used for dynamic configuration management. This allows applications to retrieve configuration data at runtime without restarting.\n\n- **Health Checking:** Consul monitors the health of services through health checks. If a service fails its health check, Consul can automatically remove it from the service registry, preventing traffic from being routed to unhealthy instances.\n\n- **Agent:** Each node in a Consul cluster runs an agent that provides a local interface for service registration, health checking, and querying. Agents communicate with each other to ensure consistent service data across the cluster.\n\n### **Service Mesh Features**\n\n- **Connect:** Consul’s service mesh feature, Connect, provides secure service-to-service communication using mutual TLS (mTLS). It ensures that all traffic between services is encrypted and authenticated.\n\n- **Intention:** Intentions in Consul define policies that control which services are allowed to communicate with each other. This fine-grained access control enhances security by ensuring that only authorized services can connect.\n\n- **Sidecar Proxy:** Consul uses Envoy as a sidecar proxy to manage and secure service communication. The sidecar handles tasks such as load balancing, mTLS, and observability.\n\n### **Traffic Management**\n\n- **Service Segmentation:** Consul’s intentions allow you to segment traffic by defining which services can communicate. For example, you can ensure that only the web service can talk to the payment service, preventing unauthorized access.\n\n- **Service Failover:** If a service instance becomes unhealthy or fails, Consul can automatically reroute traffic to healthy instances. This ensures high availability and resilience in your applications.\n\n- **Ingress Gateways:** Consul manages ingress gateways that control and secure traffic entering the service mesh. These gateways can enforce policies and provide TLS termination for incoming traffic.\n\n### **Security**\n\n- **ACLs (Access Control Lists):** Consul’s ACL system provides fine-grained security controls. You can create policies that determine which users or services have access to specific resources, enhancing security in multi-tenant environments.\n\n- **mTLS:** Consul uses mutual TLS to secure communication between services. mTLS not only encrypts traffic but also ensures that both the client and server are authenticated before communication is allowed.\n\n- **Service Mesh Policies:** Consul allows you to define policies that control various aspects of service communication, such as rate limiting, traffic shaping, and access control. These policies help you manage and secure your service mesh.\n\n### **Observability**\n\n- **Metrics:** Consul provides detailed metrics about service health, traffic patterns, and performance. These metrics can be exported to monitoring systems like Prometheus for further analysis.\n\n- **Logs:** Consul collects and stores logs related to service health, configuration changes, and traffic routing. These logs are useful for auditing and troubleshooting.\n\n- **Tracing:** Consul integrates with tracing systems like Jaeger and Zipkin to provide visibility into service communication. Tracing helps you understand how requests flow through your services and identify bottlenecks or failures.\n\n### **Advanced Concepts**\n\n- **Mesh Gateways:** Mesh gateways allow Consul to manage traffic between services in different datacenters or regions. This extends the service mesh beyond a single cluster, enabling global service networking.\n\n- **Network Middleware Integration:** Consul can integrate with firewalls, load balancers, and other network devices to enforce policies outside the service mesh. This is useful for securing traffic at the network edge.\n\n- **Service Failover Across Datacenters:** In multi-datacenter deployments, Consul can automatically failover services to another datacenter if the primary one fails. This ensures continuity and resilience.\n\n- **Consul-Terraform Sync:** Consul can automatically configure network infrastructure by syncing its service data with Terraform. This allows you to dynamically manage network devices based on the state of your services.\n\n### **Example Use Case**\n\nConsider a microservices architecture where services need to be dynamically discovered, secured, and managed across multiple environments:\n\n1. **Service Discovery:** Use Consul to automatically register services and make them discoverable to other services without manual intervention.\n2. **Secure Communication:** Implement mTLS with Consul Connect to ensure all service-to-service communication is encrypted and authenticated.\n3. **High Availability:** Configure service failover to reroute traffic to healthy instances if a service fails.\n4. **Access Control:** Use ACLs to restrict access to sensitive services like payment processing, ensuring that only authorized services can communicate with them.\n5. **Multi-Datacenter Resilience:** Deploy mesh gateways to manage traffic between services across different datacenters, ensuring global service availability.\n",
  "Networking/Envoy": "# Envoy Cheatsheet\n\n![text](https://imgur.com/iw5sG1a.png)\n\n## **Overview**\n\nEnvoy is a high-performance, open-source edge and service proxy. Originally developed by Lyft, Envoy is now widely adopted for managing microservices communication, especially within service meshes. Envoy handles tasks such as load balancing, security, observability, and routing.\n\n### **Basic Concepts**\n\n- **Proxy:** Envoy acts as a proxy, sitting between services and managing all incoming and outgoing traffic. It intercepts, processes, and forwards requests based on predefined configurations.\n\n- **Listener:** A listener is a configuration that defines how Envoy should accept incoming connections. It specifies the port and protocols (e.g., HTTP, TCP) Envoy listens to.\n\n- **Cluster:** In Envoy, a cluster represents a group of upstream services that Envoy proxies traffic to. A cluster typically consists of multiple instances of a service, allowing Envoy to distribute requests across them.\n\n- **Route:** Routes define how requests are processed and forwarded by Envoy. A route maps incoming requests to the appropriate cluster based on various criteria like URL paths or headers.\n\n### **Traffic Management**\n\n- **Load Balancing:** Envoy provides several load balancing algorithms to distribute traffic across service instances. Common algorithms include round-robin, least-request, and ring-hash. Load balancing ensures that no single instance is overwhelmed with too much traffic.\n\n- **Retries:** Envoy can automatically retry failed requests based on configurable policies. For example, if an upstream service fails to respond, Envoy can retry the request on a different instance.\n\n- **Circuit Breakers:** Circuit breakers prevent a service from becoming overwhelmed by limiting the number of concurrent connections or requests. If a service exceeds the defined thresholds, Envoy will stop sending traffic to it until it recovers.\n\n- **Rate Limiting:** Envoy allows you to define rate limits on incoming requests, controlling how many requests are allowed over a given period. This is useful for preventing abuse or overloading of services.\n\n### **Security**\n\n- **TLS Termination:** Envoy can handle TLS termination, decrypting inbound traffic, and encrypting outbound traffic. This simplifies the management of secure communications within your services.\n\n- **mTLS (Mutual TLS):** Envoy supports mutual TLS for securing service-to-service communication. This ensures that both parties in a communication exchange authenticate each other and that their communication is encrypted.\n\n- **RBAC (Role-Based Access Control):** Envoy implements RBAC to control access to services based on predefined roles and permissions. This adds an additional layer of security, ensuring that only authorized services or users can access specific resources.\n\n### **Observability**\n\n- **Metrics:** Envoy provides detailed metrics about network traffic, including request counts, latency, error rates, and more. These metrics are essential for monitoring the health and performance of your services.\n\n- **Access Logs:** Envoy generates detailed access logs for each request it handles. These logs include information about the request’s origin, the response status, and any errors encountered. Access logs are valuable for auditing and debugging.\n\n- **Tracing:** Envoy integrates with distributed tracing systems like Jaeger and Zipkin. Tracing provides a detailed view of a request’s journey through various services, helping you identify bottlenecks and failures in your application.\n\n### **Advanced Concepts**\n\n- **Filter Chains:** Envoy’s filter chains allow for complex request processing. Filters can modify, route, or reject requests based on various conditions. Common filters include authentication, rate limiting, and request transformation.\n\n- **Dynamic Configuration with xDS APIs:** Envoy supports dynamic configuration through a set of APIs known as xDS (e.g., ADS, CDS, LDS, RDS, EDS). These APIs allow Envoy to update its configuration in real-time without restarting. This capability is crucial for environments where services are constantly changing.\n\n- **Sidecar Proxy:** In a service mesh, Envoy is typically deployed as a sidecar proxy alongside each microservice. The sidecar intercepts all traffic to and from the service, providing security, observability, and traffic management features.\n\n### **Example Use Case**\n\nImagine you are running an e-commerce application with multiple microservices such as payment, inventory, and user services. Here’s how\n\n Envoy can help:\n\n1. **Secure Communication:** Use Envoy’s TLS termination to encrypt all traffic between the microservices.\n2. **Load Balancing:** Distribute incoming requests evenly across multiple instances of the payment service using Envoy’s round-robin load balancing.\n3. **Rate Limiting:** Protect the user service from abuse by setting a rate limit on login attempts.\n4. **Observability:** Monitor the health of all microservices using Envoy’s metrics and integrate with Prometheus for alerting.\n5. **Resilience:** Use circuit breakers to prevent the inventory service from becoming overwhelmed during high traffic periods.\n",
  "Networking/Istio": "# Istio Cheatsheet\n\n![text](https://imgur.com/QLlMSCp.png)\n\n## **Overview**\n\nIstio is an open-source service mesh that layers transparently onto existing distributed applications. It provides a way to control how microservices share data with one another. Key features of Istio include traffic management, security, and observability.\n\n### **Basic Concepts**\n\n- **Service Mesh:** Istio creates a service mesh, which is an infrastructure layer that enables microservices to communicate with each other securely and efficiently. It also allows for traffic management and monitoring without requiring changes to the microservices themselves.\n  \n- **Control Plane vs. Data Plane:** Istio's architecture is divided into two planes:\n  - **Control Plane:** Manages and configures the proxies (Envoy) to route traffic, enforce policies, and collect telemetry.\n  - **Data Plane:** Consists of Envoy proxies deployed as sidecars to the microservices, handling all network traffic between services.\n\n### **Key Components**\n\n- **Envoy Proxy:** The core component of Istio’s data plane. Envoy is deployed as a sidecar to each service and intercepts all inbound and outbound traffic.\n\n- **Pilot:** Manages the configuration of the Envoy proxies, distributing routing rules and policies across the mesh.\n\n- **Mixer:** Enforces access control and usage policies, and collects telemetry data. It interacts with the Envoy proxies and provides insights into traffic patterns and security.\n\n- **Citadel:** Manages certificates and keys for mutual TLS (mTLS) and service identities within the mesh, ensuring secure communication between services.\n\n- **Galley:** Istio’s configuration validation component. It ensures that configurations are correct and distributes them to the appropriate components within the mesh.\n\n### **Traffic Management**\n\n- **VirtualService:** A resource that defines how traffic is routed to a service. It allows you to configure complex routing rules like request matching, traffic splitting, and more.\n\n- **DestinationRule:** Defines policies that apply to traffic after it has been routed to a destination. These policies can include load balancing settings, connection pool sizes, and outlier detection.\n\n- **Gateway:** Manages external traffic entering the mesh. It controls how traffic from outside the cluster is directed into the mesh and routed to the appropriate services.\n\n- **Sidecar:** This resource configures the behavior of the sidecar proxies deployed alongside the microservices. It allows for fine-grained control over traffic management and resource usage.\n\n### **Security**\n\n- **mTLS (Mutual TLS):** Istio supports mTLS to secure service-to-service communication. mTLS ensures that the identity of both the client and the server is authenticated and that the communication between them is encrypted.\n\n- **Authorization Policies:** These policies define access control rules, determining which services or users can access specific resources. Policies can be applied globally, per namespace, or per workload.\n\n- **Ingress/Egress Control:** Istio manages both inbound and outbound traffic to ensure that it complies with security policies. Ingress controls how external traffic enters the mesh, while egress manages how traffic leaves the mesh.\n\n### **Observability**\n\n- **Telemetry:** Istio collects telemetry data such as metrics, logs, and traces, providing deep insights into the behavior of your microservices. This data is essential for monitoring and debugging applications.\n\n- **Prometheus:** Istio integrates with Prometheus, a monitoring system that scrapes metrics from the Envoy proxies. These metrics can be visualized using tools like Grafana.\n\n- **Grafana:** A visualization tool used to create dashboards that display the metrics collected by Prometheus. Istio provides pre-built Grafana dashboards to monitor your service mesh.\n\n- **Jaeger/Zipkin:** Distributed tracing tools integrated with Istio. They allow you to trace the path of a request as it travels through various services in the mesh, helping to identify performance bottlenecks and errors.\n\n### **Advanced Concepts**\n\n- **Canary Deployments:** Istio enables canary deployments by allowing you to gradually roll out a new version of a service to a small percentage of users while monitoring its performance before fully deploying it.\n\n- **Traffic Mirroring:** This feature allows you to mirror a portion of live traffic to a new service version without impacting production traffic. It’s useful for testing new versions in a real-world environment.\n\n- **Circuit Breaking:** Prevents services from being overwhelmed by limiting the number of concurrent connections or requests. If the limit is reached, Istio can return an error or route traffic to a backup service.\n\n- **Rate Limiting:** Controls the rate at which requests are sent to a service, preventing overloads. Rate limits can be defined based on various factors, such as user identity or source IP.\n\n- **Ingress/Egress Policies:** These policies control what traffic is allowed to enter or leave the service mesh, enhancing security by restricting access based on predefined rules.\n\n- **Service Entries:** Extend the mesh to services outside of the mesh, allowing them to be treated as if they were inside the mesh. This is useful for managing and securing external services.\n\n### **Example Use Case**\n\nConsider a microservices architecture where you need to manage traffic between different versions of a service. With Istio, you can:\n\n1. **Deploy a New Version:** Use a VirtualService to route 10% of traffic to a new version of your service.\n2. **Monitor the New Version:** Collect telemetry data to ensure the new version behaves as expected.\n3. **Gradually Increase Traffic:** If the new version is stable, gradually increase the traffic percentage.\n4. **Roll Back if Needed:** If issues are detected, quickly route all traffic back to the previous version using Istio’s traffic management capabilities.\n",
  "Networking/Linkerd": "# Linkerd Cheatsheet\n\n![text](https://imgur.com/xyQcgGf.png)\n\n## **Overview**\n\nLinkerd is a lightweight service mesh designed to be simple to operate while providing powerful features for observability, security, and reliability. Unlike some other service meshes, Linkerd focuses on minimal configuration and performance.\n\n### **Basic Concepts**\n\n- **Service Mesh:** Linkerd provides an infrastructure layer that enables secure, reliable, and observable communication between microservices. It operates transparently, requiring minimal changes to your services.\n\n- **Control Plane:** Linkerd’s control plane manages the configuration and behavior of the service mesh. It includes components for managing policies, collecting telemetry, and issuing certificates.\n\n- **Data Plane:** The data plane consists of lightweight proxies deployed as sidecars to each service. These proxies handle all inbound and outbound traffic, providing features like mTLS, retries, and load balancing.\n\n### **Traffic Management**\n\n- **Routing:** Linkerd automatically manages routing for service-to-service communication. It handles retries and timeouts, ensuring that requests are routed efficiently and reliably.\n\n- **Load Balancing:** Linkerd distributes traffic across available service instances to prevent any single instance from being overwhelmed. It uses algorithms like random and least-request to balance traffic effectively.\n\n- **Traffic Splitting:** Linkerd allows you to split traffic between different versions of a service. This is useful for canary deployments, where a small percentage of traffic is sent to a new version before full rollout.\n\n### **Security**\n\n- **mTLS:** Linkerd provides out-of-the-box mutual TLS (mTLS) for all communication between services. This ensures that all traffic is encrypted and that both the client and server are authenticated.\n\n- **Identity Service:** Linkerd includes an identity service that issues and renews TLS certificates for the proxies. This service manages the cryptographic identities used for mTLS.\n\n- **Authorization:** Linkerd’s mTLS also acts as an authorization mechanism, ensuring that only authorized services can communicate with each other. This enhances security by preventing unauthorized access.\n\n### **Observability**\n\n- **Metrics:** Linkerd automatically collects and exposes metrics such as latency, success rates, and request volumes. These metrics are essential for monitoring the health and performance of your services.\n\n- **Prometheus Integration:** Linkerd integrates seamlessly with Prometheus, allowing you to scrape and visualize metrics. Prometheus can be used to create alerts based on Linkerd’s metrics.\n\n- **Grafana Dashboards:** Linkerd provides pre-built Grafana dashboards for visualizing metrics. These dashboards offer insights into service performance and help in identifying issues.\n\n- **Distributed Tracing:** Linkerd supports distributed tracing, allowing you to track requests as they flow through different services. This helps in understanding the service interaction and diagnosing issues.\n\n### **Advanced Concepts**\n\n- **Service Profiles:** Service profiles allow you to define expected behavior for services, such as retries, timeouts, and traffic shaping. They provide fine-grained control over how traffic is handled.\n\n- **Tap API:** The Tap API provides real-time visibility into live traffic. You can use it to inspect requests and responses, making it a powerful tool for debugging and monitoring.\n\n- **Traffic Shifting:** Linkerd supports traffic shifting, enabling you to gradually shift traffic from one version of a service to another. This is particularly useful for rolling out updates safely.\n\n- **Multicluster Support:** Linkerd can extend its service mesh across multiple Kubernetes clusters, allowing you to manage services that span different environments. This is useful for high availability and disaster recovery.\n\n- **Policy Enforcement:** Linkerd allows you to define policies that control traffic routing, access control, and rate limiting. These policies help ensure that services behave as expected under various conditions.\n\n### **Example Use Case**\n\nSuppose you are managing a microservices application where you need a lightweight service mesh to provide observability and security with minimal overhead:\n\n1. **Simplified Deployment:** Deploy Linkerd with minimal configuration and start benefiting from automatic mTLS and load balancing.\n2. **Canary Releases:** Use traffic splitting to gradually route traffic to a new version of a service, reducing the risk of full deployment.\n3. **Real-time Monitoring:** Utilize the Tap API to monitor live traffic and quickly identify any issues with requests.\n4. **Secure Communication:** Rely on Linkerd’s mTLS to secure all service-to-service communication without the need for complex certificate management.\n5. **Cross-Cluster Management:** Extend Linkerd’s service mesh across multiple Kubernetes clusters to ensure high availability and disaster recovery.\n",
  "Monitoring/CloudWatch": "# CloudWatch Cheatsheet\n\n![text](https://imgur.com/BU5g7ce.png)\n\nAmazon CloudWatch is a comprehensive monitoring and management service designed for AWS and hybrid cloud applications. This guide covers everything from basic concepts to advanced configurations, helping you leverage CloudWatch for performance monitoring, troubleshooting, and operational insights.\n\n---\n\n## **1. Introduction to CloudWatch**\n\n### What is CloudWatch?\n\n- Amazon CloudWatch is a monitoring and observability service for AWS resources and custom applications.\n- Provides actionable insights through metrics, logs, alarms, and dashboards.\n- Supports both infrastructure and application-level monitoring.\n\n### Key Features:\n\n- **Metrics**: Collect and monitor key performance data.\n- **Logs**: Aggregate, analyze, and search logs.\n- **Alarms**: Set thresholds for metrics to trigger automated actions.\n- **Dashboards**: Visualize data in real time.\n- **CloudWatch Events**: Trigger actions based on changes in AWS resources.\n\n---\n\n## **2. CloudWatch Architecture Overview**\n\n- **Data Sources**:\n  - AWS Services: EC2, RDS, Lambda, etc.\n  - On-premises servers or hybrid setups using CloudWatch Agent.\n- **Core Components**:\n  - **Metrics**: Quantifiable data points (e.g., CPU utilization).\n  - **Logs**: Application and system logs.\n  - **Alarms**: Notifications or automated responses.\n  - **Dashboards**: Custom visualizations.\n  - **Insights**: Advanced log analytics.\n\n---\n\n## **3. Setting Up CloudWatch**\n\n### Accessing CloudWatch\n\n1. Go to the **AWS Management Console**.\n2. Navigate to **CloudWatch** under the **Management & Governance** section.\n\n### CloudWatch Agent Installation\n\nTo monitor custom metrics or on-premises resources:\n\n1. Install the CloudWatch Agent on your instance:\n\n   ```bash\n   sudo yum install amazon-cloudwatch-agent\n   ```\n\n2. Configure the agent:\n\n   ```bash\n   sudo /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-config-wizard\n   ```\n\n3. Start the agent:\n\n   ```bash\n   sudo /opt/aws/amazon-cloudwatch-agent/bin/start-amazon-cloudwatch-agent\n   ```\n\n### Setting IAM Permissions\n\nAttach the **CloudWatchFullAccess** policy to the IAM role or user managing CloudWatch.\n\n---\n\n## **4. Metrics Monitoring**\n\n### Viewing Metrics\n\n1. In the CloudWatch console, go to **Metrics**.\n2. Select a namespace (e.g., `AWS/EC2`, `AWS/Lambda`).\n3. Choose metrics like `CPUUtilization`, `DiskWriteOps`, etc.\n\n### Common Metrics:\n\n- **EC2**:\n  - `CPUUtilization`\n  - `DiskReadBytes`\n  - `NetworkIn/Out`\n- **RDS**:\n  - `DatabaseConnections`\n  - `ReadIOPS`\n  - `WriteLatency`\n- **Lambda**:\n  - `Invocations`\n  - `Duration`\n  - `Errors`\n\n### Custom Metrics\n\nTo send custom metrics:\n\n1. Install the AWS CLI.\n2. Publish a metric:\n\n   ```bash\n   aws cloudwatch put-metric-data --namespace \"CustomNamespace\" --metric-name \"MetricName\" --value 100\n   ```\n\n---\n\n## **5. CloudWatch Logs**\n\n### Setting Up Log Groups and Streams\n\n1. Navigate to **Logs** in the CloudWatch console.\n2. Create a **Log Group** (e.g., `/aws/lambda/my-function`).\n3. Each application/service writes to a **Log Stream** under the group.\n\n### Exporting Logs to S3\n\n1. Go to **Logs** → Select a log group.\n2. Click **Actions** → **Export data to Amazon S3**.\n3. Configure the export with the desired time range.\n\n### Querying Logs with CloudWatch Logs Insights\n\n1. Navigate to **Logs Insights**.\n2. Write queries for analysis:\n\n   ```sql\n   fields @timestamp, @message\n   | filter @message like /ERROR/\n   | sort @timestamp desc\n   | limit 20\n   ```\n\n---\n\n## **6. CloudWatch Alarms**\n\n### Creating an Alarm\n\n1. Go to **Alarms** in the CloudWatch console.\n2. Click **Create Alarm**.\n3. Select a metric (e.g., `CPUUtilization`).\n4. Set a threshold (e.g., `> 80%` for 5 minutes).\n5. Choose an action (e.g., send an SNS notification).\n\n### Alarm States:\n\n- **OK**: Metric is within the defined threshold.\n- **ALARM**: Metric breaches the threshold.\n- **INSUFFICIENT DATA**: No data available.\n\n### Advanced Alarm Configurations\n\n- Composite Alarms: Combine multiple alarms.\n- Actions:\n  - Notify via SNS.\n  - Trigger Lambda functions.\n  - Stop/start EC2 instances.\n\n---\n\n## **7. CloudWatch Dashboards**\n\n### Creating a Dashboard\n\n1. Go to **Dashboards** in the CloudWatch console.\n2. Click **Create Dashboard**.\n3. Add widgets:\n   - **Line** for metrics.\n   - **Number** for single values.\n   - **Text** for notes.\n\n### Customizing Widgets\n\n- Choose metrics from different namespaces.\n- Configure time ranges and granularity.\n\n### Example: Multi-Service Dashboard\n\n- **EC2 Metrics**: CPU, Disk, Network.\n- **RDS Metrics**: Connections, IOPS.\n- **Lambda Metrics**: Invocations, Errors.\n\n---\n\n## **8. CloudWatch Events (EventBridge)**\n\n### Creating Rules\n\n1. Navigate to **Rules** under **Events** in the CloudWatch console.\n2. Create a rule with an event pattern (e.g., EC2 state change).\n3. Add a target (e.g., SNS, Lambda, Step Functions).\n\n### Example: Automate Instance Shutdown\n\n1. Event Pattern:\n\n   ```json\n   {\n     \"source\": [\"aws.ec2\"],\n     \"detail-type\": [\"EC2 Instance State-change Notification\"],\n     \"detail\": {\n       \"state\": [\"stopped\"]\n     }\n   }\n   ```\n\n2. Target: Send an SNS notification.\n\n---\n\n## **9. Advanced Configurations**\n\n### Cross-Account Monitoring\n\n1. Create a cross-account role with permissions to access CloudWatch in the target account.\n2. Use the `CloudWatch:ListMetrics` and `CloudWatch:GetMetricData` APIs.\n\n### Anomaly Detection\n\nEnable anomaly detection for metrics:\n\n1. Go to **Metrics** → Select a metric.\n2. Click **Actions** → **Enable anomaly detection**.\n\n### Metric Math\n\nPerform calculations across metrics:\n\n- Example: Combine CPU utilization across instances.\n\n  ```bash\n  (m1+m2)/2\n  ```\n\n---\n\n## **10. Integration with Other Services**\n\n### AWS Lambda\n\n- Use `console.log()` to write logs to CloudWatch.\n- Monitor Lambda-specific metrics like `Errors` and `Throttles`.\n\n### ECS/EKS\n\n- Enable CloudWatch Container Insights for detailed monitoring.\n- Use `awslogs` driver to send container logs to CloudWatch.\n\n### Integration with Third-Party Tools\n\n- Use **DataDog** or **Grafana** for enhanced visualization.\n- Integrate CloudWatch metrics into these platforms using APIs.\n\n---\n\n## **11. Security Best Practices**\n\n### Log Retention\n\n- Set retention policies for logs to reduce costs:\n\n  ```bash\n  aws logs put-retention-policy --log-group-name \"/aws/lambda/my-function\" --retention-in-days 30\n  ```\n\n### Fine-Grained Access Control\n\n- Use IAM policies to restrict access to specific metrics, logs, or dashboards.\n\n---\n\n## **12. CloudWatch Pricing**\n\n### Pricing Model\n\n1. **Metrics**: Charged per metric, per month.\n2. **Logs**:\n   - Ingestion: Cost per GB ingested.\n   - Storage: Cost per GB stored.\n3. **Dashboards**: Charged per dashboard, per month.\n\n### Cost Optimization Tips\n\n- Use metric filters to limit data collection.\n- Set shorter retention periods for logs.\n\n---\n\n## **13. Best Practices**\n\n1. **Organize Log Groups**:\n   - Use consistent naming conventions (e.g., `/application/environment/service`).\n\n2. **Use Alarms Wisely**:\n   - Avoid too many alarms to prevent alert fatigue.\n   - Use composite alarms to group related metrics.\n\n3. **Automate Monitoring**:\n   - Automate alert creation and dashboards using CloudFormation or Terraform.\n\n4. **Optimize Log Storage**:\n   - Export logs to S3 for long-term storage and analysis.\n\n5. **Enable Anomaly Detection**:\n   - Automate anomaly detection for critical metrics.\n\n---\n\n## **14. References and Resources**\n\n- [CloudWatch Documentation](https://docs.aws.amazon.com/cloudwatch/)\n- [Metric Math Syntax Guide](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/using-metric-math.html)\n- [CloudWatch Pricing](https://aws.amazon.com/cloudwatch/pricing/)\n",
  "Monitoring/ELK-Stack": "# ELK Stack Cheatsheet\n\n![text](https://imgur.com/wLayBA4.png)\n\n**1. Introduction:**\n\n- The **ELK Stack** is a powerful suite of open-source tools: **Elasticsearch** for search and analytics, **Logstash** for data processing, and **Kibana** for visualization. It's often extended with **Beats** for data collection and **X-Pack** for additional features.\n\n**2. Elasticsearch:**\n\n- **Installing Elasticsearch:**\n\n  ```bash\n  wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.10.2-x86_64.rpm\n  sudo rpm -ivh elasticsearch-7.10.2-x86_64.rpm\n  sudo systemctl start elasticsearch\n  sudo systemctl enable elasticsearch\n  ```\n\n- **Basic Configuration:**\n  - Edit `/etc/elasticsearch/elasticsearch.yml`:\n\n  ```yaml\n  network.host: localhost\n  http.port: 9200\n  ```\n\n- **Basic Queries:**\n\n  ```bash\n  curl -X GET \"localhost:9200/_cat/indices?v\"\n  curl -X GET \"localhost:9200/my-index/_search?q=user:john\"\n  ```\n\n- **Indexing Documents:**\n\n  ```bash\n  curl -X POST \"localhost:9200/my-index/_doc/1\" -H 'Content-Type: application/json' -d'\n  {\n    \"user\": \"john\",\n    \"message\": \"Hello, Elasticsearch!\"\n  }'\n  ```\n\n- **Elasticsearch Cluster:**\n  - Configure multi-node clusters by setting `cluster.name`, `node.name`, and `discovery.seed_hosts` in `elasticsearch.yml`.\n\n**3. Logstash:**\n\n- **Installing Logstash:**\n\n  ```bash\n  wget https://artifacts.elastic.co/downloads/logstash/logstash-7.10.2.rpm\n  sudo rpm -ivh logstash-7.10.2.rpm\n  sudo systemctl start logstash\n  sudo systemctl enable logstash\n  ```\n\n- **Logstash Configuration:**\n\n  ```yaml\n  input {\n    file {\n      path => \"/var/log/syslog\"\n      start_position => \"beginning\"\n    }\n  }\n  filter {\n    grok {\n      match => { \"message\" => \"%{SYSLOGLINE}\" }\n    }\n  }\n  output {\n    elasticsearch {\n      hosts => [\"localhost:9200\"]\n      index => \"syslog-%{+YYYY.MM.dd}\"\n    }\n  }\n  ```\n\n- **Running Logstash:**\n\n  ```bash\n  sudo systemctl start logstash\n  ```\n\n- **Using Beats with Logstash:**\n  - Use **Filebeat**, **Metricbeat**, or **Packetbeat** to ship data to Logstash for processing.\n\n**4. Kibana:**\n\n- **Installing Kibana:**\n\n  ```bash\n  wget https://artifacts.elastic.co/downloads/kibana/kibana-7.10.2-x86_64.rpm\n  sudo rpm -ivh kibana-7.10.2-x86_64.rpm\n  sudo systemctl start kibana\n  sudo systemctl enable kibana\n  ```\n\n- **Basic Configuration:**\n  - Edit `/etc/kibana/kibana.yml`:\n\n  ```yaml\n  server.port: 5601\n  server.host: \"localhost\"\n  elasticsearch.hosts: [\"http://localhost:9200\"]\n  ```\n\n- **Creating Visualizations:**\n  1. Navigate to **Visualize** in the Kibana interface.\n  2. Choose a visualization type (e.g., line chart, pie chart).\n  3. Select the data source and configure your queries.\n  4. Save and add the visualization to a dashboard.\n\n- **Kibana Dashboards:**\n  - Use dashboards to combine multiple visualizations into a single view, useful for monitoring and analysis.\n\n**5. Beats:**\n\n- **Filebeat:**\n  - **Installing Filebeat:**\n\n    ```bash\n    wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.10.2-x86_64.rpm\n    sudo rpm -ivh filebeat-7.10.2-x86_64.rpm\n    sudo systemctl start filebeat\n    sudo systemctl enable filebeat\n    ```\n\n  - **Configuring Filebeat:**\n\n    ```yaml\n    filebeat.inputs:\n    - type: log\n      paths:\n        - /var/log/syslog\n\n    output.elasticsearch:\n      hosts: [\"localhost:9200\"]\n    ```\n\n  - **Running Filebeat:**\n\n    ```bash\n    sudo systemctl start filebeat\n    ```\n\n- **Metricbeat:**\n  - Collects metrics from the system and services like MySQL, Docker, etc.\n\n- **Packetbeat:**\n  - Captures network traffic and analyzes protocols.\n\n**6. Security in ELK Stack:**\n\n- **Enabling HTTPS in Elasticsearch:**\n\n  ```yaml\n  xpack.security.enabled: true\n  xpack.security.http.ssl.enabled: true\n  xpack.security.http.ssl.keystore.path: /path/to/keystore.jks\n  ```\n\n- **User Authentication:**\n  - Use **X-Pack** to manage users, roles, and permissions.\n\n**7. ELK Stack in Kubernetes:**\n\n- **Deploying ELK Stack:**\n  - Use Helm charts to deploy the ELK stack in Kubernetes for easier management and scaling.\n\n**8. Troubleshooting ELK Stack:**\n\n- **Common Issues:**\n  - **High Memory Usage:** Optimize the heap size in Elasticsearch.\n  - **Logstash Performance:** Tune pipeline workers\n\n and batch size.\n\n- **Debugging:**\n  - Check logs for Elasticsearch (`/var/log/elasticsearch/`), Logstash (`/var/log/logstash/`), and Kibana (`/var/log/kibana/`).\n  - Use `curl` to test Elasticsearch endpoints and ensure services are running.\n",
  "Monitoring/Grafana": "# Grafana Cheatsheet\n\n![text](https://imgur.com/j07r4L6.png)\n\n**1. Introduction:**\n\n- **Grafana** is an open-source platform for monitoring and observability that allows you to query, visualize, and alert on metrics from multiple data sources like Prometheus, InfluxDB, Elasticsearch, and more.\n\n**2. Key Concepts:**\n\n- **Dashboard:** A collection of panels organized into a grid.\n- **Panel:** A visualization of data (graphs, charts, etc.) from a specific data source.\n- **Data Source:** The database or service that provides the metrics for Grafana to visualize.\n- **Alerting:** Set up conditions to trigger notifications when metrics meet specific criteria.\n\n**3. Installation:**\n\n- **Running Grafana:**\n\n  ```bash\n  sudo apt-get install -y adduser libfontconfig1\n  wget https://dl.grafana.com/oss/release/grafana_7.5.7_amd64.deb\n  sudo dpkg -i grafana_7.5.7_amd64.deb\n  sudo systemctl start grafana-server\n  sudo systemctl enable grafana-server\n  ```\n\n- **Docker:**\n\n  ```bash\n  docker run -d -p 3000:3000 --name=grafana grafana/grafana\n  ```\n\n**4. Configuring Data Sources:**\n\n- **Adding Prometheus as a Data Source:**\n  1. Navigate to **Configuration > Data Sources**.\n  2. Click on **Add data source** and select **Prometheus**.\n  3. Enter the URL of your Prometheus server (e.g., `http://localhost:9090`).\n  4. Click **Save & Test** to verify the connection.\n\n- **Adding Elasticsearch as a Data Source:**\n  1. Navigate to **Configuration > Data Sources**.\n  2. Click on **Add data source** and select **Elasticsearch**.\n  3. Enter the URL, index name, and time field.\n  4. Click **Save & Test** to verify the connection.\n\n**5. Building Dashboards:**\n\n- **Creating a New Dashboard:**\n  1. Click the **+** icon in the sidebar and select **Dashboard**.\n  2. Click **Add new panel**.\n  3. Choose your data source and write a query (e.g., `rate(http_requests_total[5m])` for Prometheus).\n  4. Select a visualization type (e.g., **Graph**, **Stat**, **Gauge**).\n  5. Save the panel and the dashboard.\n\n- **Using Variables:**\n  - **Creating a Variable:**\n    1. Go to **Dashboard settings** > **Variables** > **New**.\n    2. Set the **Name**, **Type** (e.g., **Query**), and **Query**.\n    3. Use the variable in panel queries by referencing it as **`$variable_name`**.\n\n**6. Alerting:**\n\n- **Creating Alerts:**\n\n  1. Add a panel to your dashboard.\n  2. In the **Alert** tab, click **Create Alert**.\n  3. Set the **Conditions** for triggering the alert (e.g., when a metric crosses a threshold).\n  4. Define the **Evaluation Interval** and **No Data** options.\n  5. Configure **Notifications** to send alerts via email, Slack, or other channels.\n\n- **Managing Alerts:**\n  - Alerts can be managed centrally through the **Alerting** section in the sidebar.\n\n**7. Grafana Plugins:**\n\n- **Installing Plugins:**\n\n  ```bash\n  grafana-cli plugins install grafana-piechart-panel\n  sudo systemctl restart grafana-server\n  ```\n\n- **Popular Plugins:**\n  - **Pie Chart Panel:** Display metrics in a pie chart.\n  - **Worldmap Panel:** Visualize data on a world map.\n  - **Alert List Panel:** Display active alerts from multiple sources.\n\n**8. Dashboard Templating:**\n\n- **Using Templated Dashboards:**\n  - Leverage variables to create dynamic dashboards that can change based on user input.\n\n- **Dynamic Panels:**\n  - Create repeating panels or rows based on variable values (e.g., show metrics per host).\n\n**9. Customizing Grafana:**\n\n- **Themes:**\n  - Switch between light and dark themes via **Preferences** in the dashboard settings.\n\n- **Custom Branding:**\n  - Modify Grafana's appearance by adding custom logos and colors. Requires editing configuration files and CSS.\n\n**10. Securing Grafana:**\n\n- **User Management:**\n  - Add users and assign them roles such as Viewer, Editor, or Admin.\n\n- **LDAP/SSO Integration:**\n  - Configure Grafana to use LDAP or Single Sign-On (SSO) for user authentication.\n\n- **Enabling HTTPS:**\n\n  ```yaml\n  [server]\n  protocol = https\n  cert_file = /path/to/cert.crt\n  cert_key = /path/to/cert.key\n  ```\n\n**11. Advanced Queries and Visualizations:**\n\n- **Grafana with PromQL:**\n  - Use advanced PromQL queries for more complex visualizations.\n\n- **Annotations:**\n  - Add annotations to mark specific events on graphs, useful for correlating issues with changes or incidents.\n\n**12. Grafana Loki:**\n\n- **Introduction to Loki:**\n  - Grafana Loki is a horizontally scalable, highly available log aggregation system inspired by Prometheus.\n\n- **Setting up Loki:**\n\n  ```bash\n  docker run -d --name=loki -p 3100:3100 grafana/loki:2.2.0 -config.file=/etc/loki/local-config.yaml\n  ```\n\n- **Querying Logs in Grafana:**\n  - Use **Loki** as a data source to query and visualize logs alongside metrics.\n\n**13. Grafana in Kubernetes:**\n\n- **Deploying Grafana in Kubernetes:**\n\n  ```yaml\n  apiVersion: apps/v1\n  kind: Deployment\n  metadata:\n    name: grafana\n  spec:\n    replicas: 1\n    selector:\n      matchLabels:\n        app: grafana\n    template:\n      metadata:\n        labels:\n          app: grafana\n      spec:\n        containers:\n        - name: grafana\n          image: grafana/grafana:7.5.7\n          ports:\n          - containerPort: 3000\n  ```\n\n**14. Troubleshooting Grafana:**\n\n- **Common Issues:**\n  - **No Data:** Check data source configuration and queries.\n  - **Slow Dashboards:** Optimize queries and reduce the time range.\n  - **Plugin Errors:** Ensure plugins are compatible with your Grafana version.\n\n- **Debugging:**\n  - View logs at `/var/log/grafana/grafana.log` for error details.\n  - Use **`curl`** to test data source connectivity (e.g., `curl http://localhost:9090` for Prometheus).\n",
  "Monitoring/Nagios": "# Nagios Cheatsheet\n\n![text](https://imgur.com/O9DGMee.png)\n\n**1. Introduction:**\n\n- **Nagios** is a powerful open-source monitoring tool that provides comprehensive monitoring of systems, networks, and infrastructure. It is known for its robustness, flexibility, and extensive plugin system.\n\n**2. Installation:**\n\n- **Installing Nagios Core:**\n\n  ```bash\n  sudo apt-get update\n  sudo apt-get install -y build-essential libgd2-xpm-dev openssl libssl-dev xinetd apache2-utils unzip\n  wget https://assets.nagios.com/downloads/nagioscore/releases/nagios-4.4.6.tar.gz\n  tar -xzf nagios-4.4.6.tar.gz\n  cd nagios-4.4.6/\n  ./configure --with-httpd-conf=/etc/apache2/sites-enabled\n  make all\n  sudo make install\n  sudo make install-commandmode\n  sudo make install-init\n  sudo make install-config\n  sudo make install-webconf\n  ```\n\n- **Starting Nagios:**\n\n  ```bash\n  sudo systemctl start nagios\n  sudo systemctl enable nagios\n  ```\n\n**3. Configuration:**\n\n- **Basic Configuration:**\n  - Nagios configuration files are typically located in `/usr/local/nagios/etc/`.\n\n- **Defining a Host:**\n\n  ```cfg\n  define host {\n    use             linux-server\n    host_name       myserver\n    alias           My Linux Server\n    address         192.168.1.1\n    }\n  ```\n\n- **Defining a Service:**\n\n  ```cfg\n  define service {\n    use                     generic-service\n    host_name               myserver\n    service_description     HTTP\n    check_command           check_http\n    }\n  ```\n\n**4. Nagios Plugins:**\n\n- **Installing Plugins:**\n\n  ```bash\n  wget https://nagios-plugins.org/download/nagios-plugins-2.3.3.tar.gz\n  tar -xzf nagios-plugins-2.3.3.tar.gz\n  cd nagios-plugins-2.3.3/\n  ./configure\n  make\n  sudo make install\n  ```\n\n- **Common Plugins:**\n  - **check_ping:** Monitors network connectivity.\n  - **check_http:** Monitors HTTP servers.\n  - **check_disk:** Monitors disk usage.\n\n**5. Notifications:**\n\n- **Setting Up Email Notifications:**\n  - Configure email settings in `/usr/local/nagios/etc/objects/contacts.cfg`:\n\n  ```cfg\n  define contact {\n    contact_name                    nagiosadmin\n    use                             generic-contact\n    alias                           Nagios Admin\n    email                           nagios@yourdomain.com\n  }\n  ```\n\n- **Notification Commands:**\n  - Use commands like `notify-host-by-email` and `notify-service-by-email` to define how notifications are sent.\n\n**6. Web Interface:**\n\n- **Accessing Nagios Web Interface:**\n  - Nagios web interface is usually accessible at `http://<your-server-ip>/nagios`.\n  - Default credentials: `nagiosadmin` and the password set during installation.\n\n- **Customizing the Interface:**\n  - Modify the theme and layout by editing files in `/usr/local/nagios/share`.\n\n**7. Monitoring Remote Hosts:**\n\n- **NRPE (Nagios Remote Plugin Executor):**\n  - **Installing NRPE:**\n\n    ```bash\n    sudo apt-get install nagios-nrpe-server nagios-plugins\n    sudo systemctl start nagios-nrpe-server\n    ```\n\n  - **Configuring NRPE:**\n    - Edit `/etc/nagios/nrpe.cfg` to define allowed hosts and monitored services.\n\n    ```cfg\n    allowed_hosts=127.0.0.1,192.168.1.100\n    command[check_disk]=/usr/lib/nagios/plugins/check_disk -w 20% -c 10% -p /dev/sda1\n    ```\n\n  - **Monitoring with NRPE:**\n    - Add a service in Nagios to monitor a remote host using NRPE.\n\n    ```cfg\n    define service {\n      use                     generic-service\n      host_name               remotehost\n      service_description     Disk Usage\n      check_command           check_nrpe!check_disk\n    }\n    ```\n\n**8. Nagios XI:**\n\n- **Introduction to Nagios XI:**\n  - Nagios XI is the commercial version of Nagios Core, providing additional features like a more user-friendly interface, reporting, and advanced monitoring capabilities.\n\n- **Differences from Nagios Core:**\n  - Built-in wizards, easier configuration, and more extensive support.\n\n**9. Advanced Nagios Concepts:**\n\n- **Passive Checks:**\n  - Useful for monitoring systems where Nagios cannot initiate checks, but the system can send results to Nagios.\n\n- **Distributed Monitoring:**\n  - Implement distributed monitoring by setting up multiple Nagios servers and configuring them to send data to a central Nagios server.\n\n**10. Securing Nagios:**\n\n- **Enabling HTTPS:**\n  - Configure Apache to serve Nagios over HTTPS.\n\n  ```bash\n  sudo a2enmod ssl\n  sudo service apache2 restart\n  ```\n\n  - Update Nagios configuration in `/etc/apache2/sites-available/nagios.conf` to use SSL certificates.\n\n- **User Authentication:**\n  - Use `.htpasswd` files to manage user access to the Nagios web interface.\n\n**11. Troubleshooting Nagios:**\n\n- **Common Issues:**\n  - **Service Check Failing:** Ensure plugins are executable and paths are correct.\n  - **Email Notifications Not Working:** Verify the mail server configuration and check the `maillog` for errors.\n\n- **Debugging:**\n  - Use the Nagios log file at `/usr/local/nagios/var/nagios.log` to troubleshoot issues.\n  - Run checks manually to verify plugin output.\n\n  ```bash\n  /usr/local/nagios/libexec/check_http -I 127.0.0.1\n  ```\n\n**12. Nagios and Docker:**\n\n- **Running Nagios in Docker:**\n\n  ```bash\n  docker run --name nagios -p 0.0.0.0:8080:80 jasonrivers/nagios\n  ```\n\n- **Customizing Dockerized Nagios:**\n  - Mount volumes to add custom configurations and plugins.\n\n  ```bash\n  docker run --name nagios -v /path/to/nagios.cfg:/usr/local/nagios/etc/nagios.cfg jasonrivers/nagios\n  ```\n",
  "Monitoring/Prometheus": "# Prometheus Cheatsheet\n\n![text](https://imgur.com/nthHFQk.png)\n\n**1. Introduction:**\n\n- **Prometheus** is an open-source systems monitoring and alerting toolkit, particularly well-suited for monitoring dynamic, cloud-native environments such as Kubernetes. It uses a pull-based model to scrape metrics from configured endpoints.\n\n**2. Key Concepts:**\n\n- **Metrics:** Data points collected over time, usually in the form of time series.\n- **PromQL:** Prometheus Query Language used to query the collected metrics.\n- **Exporters:** Components that expose metrics in a format that Prometheus can scrape.\n- **Alertmanager:** Manages alerts generated by Prometheus.\n\n**3. Installation:**\n\n- **Running Prometheus:**\n\n  ```bash\n  wget https://github.com/prometheus/prometheus/releases/download/v2.30.0/prometheus-2.30.0.linux-amd64.tar.gz\n  tar xvfz prometheus-*.tar.gz\n  cd prometheus-*\n  ./prometheus --config.file=prometheus.yml\n  ```\n\n- **Docker:**\n\n  ```bash\n  docker run -p 9090:9090 prom/prometheus\n  ```\n\n**4. Prometheus Configuration:**\n\n- **Basic `prometheus.yml` Configuration:**\n\n  ```yaml\n  global:\n    scrape_interval: 15s\n\n  scrape_configs:\n    - job_name: 'prometheus'\n      static_configs:\n        - targets: ['localhost:9090']\n  ```\n\n- **Adding Targets:**\n\n  ```yaml\n  - job_name: 'node_exporter'\n    static_configs:\n      - targets: ['localhost:9100']\n  ```\n\n**5. Prometheus Query Language (PromQL):**\n\n- **Basic Queries:**\n\n  ```promql\n  up\n  rate(http_requests_total[5m])\n  ```\n\n- **Aggregations:**\n\n  ```promql\n  sum(rate(http_requests_total[5m]))\n  avg_over_time(http_requests_total[5m])\n  ```\n\n- **Recording Rules:**\n\n  ```yaml\n  groups:\n  - name: example\n    rules:\n    - record: job:http_inprogress_requests:sum\n      expr: sum(http_inprogress_requests) by (job)\n  ```\n\n**6. Exporters:**\n\n- **Node Exporter:** Collects system-level metrics.\n\n  ```bash\n  wget https://github.com/prometheus/node_exporter/releases/download/v1.2.2/node_exporter-1.2.2.linux-amd64.tar.gz\n  tar xvfz node_exporter-*.tar.gz\n  ./node_exporter\n  ```\n\n- **Custom Exporter:** Writing a custom exporter using Python.\n\n  ```python\n  from prometheus_client import start_http_server, Gauge\n  import random\n  import time\n\n  g = Gauge('random_number', 'A random number')\n\n  def generate_random_number():\n      while True:\n          g.set(random.random())\n          time.sleep(5)\n\n  if __name__ == '__main__':\n      start_http_server(8000)\n      generate_random_number()\n  ```\n\n**7. Alerts and Alertmanager:**\n\n- **Alerting Rules:**\n\n  ```yaml\n  groups:\n  - name: example\n    rules:\n    - alert: HighMemoryUsage\n      expr: node_memory_Active_bytes / node_memory_MemTotal_bytes * 100 > 90\n      for: 5m\n      labels:\n        severity: critical\n      annotations:\n        summary: \"High memory usage detected on {{ $labels.instance }}\"\n        description: \"Memory usage is above 90% for more than 5 minutes.\"\n  ```\n\n- **Alertmanager Configuration:**\n\n  ```yaml\n  global:\n    resolve_timeout: 5m\n\n  route:\n    group_by: ['alertname']\n    receiver: 'email'\n\n  receivers:\n  - name: 'email'\n    email_configs:\n    - to: 'your-email@example.com'\n      from: 'prometheus@example.com'\n      smarthost: 'smtp.example.com:587'\n      auth_username: 'username'\n      auth_password: 'password'\n  ```\n\n**8. Prometheus Federation:**\n\n- **Setting Up Federation:**\n\n  ```yaml\n  scrape_configs:\n  - job_name: 'federate'\n    honor_labels: true\n    metrics_path: '/federate'\n    params:\n      match[]:\n        - '{job=\"prometheus\"}'\n    static_configs:\n      - targets:\n        - 'prometheus-server-1:9090'\n        - 'prometheus-server-2:9090'\n  ```\n\n**9. Monitoring Kubernetes with Prometheus:**\n\n- **Deploying Prometheus on Kubernetes:**\n\n  ```yaml\n  apiVersion: monitoring.coreos.com/v1\n  kind: Prometheus\n  metadata:\n    name: prometheus\n  spec:\n    replicas: 1\n    serviceAccountName: prometheus\n    serviceMonitorSelector:\n      matchLabels:\n        team: frontend\n    resources:\n      requests:\n        memory: 400Mi\n    storage:\n      volumeClaimTemplate:\n        spec:\n          storageClassName: standard\n          resources:\n            requests:\n              storage: 50Gi\n  ```\n\n- **ServiceMonitor Example:**\n\n  ```yaml\n  apiVersion: monitoring.coreos.com/v1\n  kind: ServiceMonitor\n  metadata:\n    name: example-monitor\n  spec:\n    selector:\n      matchLabels:\n        app: example\n    endpoints:\n      - port: web\n  ```\n\n**10. Advanced Prometheus Concepts:**\n\n- **Thanos:** Extends Prometheus with long-term storage, global querying, and downsampling.\n- **Cortex:** Multi-tenant, horizontally scalable Prometheus as a service.\n\n**11. Prometheus Security:**\n\n- **Basic Authentication:**\n\n  ```yaml\n  basic_auth:\n    username: admin\n    password: admin\n  ```\n\n- **TLS/SSL Configuration:**\n\n  ```yaml\n  tls_config:\n    ca_file: /etc/prometheus/certs/ca.crt\n    cert_file: /etc/prometheus/certs/prometheus.crt\n    key_file: /etc/prometheus/certs/prometheus.key\n  ```\n\n**12. Troubleshooting Prometheus:**\n\n- **Common Issues:**\n  - **High Cardinality Metrics:** Too many unique time series can overwhelm Prometheus.\n  - **Slow Queries:** Optimize queries by avoiding high cardinality and using efficient aggregations.\n\n- **Debugging:**\n  - Use the **`promtool`** command-line tool to check configuration files.\n  - **Prometheus UI** provides an interface to debug queries and examine time series data.\n"
}